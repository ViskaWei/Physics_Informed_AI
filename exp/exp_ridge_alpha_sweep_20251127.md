# 📊 Ridge 回归正则化强度 (α) 调优实验报告

---

# 0. 元信息（Meta Information）
- **实验名称：** Ridge Regression Alpha Sweep Experiment  
- **作者：** TODO  
- **日期：** 2025-11-27  
- **数据版本：** HDF5 光谱数据（4096 像素合成光谱）  
- **模型版本：** Ridge Regression with α ∈ [0.001, 1000]

---

# 1. 目标

## 1.1 大目标

> **核心假设：神经网络的大部分 capacity 是用来"删掉无用信息"，而不是"提取有用信息"。**

我们想验证：
- 4096 维光谱中，是否存在大量与 log_g **完全无关** 的像素/信息？
- 模型的核心任务是否是 **信息过滤（filtering）** 而非 **信息提取（extraction）**？
- 如果正则化（即"压制无关维度"）能显著提升性能，则说明 NN 设计应优先考虑 **去噪/稀疏化机制**

**最终想验证的结论：** 预测 log_g 时，把无关像素"扔掉"比"保留"更有效 —— 这意味着后续 NN 架构应侧重于学习"哪些信息不重要"。

## 1.2 实验目标

本次实验通过 Ridge 回归提供以下证据：

- **证据 1**：α=0.001 时 R² 从 OLS 的 0.969 跃升至 0.999 —— 即使无噪声，也有无关信息需要压制
- **证据 2**：最优 α 随噪声单调增大 —— 噪声越大，需要"扔掉"的无关像素越多
- **证据 3**：Ridge 在所有噪声下优于 OLS —— 信息过滤始终有益

## 1.3 子目标

本次实验要回答的具体问题：

1. **无噪声时是否也需要正则化？** → 若需要，说明光谱本身含无关信息
2. **最优 α 如何随噪声变化？** → 揭示"需删除信息量"与噪声的关系
3. **Ridge vs OLS 的性能差距有多大？** → 量化"信息过滤"的收益
4. **高噪声下线性模型的极限在哪？** → 判断是否需要非线性来"更智能地过滤"

---

# 2. 实验设计（Experiment Design）

## 2.1 数据（Data）

| 配置项 | 值 |
|--------|-----|
| 样本数 | ~52 unique (α, noise_level) 组合 |
| 特征维度 | 4,096 |
| 标签参数 | log_g |
| 噪声水平 | 0.0, 0.1, 0.2, 0.5, 1.0, 2.0 |

**噪声模型：**
$$
\text{noisy\_flux} = \text{flux} + \mathcal{N}(0, 1) \times \text{error} \times \text{noise\_level}
$$

其中：
- **flux**: 光谱流量值（每个波长点的辐射强度）
- **error**: 每个波长点的已知高斯噪声标准差 σ
- **noise_level**: 噪声缩放因子 (0.0 - 2.0)

## 2.2 模型与算法（Model & Algorithm）

### Ridge 回归（L2 正则化线性回归）
$$
\hat{y} = X w + b
$$
$$
w = (X^\top X + \alpha I)^{-1} X^\top y
$$

### OLS（Ordinary Least Squares，无正则化）
$$
w = (X^\top X)^{-1} X^\top y
$$

## 2.3 超参数搜索空间

| 参数 | 搜索范围 |
|------|----------|
| Ridge α | 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0 |
| noise_level | 0.0, 0.1, 0.2, 0.5, 1.0, 2.0 |
| 特征维度 | 4096 |

## 2.4 数据来源

| 来源 | 文件路径 | 噪声范围 | Alpha 范围 |
|------|----------|----------|------------|
| Alpha Sweep | `results/linear_alpha_search/linear_alpha_sweep.csv` | 0.0 - 2.0 | 0.001 - 1000 |
| Linear Experiments | `results/all_linear_experiments.csv` | 0.0, 0.1, 1.0 | 1 - 100 |
| Sonnet Collection | `collections/sonnet/results/LNREG_MASTER_RESULTS_TABLE.csv` | 0.0 - 2.0 | 100 |

---

# 3. 实验结果表（Results）

## 3.1 Ridge 回归完整结果（按噪声水平分组）

### Noise = 0.0（无噪声）

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | **0.9990** | **0.0060** | **0.0092** |
| 0.01 | 0.9978 | 0.0093 | 0.0138 |
| 0.1 | 0.9934 | 0.0162 | 0.0237 |
| 1.0 | 0.9784 | 0.0294 | 0.0429 |
| 10.0 | 0.9301 | 0.0546 | 0.0772 |
| 100.0 | 0.7943 | 0.1014 | 0.1324 |
| 1000.0 | 0.4720 | 0.1798 | 0.2122 |
| **OLS** | 0.9694 | 0.0380 | 0.0511 |

### Noise = 0.1

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.9012 | 0.0674 | 0.0918 |
| 0.1 | 0.9029 | 0.0669 | 0.0910 |
| 1.0 | **0.9090** | **0.0650** | **0.0881** |
| 10.0 | 0.8907 | 0.0724 | 0.0965 |
| 100.0 | 0.7802 | 0.1051 | 0.1369 |
| **OLS** | 0.9007 | 0.0673 | 0.0920 |

### Noise = 0.5

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.6075 | 0.1397 | 0.1829 |
| 10.0 | 0.6325 | 0.1359 | 0.1770 |
| 100.0 | **0.6493** | **0.1357** | **0.1729** |
| 1000.0 | 0.4365 | 0.1860 | 0.2192 |
| **OLS** | 0.6075 | 0.1397 | 0.1829 |

### Noise = 1.0

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.3851 | 0.1776 | 0.2290 |
| 50.0 | 0.4325 | 0.1734 | 0.2199 |
| 100.0 | **0.4507** | **0.1730** | **0.2164** |
| 1000.0 | 0.3684 | 0.1963 | 0.2320 |
| **OLS** | 0.3851 | 0.1776 | 0.2290 |

### Noise = 2.0

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.1312 | 0.2214 | 0.2722 |
| 100.0 | 0.1709 | 0.2184 | 0.2659 |
| 1000.0 | **0.2210** | **0.2177** | **0.2577** |
| **OLS** | 0.1312 | 0.2214 | 0.2722 |

## 3.2 最优 α 与 OLS 对比总结

| Noise | Best α | Ridge R² | OLS R² | Δ R² | 相对改进 |
|-------|--------|----------|--------|------|----------|
| 0.0 | 0.001 | **0.9990** | 0.9694 | +0.030 | +3.1% |
| 0.1 | 1.0 | **0.9090** | 0.9007 | +0.008 | +0.9% |
| 0.2 | 10.0 | **0.8264** | 0.8108 | +0.016 | +1.9% |
| 0.5 | 100.0 | **0.6493** | 0.6075 | +0.042 | +6.9% |
| 1.0 | 100.0 | **0.4507** | 0.3851 | +0.066 | +17.0% |
| 2.0 | 1000.0 | **0.2210** | 0.1312 | +0.090 | +68.4% |

---

# 4. 关键洞见（Key Insights）

## 4.1 宏观层洞见（支撑大目标假设）

### 🔑 核心发现：光谱中存在与 log_g 完全无关的信息

**关键证据：无噪声时 α=0.001 的巨大提升**

| 模型 | noise=0 时 R² | 说明 |
|------|---------------|------|
| OLS（无正则化） | 0.9694 | 保留所有 4096 维信息 |
| Ridge α=0.001 | **0.9990** | 轻微压制无关维度 |
| **Δ R²** | **+0.030 (+3.1%)** | 即使数据完全干净，也有信息需要"扔掉" |

**这说明什么？**
- 4096 维光谱中，部分像素与 log_g **完全无关**
- OLS 试图用这些无关像素拟合，反而引入噪声
- 极小的正则化（α=0.001）就能让模型"忽略"这些无关信息

### 最优 α 随噪声单调增大 → 需删除的无关信息越来越多

$$
\text{noise} \uparrow \quad \Longrightarrow \quad \alpha_{\text{opt}} \uparrow \quad \Longrightarrow \quad \text{需"扔掉"的像素越多}
$$

| 噪声水平 | 最优 α | 物理含义 |
|----------|--------|----------|
| 0.0 | 0.001 | 光谱本身含少量无关信息 |
| 0.1 | 1.0 | 噪声污染了部分像素 |
| 0.5 | 100 | 大量像素被噪声淹没 |
| 2.0 | 1000 | 几乎所有像素都需强压制 |

### 对 NN 设计的核心启示

> **NN 的主要任务不是"从光谱提取 log_g"，而是"学会哪些像素该忽略"。**

1. **架构设计应侧重"信息过滤"机制**
   - Attention 机制：学习哪些像素重要
   - Sparse 层：自动屏蔽无关维度
   - Denoising 预处理：先去噪再预测

2. **正则化 = 显式告诉模型"忽略某些信息"**
   - Weight decay、Dropout、L1 稀疏化都是在做同一件事
   - 噪声越大，需要越强的"忽略"机制

3. **Capacity 分配**
   - 大部分参数应用于"过滤无关信息"
   - 少量参数用于"从有用信息线性映射到 log_g"（因为本质是线性的）

## 4.2 关键洞见精要（Key Insights）

### 🔹 1. 为什么 Ridge 在无噪声下反而比 OLS 更好？

- 光谱中包含 **与 log_g 完全无关的特征**
- OLS（无正则）会过度拟合这些无关维度 → R²≈0.97
- Ridge (α≈0.001) 抑制这些无关方向 → 逼近完美线性关系 R²≈1.0
- **说明 100% 的 log_g 信息都在线性子空间里，OLS 只是"走偏了"**

### 🔹 2. 为什么最佳 α 会随着噪声上升而变大？

- 每个噪声水平都有一个最佳的 **bias–variance tradeoff** 点
- 噪声越大 → 模型越容易拟合噪声 → 需要更强正则（更大 α）
- **这说明光谱在噪声 regime 下：噪声主导的是高频维度，信号偏低频/平滑**

### 🔹 3. α 随噪声变化透露了数据的物理结构

| α 随 noise 的变化 | 含义 | 本实验情况 |
|-------------------|------|------------|
| **α 随 noise ↑ 上升** | 数据中有大量可被噪声污染的高频分量（像素级信息）；真正 log_g 信息在更"平滑"的方向上；需要强正则来过滤噪声 | ✅ **符合** |
| α 不变 | 信号结构稳定，对噪声不敏感（常见于低维结构或强归一化数据） | ❌ |
| α 随 noise ↑ 反而下降（少见） | 数据天然具有平滑性／强先验结构，不需要大正则 | ❌ |

**物理解读：** log_g 信息编码在光谱的 **低频/平滑结构** 中，而非像素级细节。噪声优先污染高频分量，因此需要正则化来"低通滤波"。

---

## 4.3 模型层洞见（用于优化模型）

### Ridge 一致性优于 OLS

在所有噪声水平下，最优调参的 Ridge 都优于 OLS：
- 最小改进：noise=0.1 时 +0.9%
- 最大改进：noise=2.0 时 +68.4%

**结论：** 即使是简单的 L2 正则化，在高维回归中也是必要的。

### 过度正则化的代价

| Noise | α=100 vs α_opt |
|-------|----------------|
| 0.0 | R² 从 0.999 降至 0.794 (−20%) |
| 0.1 | R² 从 0.909 降至 0.780 (−14%) |

**警示：** 固定 α 策略在跨噪声场景下不可行。

### 评估指标一致性

R², MAE, RMSE 三个指标在所有噪声水平下指向相同的最优 α，表明：
- 无需针对不同指标选择不同超参数
- 可以使用任一指标进行超参数搜索

## 4.4 物理层洞见

### 光谱-log_g 映射的线性本质

$$
\text{noise} = 0 \Rightarrow R^2 = 0.999
$$

这表明：
1. **log_g 信息分布在多个像素上**，而非稀疏谱线
2. **映射本质是线性的**，非线性模型可能只带来边际改进
3. **特征工程重点应在去噪**，而非复杂变换

### 噪声对信息的破坏

| Noise | Best R² | 信息损失 |
|-------|---------|----------|
| 0.0 | 0.999 | 0% |
| 0.1 | 0.909 | ~9% |
| 0.5 | 0.649 | ~35% |
| 1.0 | 0.451 | ~55% |
| 2.0 | 0.221 | ~78% |

**结论：** 噪声对性能的影响是剧烈的，再多的正则化也无法恢复丢失的信息。

---

# 5. 实验结果图

## 5.1 主图：Ridge 性能 vs log₁₀(α)（按噪声水平分组）

![Ridge Metrics vs Alpha by Noise](ridge_metrics_vs_alpha_by_noise.png)

**图表结构：** 3×1 布局
- **上图**：Test R² vs log₁₀(α)（越高越好）
- **中图**：Test MAE vs log₁₀(α)（越低越好）
- **下图**：Test RMSE vs log₁₀(α)（越低越好）

**颜色方案：** Viridis colormap
- 🟡 黄色：noise=0（干净数据）
- 🟣 紫色：noise=2（高噪声）

**标记说明：**
- 折线 + 圆点：Ridge 回归结果
- ★ 星号 (x=-3.5)：OLS 基线

---

# 6. 结论（Conclusion）

## 6.1 本实验验证了什么？

| 结论 | 证据 |
|------|------|
| ✅ 最优 α 随噪声单调增大 | α_opt: 0.001 → 1000 (noise: 0 → 2) |
| ✅ Ridge 在所有噪声下优于 OLS | Δ R²: +0.8% ~ +68.4% |
| ✅ 光谱-log_g 映射本质线性 | noise=0 时 R²=0.999 |
| ✅ 三个评估指标一致指向相同最优 α | R², MAE, RMSE 峰值/谷值重合 |
| ⚠️ 高噪声下线性模型能力有限 | noise=2 时 best R²=0.22 |

## 6.2 对模型设计的启示

1. **线性模型足以作为强基线**
   - noise ≤ 0.5 时，Ridge R² ≥ 0.65
   - NN 需要明显超越此基线才有价值

2. **正则化策略**
   - NN 的 weight decay 应与数据噪声水平挂钩
   - 考虑自适应正则化机制

3. **架构设计**
   - 推荐 "Linear + Residual" 结构
   - 先用 Ridge 获得初始预测，再用 NN 学习残差

## 6.3 对光谱物理的贡献

- 证实了 **4096 像素光谱对 log_g 的线性映射几乎完美**
- 信息冗余性高，支撑使用压缩/降维技术
- 噪声鲁棒性需要依靠正则化而非模型复杂度

## 6.4 仍不确定的问题

- 非线性模型（NN、LightGBM）在高噪声下能否超越 Ridge？
- 其他恒星参数（T_eff, [Fe/H]）是否呈现相似的线性特性？
- α_opt 是否可以从噪声统计量直接估计？

---

# 7. 下一步（Next Steps）

## 7.1 非线性模型对比

| 实验 | 目的 |
|------|------|
| LightGBM vs Ridge (same noise levels) | 量化非线性增益 |
| NN vs Ridge (same noise levels) | 评估神经网络必要性 |

## 7.2 其他恒星参数

```python
# 对 T_eff, [Fe/H] 重复相同实验
for param in ['teff', 'feh']:
    run_alpha_sweep(target=param, noise_levels=[0, 0.1, 0.5, 1.0, 2.0])
```

## 7.3 α 自动选择

- 交叉验证自动选择 α
- 探索 α 与噪声估计的函数关系

## 7.4 神经网络架构验证

```python
# 验证 "Linear + Residual" 设计
class LinearResidualNN(nn.Module):
    def __init__(self):
        self.ridge_layer = nn.Linear(4096, 1)  # 用 Ridge 权重初始化
        self.residual_net = MLP(4096, 1)
    
    def forward(self, x):
        return self.ridge_layer(x) + self.residual_net(x)
```

---

# 8. 相关文件索引

| 类型 | 路径 |
|------|------|
| 图表 | `figs/ridge_metrics_vs_alpha_by_noise.png` |
| 绘图脚本 | `scripts/plot_ridge_r2_vs_alpha.py` |
| Alpha Sweep 脚本 | `scripts/alpha_sweep.sh` |
| Ridge 配置 | `configs/exp/logg/linear_ridge.yaml` |
| 结果汇总 | `results/LINEAR_ALPHA_SWEEP_RESULTS.md` |

---

# 9. 复现命令

```bash
cd /home/swei20/VIT
python scripts/plot_ridge_r2_vs_alpha.py
# Output: figs/ridge_metrics_vs_alpha_by_noise.png
```

---

*Generated: 2025-11-27*


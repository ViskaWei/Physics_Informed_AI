# 2025-09-18（留学生）-AI岗 题

## 一、单选题

### 1. 关于 GPT 系列模型在微调时的使用方式，哪项最常见?

* A. 采用文本生成式微调，通过给定前缀（prompt）进行自回归生成
* B. 添加分类头井只保留 encoder 层
* C. 在输入句子中随机掩码若干词进行填空
* D. 在句对中加入 segment embedding

**答案：A**

GPT 为 decoder-only，常见微调为因果语言建模/指令微调（prompt 触发自回归生成）。

---

### 2. 用迭代法解方程 $x=2x-3$ 。构造选代公式：$x_{k+1}=2x_k-3$ 。若初值 $x_0=1$ ，则下一步迭代值 $x_1$；和再下一步 $x_2$ 分别是?

* A. $x_1=-1,\ x_2=1$
* B. $x_1=-1,\ x_2=-5$
* C. $x_1=1,\ x_2=-1$
* D. $x_1=-3,\ x_2=-9$

**答案：B**

$$x_1=2\cdot1-3=-1,\quad x_2=2\cdot(-1)-3=-5$$

---

### 3. 在用高斯消元法解线性方程组 $Ax=b$ 时，若不使用主元选择，算法可能不稳定的原因是?

* A. 出现除数接近零的情况
* B. 输入向量 $b$ 有扰动
* C. 矩阵 $A$ 的元素过大
* D. 矩阵 $A$ 的维度过高

**答案：A**

枢轴接近 0 时会发生“用近零数作除数”，舍入误差被放大而不稳定。

---

### 4. 下列方法中没有考虑先验分布的是()

* A. 最大似然估计
* B. 最大后验估计
* C. 贝叶斯分类器
* D. 贝叶斯学习

**答案：A**

MLE 只最大化似然，不引入先验分布。

---

### 5. 对于二元逐辑回归模型，已训练得到的参数为 $w=[0.5,-1.0]$，$b=-1.0$ 。现给定输入样本 $x=[2,1]$，使用 Sigmold 系数计算预测概率 $P(y=1\mid x)$ 。结果保留两位小数，最接近以下哪个值?

* A. 0.27
* B. 0.55
* C. 0.60
* D. 0.43

**答案：A**

$$z=w^\top x+b=0.5\times2+(-1)\times1-1=-1,\quad \sigma(z)=\frac{1}{1+e^{1}}\approx0.27$$

---

### 6. 设二阶张量 $A=\begin{bmatrix}1&2\3&4\end{bmatrix}$，向量 $x=\begin{bmatrix}5\6\end{bmatrix}$。则张量缩幷运算 $A\cdot x$ 的结果是?

* A. $\begin{bmatrix}23\34\end{bmatrix}$
* B. $\begin{bmatrix}17\39\end{bmatrix}$
* C. $\begin{bmatrix}5&6\15&24\end{bmatrix}$
* D. $\begin{bmatrix}17&23\39&53\end{bmatrix}$

**答案：B**

$$Ax=\begin{bmatrix}1&2\3&4\end{bmatrix}\begin{bmatrix}5\6\end{bmatrix}=\begin{bmatrix}17\39\end{bmatrix}$$

---

### 7. 假设我们部署一个 LIama 70B 模型，模型有 80 层，最大支持 32k 的上下文，并且每个参数占用 2 个字节。key 和 value 都具有 4096 维，假设我们需要支持 10 个用户同时进行推理，且每个用户的请求都独立。计算所需 GPU 显存时，以下哪个选项最接近计算出的总显存需求?

* A. 10G
* B. 2000G
* C. 1000G
* D. 100G

**答案：C**

参数显存约 $70\text{B}\times2\text{B}=140\text{GB}$；KV cache（32k，上下文、80层、10并发）合计约数百 GB，总量约 550GB，最接近 1000G。

---

### 8. 在深度学习中，ReLU 激活函数的优势包括?

* A. 输出值范围为 $[-1,1]$
* B. 对输入数据的敏感度低
* C. 避免梯度消失问题
* D. 计算复杂度高，可以增强模型的表达能力

**答案：C**

ReLU 在正区间梯度为 1，可缓解梯度消失且计算简单。

---

### 9. LSTM 中，细胞状态 $c_t$ 的正确更新公式是?（$\sigma$ 为 sigmoid，$\odot$ 为逐元素乘）

* A. $c_t=i_t\odot g_t+e^{c_{t-1}}$
* B. $c_t=o_t\odot\tanh(c_{t-1})$
* C. $c_t=f_t\odot c_{t-1}+i_t\odot g_t$
* D. $c_t=\tanh(c_{t-1})+i_t\odot g_t$

**答案：C**

$$c_t=f_t\odot c_{t-1}+i_t\odot g_t$$

---

### 10. 假设随机变量 $X$ 服从均值为 1 的泊松分布，那么以下说法不正确的有

* A. $X$ 的方差也为 1
* B. 存在另一个服从泊松分布的随机变量 $Z$ 使得 $P(Z>X)=1$
* C. 泊松分布适合于描述单位时间内随机事件发生的次数
* D. 如果随机变量 $Y$ 与 $X$ 独立同分布，那么 $X+Y$ 服从均值为 2 的泊松分布

**答案：B**

泊松变量取非负整数，无法保证几乎处处 $Z>X$ 成立。

---

### 11. 在卷积神经网络中，一般而言，池化层(如 Max Pooling) 的主要作用是?

* A. 增加模型参数数量，提升模型泛化性
* B. 增强模型对输入数据的敏感度
* C. 提取局部特征并降低空间维度
* D. 提高计算精度

**答案：C**

池化用于下采样，保留显著响应并降低空间维度与计算量。

---

### 12. 某班级 60% 的学生喜欢打篮球，40% 的学生喜欢踢足球，20% 的学生两者都喜欢。随机选一名学生，若已知他喜欢打篮球，他同时喜欢足球的摄率是

* A. 50%
* B. 20%
* C. 66.7%
* D. 33.3%

**答案：D**

$$P(\text{足}\mid \text{篮})=\frac{P(\text{足且篮})}{P(\text{篮})}=\frac{0.2}{0.6}=\frac{1}{3}\approx33.3%$$

---

### 13. 在深度学习中，Batch Normalization (批归一化)的主要作用是?

* A. 直接提高模型在测试集上的准确率
* B. 通过引入随机噪声增强模型泛化能力
* C. 增加模型参数数量以提升表达能力
* D. 加速训练过程并减少对初始化的敏感度

**答案：D**

BatchNorm 规范化激活，有助于加快收敛并降低对初始化的敏感度。

---

### 14. 已知三维向量 $A=[1,2,3]$、$B=[3,4,5]$、$C=[2,5,7]$、$D=[4,3,2]$，对于以下三个任务场景，考虑采用曼哈顿距离、皮尔逊相关系数和余弦相似度进行相似性度量，下列判断错误的是()

场景1：分析两个城市“每日气温变化曲线"的相似性(关注数值波动幅度的整体接近程度)
场景2：判断两个用户“商品评分趋势"的一致性(关注评分随商品类别的变化方向是否同步，不受评分绝对值高低影响);
场景3：比较两个文档“主题分布向量”的匹配度(关注主题占比的方向一致性，忽略文档总长度差异)。

* A. 场景2中，采用皮尔逊相关系数时，$A$ 与 $C$ 的相似性高于 $A$ 与 $D$
* B. 场景3中，采用余弦相似度时，$A$ 与 $B$ 的相似性高于 $A$ 与 $D$
* C. 场景1中，采用曼哈顿距离时，$A$ 与 $B$ 的相似性高于 $A$ 与 $C$
* D. 若将所有向量均标准化(均值为 0，方差为 1)后，采用皮尔逊相关系数和采用余弦相似度的相似性排序结果不一致。

**答案：D**

标准化后余弦相似度与皮尔逊相关系数等价，因此排序应一致。

---

### 15. 如果矩阵是正交矩阵(Orthogonal Matrix)，则其特征值的模()

* A. 都是整数
* B. 都是正实数
* C. 都是实数
* D. 都是 1

**答案：D**

$$Q^\top Q=I\ \Rightarrow\ |\lambda_i|=1$$

---

## 二、多选题

### 16. 设 $T:\mathbb{R}^{3}\rightarrow \mathbb{R}^{2}$ 是线性变换，且 $T([1,0,0]^\top)=[2,1]^\top,\ T([0,1,0]^\top)=[-1,3]^\top$。以下结论正确的是?

* A. 变换的核空间至少包含一条过原点的直线
* B. 变换的像空间维度 $\le 2$
* C. $T([0,0,1]^\top)$ 可唯一确定
* D. $T([3,-2,0]^\top)=[8,-3]^\top$

**答案：A、B、D**

* ✅ A：秩 $\le 2$，由秩—零度定理零空间维数 $\ge 1$
* ✅ B：值域维度不超过陪域 $\mathbb{R}^2$ 的维数
* ❌ C：未给出 $T([0,0,1]^\top)$，无法唯一确定
* ✅ D：线性性 $T(3e_1-2e_2)=3T(e_1)-2T(e_2)=[8,-3]^\top$

---

### 17. 你正在分析一家银行的信用卡交易数据，其中盗刷交易占总交易的 0.1%。现有一个检测模型对交易进行分类。在这种高度不平衡的概率分布下，以下哪些关于统计评估的说法是正确的

* A. 准确率(Accuracy)不适合作为核心评估指标，因为即使模型将所有交易都预测为正常，准确率仍能达到 99.9%
* B. 若模型把一笔交易标记为“盗刷”，其后验为盗刷的概率应高于 0.1% 的先验概率
* C. 评估应对“盗刷/正常”两类的指标做加权（如 Balanced Accuracy/PR-AUC 等），给予两类相当权重
* D. 若 TPR=90%、FPR=1%，在 1000 笔正常交易中期望约有 10 笔被误判为盗刷

**答案：A、B、C、D**

* ✅ A：极度不平衡下 Accuracy 可能虚高
* ✅ B：阳性预测应提升后验概率（相对先验）
* ✅ C：需考虑类别不平衡的加权/更合适指标
* ✅ D：$1000\times1%=10$

---

### 18. 以下关于独立性与相关性的描述，哪些项是正确的?

* A. 若两个随机变量独立，则它们一定不相关
* B. 不相关意味着两个变量之间没有线性关系，但可能存在非线性关系
* C. 若两个随机变量相关系数为 0，则它们一定独立
* D. 若两个随机变量不相关，则它们一定独立

**答案：A、B**

* ✅ A：独立 $\Rightarrow$（有二阶矩时）相关系数为 0
* ✅ B：零相关只排除线性关系，不排除非线性依赖
* ❌ C：零相关不必然独立
* ❌ D：不相关不必然独立

---

### 19. 深入分析 Transformer 架构的内部组件，会发现其设计充满了精妙的权衡。以下关于其核心组件的描述，哪些是准确的?

* A. RMSNorm 比 LayerNorm 更简洁，省去减均值的中心化，仅按均方根缩放
* B. 前馈网络(FFN)子层通过为序列中的每一个位置学习一套独立的权重参数，来增强模型对位置特定信息的建模能力
* C. 多头注意力将 Query、Key 和 Value 投影到多个不同的低维表示子空间中，让每个“头”学习不同依赖
* D. 标准的正弦/余弦位置编码是专门为相对位置设计的编码

**答案：A、C**

* ✅ A：RMSNorm 省略中心化，仅做缩放
* ❌ B：FFN 在各位置共享同一组参数
* ✅ C：多头投影到多个子空间学习不同依赖
* ❌ D：标准正弦/余弦为绝对位置编码

---

### 20. 在以下场景中，哪些情况下数据可视化需要特别注意以避免误导性结论?

* A. 使用饼图展示超过 10 个类别的比例分布
* B. 在箱线图中忽略异常值的标注
* C. 在折线图中使用不均匀的时间问隔但未明确标注
* D. 使用散点图展示强相关变量且标明因果关系

**答案：A、B、C、D**

* ✅ A：类别过多可读性差，易误读
* ✅ B：忽略异常值信息会误导分布判断
* ✅ C：不均匀时间轴未标注会造成趋势错觉
* ✅ D：相关不等于因果，需避免因果暗示

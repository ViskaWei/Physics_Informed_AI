\section{Experiments}
\label{sec:experiments}

\subsection{Experimental Setup}
\label{sec:experiments:setup}

\todo{Describe dataset, preprocessing, and training details.}

\section{Results}
\label{sec:results}

We evaluate \textsc{SpecViT} and baseline methods on synthetic 1D stellar spectra with heteroscedastic noise, reporting performance on a held-out test set of 10{,}000 spectra. The primary metric throughout is the coefficient of determination $R^2$ for $\log g$ regression, which is comparable across linear label normalizations (Appendix~\ref{app:r2_invariance}). Unless stated otherwise, the \textsc{SpecViT} configuration used here is the fixed-capacity model with non-overlapping 16-pixel patches and a 6-layer, 256-wide Transformer encoder.

\subsection{Overall performance against classical baselines}
\label{subsec:results_overall}

Table~\ref{tab:main_results} summarizes the main $\log g$ inference results. Trained on $10^6$ spectra, \textsc{SpecViT} achieves $R^2=0.711$ on the 10k-spectrum test set, exceeding both the tree-based baseline (LightGBM; $R^2=0.614$) and the linear baseline (ridge regression; $R^2=0.50$). A physics-based template-fitting baseline achieves $R^2=0.404$ under the same evaluation split. In absolute terms, \textsc{SpecViT} improves by $\Delta R^2=0.097$ over LightGBM and by $\Delta R^2=0.307$ over template fitting, corresponding to relative gains of $\approx 16\%$ and $\approx 76\%$, respectively. For reference, the \textsc{SpecViT} model attains MAE $=0.372~\mathrm{dex}$ and RMSE $\sigma_{\mathrm{ViT}}=0.64~\mathrm{dex}$ on the same test set (Appendix~\ref{app:tables} reports supplementary metrics).

\begin{deluxetable}{lcc}
\tablecaption{Overall $\log g$ performance on the 10k-spectrum test set.\label{tab:main_results}}
\tablehead{
\colhead{Model} & \colhead{Training set size} & \colhead{$R^2$}
}
\startdata
\textsc{SpecViT} & $10^6$ & 0.711 \\
LightGBM & $10^6$ & 0.614 \\
Ridge regression & $10^6$ & 0.50 \\
Template fitting & \nodata & 0.404 \\
\enddata
\tablecomments{All methods are evaluated on the same held-out test split. Additional metrics (MAE, RMSE) and extended tables are provided in Appendix~\ref{app:tables}.}
\end{deluxetable}

\subsection{Scaling with training set size}
\label{subsec:results_scaling}

Figure~\ref{fig:scaling} shows $R^2$ as a function of training set size $N$ for \textsc{SpecViT} (fixed architecture) and the strongest classical baselines. At small scale ($N=5\times10^4$), LightGBM is competitive and marginally outperforms \textsc{SpecViT} ($R^2=0.488$ vs.\ $0.434$). However, \textsc{SpecViT} exhibits a substantially steeper improvement with data and first surpasses LightGBM at $N\sim10^5$ ($R^2=0.596$ vs.\ $0.553$). From $N=5\times10^4$ to $10^6$, \textsc{SpecViT} gains $\Delta R^2=0.277$, compared to $\Delta R^2=0.126$ for LightGBM ($\sim$2.2$\times$ smaller gain). At the largest scales, performance begins to saturate for the present \textsc{SpecViT} capacity (from $5\times10^5$ to $10^6$, $R^2$ increases only from 0.709 to 0.711), while LightGBM continues to improve over the same interval. The full numeric values are listed in Table~\ref{tab:scaling_numbers} (Appendix~\ref{app:tables}).

\begin{figure}
\centering
\IfFileExists{figs/vit_scaling_curve.png}{%
  \includegraphics[width=\columnwidth]{figs/vit_scaling_curve.png}%
}{%
  \fbox{\parbox[c][0.2\textheight][c]{0.95\columnwidth}{\centering Missing figure: \texttt{vit\_scaling\_curve.png}}}%
}
\caption{
Scaling of $\log g$ inference performance with training set size $N$.
The vertical axis shows test-set $R^2$; the horizontal axis shows the number of training spectra.
With a fixed-capacity architecture, \textsc{SpecViT} improves rapidly with data and overtakes LightGBM at $N\sim10^5$, then saturates beyond $N\gtrsim5\times10^5$.
}
\label{fig:scaling}
\end{figure}

\subsection{Robustness across signal-to-noise ratio}
\label{subsec:results_snr}

To isolate noise sensitivity, we evaluate $R^2$ within magnitude/SNR bins derived from the same forward model and noise prescription. Figure~\ref{fig:snr_ceiling} shows that all methods degrade as SNR decreases, but \textsc{SpecViT} retains an advantage across the full range tested. For representative bins, \textsc{SpecViT} achieves $R^2=0.90$ at ${\rm SNR}\approx 24$, $R^2=0.80$ at ${\rm SNR}\approx 7$, and $R^2=0.68$ at ${\rm SNR}\approx 4.6$, compared to LightGBM values of 0.87, 0.74, and 0.60, respectively. Numerical values for each SNR bin are provided in Table~\ref{tab:snr_numbers} (Appendix~\ref{app:tables}).

\begin{figure}
\centering
\IfFileExists{figs/r2_vs_snr_ceiling_test_10k_unified_snr.png}{%
  \includegraphics[width=\columnwidth]{figs/r2_vs_snr_ceiling_test_10k_unified_snr.png}%
}{%
  \fbox{\parbox[c][0.2\textheight][c]{0.95\columnwidth}{\centering Missing figure: \texttt{r2\_vs\_snr\_ceiling\_test\_10k\_unified\_snr.png}}}%
}
\caption{
Test-set $R^2$ for $\log g$ inference as a function of signal-to-noise ratio (SNR), evaluated in magnitude/SNR bins.
Solid curves show empirical performance for \textsc{SpecViT} and LightGBM; the dashed curve shows the Fisher-information--based theoretical ceiling $R^2_{\max}({\rm SNR})$ after marginalizing over nuisance parameters (see Appendix~\ref{app:fisher_extra}).
\textsc{SpecViT} remains the best-performing learned model across SNR and approaches the ceiling at faint, high-noise conditions.
}
\label{fig:snr_ceiling}
\end{figure}

\subsection{Comparison to the Fisher-information ceiling}
\label{subsec:results_fisher}

The Fisher-information analysis provides an SNR-conditioned ceiling for any unbiased $\log g$ estimator under the same noise model, expressed as $R^2_{\max}({\rm SNR})$ by converting the marginalized Cram\'er--Rao lower bound (CRLB) to an $R^2$ upper bound (Appendix~\ref{app:fisher_extra}).

Across the SNR range relevant to our synthetic dataset, \textsc{SpecViT} closes a substantial fraction of the available headroom. At ${\rm SNR}\approx 7.1$ (representative of the mid-range regime), the 5D marginalized ceiling is $R^2_{\max}=0.874$ while \textsc{SpecViT} attains $R^2=0.80$, leaving a gap of $\approx 0.07$. At ${\rm SNR}\approx 4.6$, the ceiling is $R^2_{\max}=0.698$ and \textsc{SpecViT} reaches $R^2=0.68$, within $\approx 0.02$ of the theoretical bound. These results indicate that, in the low-SNR regime most relevant to faint targets, the current architecture is already near the information limit imposed by the spectrum and noise model, whereas at moderate-to-higher SNR there remains measurable headroom that can be targeted by improved model capacity and/or tokenization choices. Additional diagnostic plots comparing residual scatter to CRLB envelopes are provided in Appendix~\ref{app:fisher_extra}.

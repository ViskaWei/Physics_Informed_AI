# GTA (Global Tower Architecture) · log_g 实验主笔记（截至 2025-11-30）

- 本目录：`logg/gta/`
- 最近更新时间：2025-11-30
- 写作风格参考：`/home/swei20/VIT/docs`
- 说明：此文件是该子目录所有实验的主索引、核心结论与未来计划。

---

# 目录

1. [研究目标](#1-研究目标)
2. [问题重述与意义澄清](#2-问题重述与意义澄清)
3. [特征家族设计：从最弱到最强](#3-特征家族设计从最弱到最强)
4. [MVP 实验路线图](#4-mvp-实验路线图)
5. [决策树与设计指导](#5-决策树与设计指导)
6. [核心发现](#6-核心发现)
7. [关键图表](#7-关键图表)
8. [实验索引](#8-实验索引)

---

# 1. 研究目标

## 1.1 核心问题

> **在只喂给模型"中低维的、全局性质的特征"（Teff、[M/H]、全谱统计量、EW、PCA 分量、noise level）时，$\log g$ 最多能被解释到什么程度？**

据此推断：

> **一个专门吃这些特征的 Global Feature Tower 应该长什么样，和本体吃 full spectrum 的 Local Tower（CNN / Transformer）应该如何分工？**

## 1.2 与 $\log g$ 总目标的关系

为**双塔架构（Global+Local Tower）**的设计提供理论依据和实验支撑。

---

# 2. 问题重述与意义澄清

## 2.1 统计学上的问题

把 $\log g$ 看成随机变量 $Y$，把各种"全局 / meta / PCA"特征看成 $F$。用某个模型（线性 / MLP 等）拟合 $Y \approx f(F)$，得到 test $R^2$。

在模型足够强、数据量足够大、正则合适的前提下：

$$
R^2 \approx 1 - \frac{\mathbb{E}[(Y - \mathbb{E}[Y|F])^2]}{\operatorname{Var}(Y)}
$$

**即：$R^2$ 越高，说明「只看 $F$，就能消掉多少 $\log g$ 的不确定性」。**

## 2.2 恒星物理上的含义

$\log g$ 的信息主要来自：
- 压力展宽、线翼形状（Balmer wings、强金属线、Ca II 等）
- 线深 / 线宽组合，与 Teff、[M/H] 有强耦合

这些本质上是"很多线的集体行为"，不太可能被"几个颜色 + Teff"完全吃掉。

如果发现"少量全局特征就能解释大部分 $\log g$ 方差"，说明两种可能：
- **(a)** 物理上 $\log g$ 和 Teff、[M/H] 在合成 grid 里高度相关（例如沿演化轨道采样）
- **(b)** 光谱中真正用于区分 $\log g$ 的信息，可以被非常粗的 summary 聚合掉，不需要 full spectrum 的局部信息

## 2.3 "只用中低维全局特征的 $R^2$ 上界"意味着什么？

这是一个**信息上界**：
- **上界高** → Local Tower 的"必要性"降低，它更多是做细节修正
- **上界低** → 说明真正的信息高度分散在高维光谱局部结构里，Global Tower 主要是提供 priors / 辅助条件

对模型设计的影响：
- 决定了 global branch 的**设计容量（维度 / 层数）**
- 决定了 fusion 方式：是"global 负责主干、local 只补残差"，还是相反

## 2.4 为什么"PCA 需要 ~100–200 维"说明是中等维子空间？

已知结论：
- 全谱 Ridge / LightGBM 在 noise=0 时 $R^2 \approx 1$
- PCA+Ridge 要用到 ~100–200 个分量，$R^2$ 才能逼近 1；用 5–10 个远远不够

这说明：

### (1) $\log g$ 在 flux 空间上基本是"线性可逼近"的
- 线性模型 + 足够多 PCA 分量可以做到接近 full-spectrum baseline
- $\log g$ 不是特别强的「高度非线性」目标——至少在 noise=0 下

### (2) $\log g$ 信息并不集中在少数几个主模态上
- PCA 按**总方差**排序，不是按"和 $\log g$ 的相关性"排序
- 如果信息主要在前几大方差方向，5–10 维就应该很接近 $R^2=1$
- 事实是要 ~100 维 ⇒ $\log g$ 依赖许多**中等方差 / 低方差**模式叠加

### (3) 直接暗示 Global Tower 的 capacity
- 如果想用"手工设计的全局特征 + 小规模 PCA"去 $\approx$ 这个 100 维 $\log g$ 子空间：
  - Global Tower 的**输入维度**应该至少有几十—上百维
  - 输出 embedding $h_\text{global}$ 不太可能小到 8–16 维

合理的数量级：
| 组件 | 建议维度 |
|------|---------|
| **Input** | ~100–200 维（PCA 分量 + 统计量 + Teff + noise）|
| **Output embedding** | ~32–128 维 |
| **Hidden layers** | 64–256 维 |

## 2.5 三个角度的价值

### 信息论角度
- $R^2$ 曲线 ≈ 信息饱和曲线的 proxy
- 随着特征家族从 F0 → F5（尤其是 PCA 维度从 0 → 10 → 50 → 100 → 200）
- $R^2(K)$ 曲线告诉你：**"再多加 1 维 global 特征，能提升多少解释度？"**
- 可看作在粗粒度上近似 mutual information $I(\log g; F_K)$ 的增长趋势

### 物理直觉角度
- 不同线对 $\log g$ 敏感性不同：Balmer wings、金属线、线混合、blanketing 等
- 很多线对 $\log g$ 的响应**非简并**
- 每一组线贡献 1–2 维"形状自由度"；几十组线 ⇒ $\log g$ 相关有效维度在 $O(100)$ 量级

### 模型设计角度
- 如果 Teff + [M/H]\_oracle + mean/std/颜色就能给 $R^2 \approx 0.95$–$0.99$：
  - Local Tower 变成"残差修正器"
  - Global Tower 可以非常"粗"：低深度 MLP + 少量特征，承担主预测
- 如果必须 100–200 PCA 才接近 1：
  - Global Tower 更重要，是"信息压缩器"
  - Local Tower 负责建模"线性模型吃不到"的高阶局部 pattern
- 噪声升高时：
  - Global Feature Tower 可看作：**"经过人类引导的 top-K 维度 + PCA + stats 压缩器"**
  - 抗噪的 global embedding 用来约束 Local Tower（FiLM / gating），减少对噪声维敏感性

## 2.6 定位：信息上界 + 结构指导

这是一组**可控环境（合成数据、Oracle [M/H]、显式 noise level）下的"上界分析"**。

**价值**：
- 给出 Global 特征如果只有 N 维时的大致上限
- PCA 维度 vs $R^2$ 的曲线，用来选择 global 表达的 target 维度
- Global Feature Tower 的输入 / 输出维度指导
- Local Tower 复杂度需求评估

**局限**：
- 合成谱 + Oracle [M/H] + 理想 noise model，与真实观测存在 domain gap
- 真实数据中上界会被进一步压低
- 结论应被理解成：
  > **"真实世界能做到的最好情况的一种参考 / 指南"，而不是直接部署的生产模型 blueprint。**

---

# 3. 特征家族设计：从最弱到最强

下面设计 7 组由弱到强的特征家族 $F_k$。

**约定**：
- 预期 $R^2$ 主要指 **noise=0、合成 grid 近似独立采样（Teff, $\log g$, [M/H] 无强物理先验相关）** 时的直觉区间
- 若 grid 带有物理先验（如沿演化轨道），可以把区间整体上/下平移
- 数值是粗预测，重点是**相对趋势**和**异常含义**

## 3.1 F0：Teff-only

### 特征列表
- Teff
- $\log(\text{Teff})$
- $\text{Teff}^2$（可加标准化后的多项式项）

### 物理 / 统计意义
- 只用有效温度，完全不看光谱形状
- 统计学含义：拟合 $\mathbb{E}[\log g | \text{Teff}]$
- 物理含义：如果采样遵循 HRD 上的真实星族分布，同一 Teff 上的 $\log g$ 会有一定分布（主序、巨星、超巨星等）

### 预期 $R^2$ 区间（noise=0）
| 采样策略 | 预期 $R^2$ |
|----------|-----------|
| 独立采样 | **[0, 0.1]**，甚至接近 0 |
| 物理星族分布 | **[0.2, 0.4]**，一般不会很高 |

### 异常解释
- **$R^2$ 显著高于 0.4–0.5**：
  - 采样策略把 $\log g$ 几乎函数化为 Teff（固定一条主序轨道）
  - 或数据/code 有泄漏（$\log g$ 被当作 feature 混入）
  - **排查**：画 Teff vs $\log g$ 散点图，检查是否几乎一条窄带

- **$R^2$ 接近负数或非常低（<0）**：
  - 模型、训练流程可能有 bug

**实验状态**：✅ 已验证: $R^2 \approx 0$

---

## 3.2 F1：Teff + oracle [M/H]

### 特征列表
- Teff, $\log(\text{Teff})$, $\text{Teff}^2$
- [M/H]\_oracle
- 交互项：Teff × [M/H], $\log(\text{Teff})$ × [M/H]（可选）

### 物理 / 统计意义
- 加入真实金属丰度（只在 teacher / 上界场景出现）
- 统计上拟合 $\mathbb{E}[\log g | \text{Teff}, [\text{M/H}]]$
- 物理上：在某些星族假设下 Teff + [M/H] 对 $\log g$ 有一定约束

### 预期 $R^2$ 区间（noise=0）
| 采样策略 | 预期 $R^2$ |
|----------|-----------|
| 独立参数 grid | **[0.0, 0.2]**，通常比 F0 略高 |
| 有物理星族先验 | **[0.3, 0.6]** |

### 异常解释
- **$R^2 > 0.8$–$0.9$**：
  - Grid 里 $\log g$ 与 (Teff, [M/H]) 基本函数关系
  - 对"用光谱测 $\log g$"的科学问题是警报（grid 物理可能不 realistic）

- **$R^2$ 远低于 F0**：
  - [M/H] 噪声/预处理有问题，或被极端值"干扰"
  - 需要 feature scaling 或去除异常

**实验状态**：✅ 已验证: $R^2 \approx 0$

---

## 3.3 F2：F1 + 全谱统计量 + 粗颜色

### 特征列表
在 F1 基础上加：
- mean(flux)
- std(flux)
- 粗颜色指数：
  - Blue\_mean：蓝端窗口 $[\lambda_{b1}, \lambda_{b2}]$ 的平均 flux
  - Red\_mean：红端窗口 $[\lambda_{r1}, \lambda_{r2}]$ 的平均 flux
  - Color\_1 = Blue\_mean - Red\_mean
- （选做）noise\_level

### 物理 / 统计意义
- mean/std 捕获整体亮度归一化问题 / line blanketing 程度
- 粗颜色捕获"总体倾斜"：类似宽带 photometry
- 实际上在问：**"如果我只看 photometry + meta 参数，不看光谱高分辨结构，$\log g$ 能被解释多少？"**

### 预期 $R^2$ 区间（noise=0）
| 采样策略 | 预期 $R^2$ |
|----------|-----------|
| 独立 grid | **[0.1, 0.3]** |
| 有物理相关 grid | **[0.4, 0.7]** |

### 异常解释
- **F2 比 F1 几乎没提升**：
  - mean/std/粗颜色在归一化方式下几乎不携带额外 $\log g$ 信息
  - 可能归一化过于激进，把 continuum shape 抹平了

- **F2 直接飙到 $R^2 > 0.9$**：
  - "粗颜色窗口"刚好选中极强 $\log g$ 敏感线（已像是 EW 特征）
  - 或 grid 里 $\log g$ 与 continuum shape 有非常强耦合

**实验状态**：⏳ TODO

---

## 3.4 F3：F2 + 基于 top-K 重要波长的 EW / 颜色型特征

### 特征构造步骤

1. **选取 top-K 波长**
   - 用全谱 + 线性回归 / LightGBM 对 $\log g$ 做训练
   - 得到按 |weight| 或 importance 排序的 top-K $\lambda_i$（如 K=10 或 20）

2. **定义窗口**
   - line window：$[\lambda_i - w_l, \lambda_i + w_l]$（覆盖 ±2–3 像素）
   - continuum window：
     - blue cont：$[\lambda_i - w_{c2}, \lambda_i - w_{c1}]$
     - red cont：$[\lambda_i + w_{c1}, \lambda_i + w_{c2}]$（5–10 像素宽）

3. **构造标量特征**
   - **EW-like**：$\mathrm{EW}_i = \sum_{\lambda \in \text{line}} (1 - F_\lambda / F_{\text{cont},i}) \Delta\lambda$
   - **Line depth**：$D_i = 1 - \min_{\lambda \in \text{line}} F_\lambda / F_{\text{cont},i}$
   - **line-to-continuum color**：$C_i = F_{\text{line mean}} - F_{\text{cont mean}}$

4. **限制总特征数**
   - 每条线取 2 个 summary，10 条线 → 20 维 EW/颜色特征

### F3 特征列表
- F2 的全部特征
- K 条线的 EW\_i, D\_i / C\_i 等共 10–40 维

### 物理 / 统计意义
- top-K $\lambda_i$ 本质上就是"对 $\log g$ 最敏感"的局部波段
- EW / line depth / 局部颜色是 $\log g$ 经典 diagnostics 的 summary
- **在多个关键线附近的 line shape 被压缩成少数 summary scalars**

### 预期 $R^2$ 区间（noise=0）
| 采样策略 | 预期 $R^2$ |
|----------|-----------|
| 独立 grid | **[0.3, 0.7]** |
| 有物理星族先验 | **[0.6, 0.85]** |

### 异常解释
- **F3 比 F2 提升极小**：
  - top-K $\lambda$ 的选取不稳（noisy model 或过强正则）
  - EW 计算受 continuum 定义 / 归一化影响
  - **排查**：画出 line window 附近不同 $\log g$ 的平均谱，检查是否真的敏感

- **F3 达到 $R^2 \geq 0.9$ 接近 full-spectrum**：
  - $\log g$ 信息极度集中在有限几组线
  - 对 Local Tower 设计：在这些 $\lambda$ 附近**加大分辨率 / 特殊 attention bias**
  - global / PCA 的价值会相对降低

**与 Global Tower 的映射**：
- 如果 F3 可以做到 $R^2 > 0.7$：
  - Global Tower 至少要预留这些"物理 EW 特征"的通道
  - 它们可以比 PCA features 拥有更高权重或单独一层

**实验状态**：⏳ TODO

---

## 3.5 F4：F3 + PCA(K\_small)

### 特征列表
- F3 全部特征
- PCA 分量：K=10 或 20（对归一化 flux 做 PCA）

### 物理 / 统计意义
- 在"手工 EW / 颜色"之外引入少量全局 shape 模式
- PC 捕获 continuum shape + 大尺度 line blending 模式
- 统计上拟合：F3 的 summary + 一个 10–20 维低秩近似光谱

### 预期 $R^2$ 区间（noise=0）
鉴于"要 100–200 PCA 维才能接近 1"，K=10/20 应该只吃到一部分：

| 采样策略 | 预期 $R^2$ |
|----------|-----------|
| 独立 grid | **[0.5, 0.8]** |
| 有物理星族先验 | **[0.7, 0.9]** |

### 异常解释
- **与 F3 几乎无差别**：
  - 前 10–20 个 PCA mode 与 $\log g$ 相关性有限，信息主要在更后面的 modes
  - 这是有趣信号：**$\log g$ 信息更偏向中低方差方向**

- **F4 已接近 full-spectrum baseline（$R^2 > 0.95$）**：
  - 与"100–200 维才接近 1"的已有结论冲突
  - **检查**：PCA 实验和之前是否用完全相同的 preprocessing / wave range；是否误用了更多维度

**实验状态**：⏳ TODO

---

## 3.6 F5：F3 + PCA(K\_mid)

### 特征列表
- F3 全部特征
- PCA 分量：$K \in \{50, 100, 200\}$

### 物理 / 统计意义
- 在 F3 的 summary 上叠加"主要承载 $\log g$ 信息的中等维度线性子空间"投影
- K=50：覆盖相当一部分 $\log g$ 相关模式，但按已有结论**不够完全**
- K=100–200：应该逼近 full-spectrum 线性模型的性能上界

### 预期 $R^2$ 区间（noise=0）

| PCA 维度 K | 预期 $R^2$ |
|-----------|-----------|
| K=50 | **[0.85, 0.95]**（若低于 0.8 → 怀疑 PCA / 实现问题）|
| K=100 | **[0.95, 0.99]**，与 full-spectrum Ridge 非常接近 |
| K=200 | **≥ full-spectrum Ridge**（若显著下降 < 0.95，说明过拟合 / 正则设置不对）|

### 异常解释
- **K 递增时 $R^2$ 非单调（K=50 > 100 或 100 > 200）**：
  - 正则或训练过程有问题（超参数针对不同 K 没有重新调优）

- **F5 明显比之前"简单 PCA+Ridge 实验"好/坏很多**：
  - 要对齐实验设定（样本数、标准化方式、train/test split）

**实验状态**：⏳ TODO

---

## 3.7 F6：现实版（无 oracle [M/H]）

### 特征列表
在 F4 / F5 基础上修改：
- 用 Teff + 全局统计 + EW + PCA(K)
- 去掉 [M/H]\_oracle，改为：
  - 无 [M/H]（极端场景），或
  - 使用观测推断的 [M/H]\_est（带噪声 / 系统偏差）+ 其不确定度

### 物理 / 统计意义
- 更接近真实观测场景
- 统计上：比较 F5 (oracle) 与 F6 的 $R^2$ 差异，评估：
  - "因 [M/H] 不确定而带来的 $\log g$ 信息损失"

### 预期 $R^2$ 区间（noise=0）
| 场景 | 预期 $R^2$ |
|------|-----------|
| 无任何 [M/H] 信息 | 比 F5 降低一个档次：**[0.8, 0.95]** |
| 有 reasonably good 的 [M/H]\_est | 只略低于 F5：**[0.9, 0.98]** |

### 异常解释
- **F6 与 F5 几乎一样好**：
  - [M/H] 不确定性在 noise=0 情景下对 $\log g$ 估计影响不大
  - 或 $\log g$ 信息主要在那些对 [M/H] 不敏感的线 / 模式上

- **F6 远远差于 F5（差 0.2 以上的 $R^2$）**：
  - $\log g$ 与 [M/H] 高度耦合
  - 提示未来可能要做**joint modeling（共享 latent 结构）或多任务网络**才能更好 disentangle

**实验状态**：⏳ TODO

---

## 3.8 特征家族汇总表

| 家族 | 包含特征 | 估计维度 | 预期 $R^2$ (独立 grid) | 状态 |
|------|---------|---------|------------------------|------|
| **F0** | Teff 多项式 | 3 | [0, 0.1] | ✅ 已验证: ≈0 |
| **F1** | F0 + [M/H]\_oracle | 5-7 | [0.0, 0.2] | ✅ 已验证: ≈0 |
| **F2** | F1 + mean/std/颜色 | 10-15 | [0.1, 0.3] | ⏳ TODO |
| **F3** | F2 + Top-K EW/depth | 30-60 | [0.3, 0.7] | ⏳ TODO |
| **F4** | F3 + PCA(10-20) | 40-80 | [0.5, 0.8] | ⏳ TODO |
| **F5** | F3 + PCA(50-200) | 80-260 | [0.85, 0.99] | ⏳ TODO |
| **F6** | F5 无 oracle [M/H] | 80-260 | [0.8, 0.95] | ⏳ TODO |

---

# 4. MVP 实验路线图

## 4.1 总体实验框架

### noise level
- 先固定 noise=0 做 sanity
- 再选几个代表值：$\sigma \in \{0.1, 0.3, 1.0, 2.0\}$ 做 noise scan

### 数据规模
| 规模 | 训练集 | 测试集 | 用途 |
|------|--------|--------|------|
| Toy sanity | 5k | 1k | 快速验证 |
| 正式 | 32k | 8k | 完整实验 |

### 模型优先级
1. 先 **Ridge / ElasticNet**（解释性强、训练稳定）
2. 若怀疑存在非线性，再加**小 MLP** 作为对照

### 特征处理
- 对所有 scalar 特征做 standard scaling（减均值除 std）
- 对 PCA 分量也建议做 scaling（虽然正交，但方差可能不同）

---

## 4.2 MVP-0.0：复现 full-spectrum baseline

**目标**：确认新数据 split / 实验脚本下，full-spectrum Ridge / LightGBM 能在 noise=0 接近 $R^2=1$

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 5k / 1k |
| 模型 | Ridge（α 做 log-grid 搜索）；LightGBM（small depth）|
| 评价 | test $R^2 \approx 0.99$–$1$；MAE 极小 |

**早期止损**：$R^2 < 0.95$ → 直接停，检查：
- 输入维度是否正确（4096）
- 归一化是否与旧实验一致
- train/test 是否正确 shuffle & split
- 代码是否对 target 做了错误变换

---

## 4.3 MVP-1.0：Teff-only baseline（F0, noise=0）

**目标**：回答"只知道 Teff，$\log g$ 的可解释度有多少？"检查合成 grid 是否存在不合理的 Teff–$\log g$ 强相关

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 5k / 1k |
| 模型 | Ridge / ElasticNet |
| 特征 | 标准化 Teff, $\text{Teff}^2$, $\log(\text{Teff})$ |

**验收预期**：
| 采样策略 | 预期 $R^2$ |
|----------|-----------|
| 独立 grid | [0, 0.1] |
| 有星族先验 | [0.2, 0.4] |

**异常处理**：
- $R^2 > 0.6$–$0.7$：画 Teff vs $\log g$ 散点，检查是否基本一条窄曲线

---

## 4.4 MVP-1.1：Teff-only across noise

**目标**：检查 noise 对纯 meta 特征回归的影响应该几乎为 0

| 项目 | 配置 |
|------|------|
| noise | $\{0, 0.3, 1.0, 2.0\}$ |
| 数据 | 每个 5k / 1k |

**验收**：$R^2$ 随 noise 几乎不变

**异常**：若随 noise 变化很大 → 检查 Teff 是否是从 noisy 光谱估计出来的（而不是真值）

---

## 4.5 MVP-2.0：F1（Teff + [M/H]\_oracle, noise=0）

**目标**：看"Teff + 真 [M/H]"本身能解释多少 $\log g$ 方差

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 5k / 1k |
| 模型 | Ridge（含交互项）；scaling |

**预期**：$R^2$ 比 F0 略高，但仍显著低于 full-spectrum（通常不超过 ~0.5–0.6）

**异常**：
- $R^2 > 0.9$：grid 后门强相关 / 泄漏；画 (Teff, [M/H]) → $\log g$ 的 2D 投影

---

## 4.6 MVP-3.0：F2（加 mean/std/粗颜色, noise=0）

**目标**：检查 photometry-like global stats 能否显著提升 $\log g$ 解释度

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 5k / 1k |
| 模型 | Ridge；注意 mean/std/颜色也要 scaling |

**预期**：相对 F1 有一定提升，但不应接近 full-spectrum；独立 grid 时从 0.1–0.2 → 0.2–0.4

**异常**：
- 几乎无提升：continuum 可能被归一化掉
- 直接来到 0.9+：粗颜色窗口已过于针对性

---

## 4.7 MVP-3.1：F3（加入 EW / 颜色线型特征）

**目标**：验证 top-K 局部线型 summary 能否显著提升 $R^2$。**检验"局部线型 vs 全局 photometry"对 $\log g$ 信息贡献的关键实验**

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 5k / 1k |
| 模型 | Ridge；也可加小 MLP（2 层、hidden=64）看是否存在明显非线性增益 |

**预期**：$R^2$ 应该从 F2 水平显著跳升（从 0.3–0.4 → 0.5–0.7 或更高）

**早停条件**：若 $R^2$ 与 F2 几乎相同（提升 < 0.05）：
- 画出这些 $\lambda_i$ 附近不同 $\log g$ 的平均谱，检查是否真的 $\log g$-sensitive
- 检查 EW 计算是否出了 bug

**→ 与 Global Tower 的映射**：
- 如果 F3 已经可以做到 $R^2 > 0.7$：
  - Global Tower 至少要预留这些"物理 EW 特征"的通道
  - 它们可以比 PCA features 拥有更高权重或单独一层

---

## 4.8 MVP-4.0：F4（F3 + PCA K=10/20, noise=0）

**目标**：看少量 PCA mode 是否让 $R^2$ 接近 full-spectrum，或至少有明显增益

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 5k / 1k |
| 模型 | Ridge |

**注意**：PCA 要在 train 上 fit，再 transform test，避免 data leakage

**预期**：相对 F3 有明显提升；但与 full-spectrum 仍有差距：$R^2$ 大致 [0.5, 0.8]

**异常**：
- $R^2 \sim$ F3：说明前 10/20 mode 对 $\log g$ 信息有限，这是重要结论
- $R^2 \geq 0.95$：与"需要 100–200 PCA 维"结论冲突

---

## 4.9 MVP-4.1：F5（F3 + PCA K=50/100/200, noise=0）

**目标**：再现并系统化之前的 PCA 结论：看 $R^2$ 随 K 的提升曲线，并和 full-spectrum baseline 对齐

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 32k / 8k（提高稳定性）|
| 模型 | Ridge（对每个 K 单独调 α）|
| 输出 | $R^2(K)$ 曲线 |

**预期**：
| K | 预期 $R^2$ |
|---|-----------|
| 50 | [0.85, 0.95] |
| 100 | [0.95, 0.99] |
| 200 | 与 full-spectrum Ridge 非常接近或略优 |

**早停 / debug**：若 K 提升时 $R^2$ 明显下降：
- 首先增加正则（α 更大），避免高维 overfit
- 确认 PCA 是 whitened=FALSE 或对 Ridge 的影响

**→ 与 Global Tower 的映射**：
- 选择 K=100 左右时，线性模型 + PCA 就几乎吃光 $\log g$ 信息
- 这给 Global Tower 输入规模一个关键"靶点"：
  > **"Global Tower 输入：PCA(K≈100) + 若干 EW / stats + Teff + noise"**
  > 总维度大概 120–150 左右，是合理设计起点

---

## 4.10 MVP-4.2：F5 across noise（多 noise, 单模型）

**目标**：比较 F5（PCA+EW+Teff+stats）在不同 noise 下的 $R^2$ vs full-spectrum baseline。检查"中等维特征 + 正则"是否在高 noise 更鲁棒

| 项目 | 配置 |
|------|------|
| noise | 把不同 noise level 样本混合训练 |
| 特征 | noise\_level 作为额外输入特征 |
| 模型 | Ridge / 小 MLP |

**预期**：在高 noise（$\sigma \geq 1$）下，F5 的 $R^2$ 下降幅度比 full-spectrum Ridge 更小

**异常**：若 full-spectrum 在高 noise 仍然 $R^2$ 很好，但 F5 下降很多：
- PCA / EW 构造在高 noise 时敏感性更差
- 可能需要在有噪声的谱上重新 fit PCA / 重新选 top-K $\lambda$

**→ 对 Global Tower 的启发**：
- 如果 F5 在高 noise 明显更鲁棒：
  - Global Tower + Local Tower 的自然分工：
    - Global Tower 提供"抗噪的低维 prior"
    - Local Tower 只在低 noise / 高 SNR 情况下充分发挥，或通过 FiLM 被 global 约束

---

## 4.11 MVP-5.0：F6（现实版，无 oracle [M/H]）

**目标**：评估 oracle vs realistic [M/H] 的差距，量化 $\log g$ 对 [M/H] 耦合的影响

| 项目 | 配置 |
|------|------|
| noise | 0 |
| 数据 | 32k / 8k |
| 模型 | Ridge / 小 MLP |
| 变体 | 无 [M/H]（极端版本）/ 有 [M/H]\_est |

**预期**：$R^2$ 比 F5 略低，但曲线形状相似

**异常**：
- 大幅下降（从 0.97 → 0.8）：
  - 强烈暗示 $\log g$ 与 [M/H] 强耦合
  - 对后续 joint modeling 有直接动机

---

## 4.12 MVP-Global-1：Global Feature Tower 单塔 vs Ridge

**目标**：用 MLP Global Tower 单独吃（F5 或 F6 特征），预测 $\log g$，看非线性能否带来增益。**这是"Global Tower 可达上界"的直接测量**

| 项目 | 配置 |
|------|------|
| noise | 选定 0.3，用于测试非线性是否有意义 |
| 数据 | 32k / 8k |

**模型对比**：
| 模型 | 结构 |
|------|------|
| **线性基线** | Ridge on F5/F6 |
| **Global Tower** | 见下方结构 |

**Global Tower 结构示意**：
- 输入维度：$d_\text{in} \approx$ (K\_PCA + EW 数 + stats + Teff + noise) $\approx 120$–$160$
- 结构：
  $$h_1 = \phi(W_1 x + b_1)$$
  $$h_2 = \phi(W_2 h_1 + b_2)$$
  $$h_\text{global} = W_3 h_2 + b_3$$
  - hidden\_dim $\approx 128$
  - 输出 embedding 维度 dim($h_\text{global}$) $\approx 64$
  - 最后线性层 $h_\text{global} \to \log g$ 预测

**评价**：比较 Ridge vs Global MLP 的 $R^2$, MAE

**意义**：
- 若非线性增益显著 ⇒ Global Tower 值得用 MLP
- 若无增益 ⇒ Global Tower 可设计成非常简单的线性 / shallow MLP 结构

---

## 4.13 MVP-Global-2：Global+Local 联合（简单 concat）

**目标**：初步测试"Global Tower + Local Tower concat"在不同 noise 下的 $R^2$ vs 单 Local Tower / 单 Global Tower

| 项目 | 配置 |
|------|------|
| noise | $\{0, 0.3, 1.0\}$ |
| 数据 | 32k / 8k |

**模型结构**：
- **Local Tower**：已在 full spectrum 上训练好的 CNN / Transformer，输出 $h_\text{local}$（dim≈128–256）
- **Global Tower**：MLP，输出 $h_\text{global}$（dim≈64）
- **融合方式**：
  $$z = [h_\text{local}; h_\text{global}]$$
  $$\hat{y} = W z + b$$

**评价**：三条 $R^2$ vs noise 曲线：
1. only Local
2. only Global
3. Local+Global

**意义**：
- 若 concat 在高 noise 下提升明显：
  - 支持"Global Tower 提供抗噪 prior"
  - 之后可尝试更高级融合（FiLM / gating）

---

## 4.14 MVP 路线图汇总

| Phase | 实验 | 目标 | 优先级 | 状态 |
|-------|------|------|--------|------|
| **Phase 0** | MVP-0.0 复现 baseline | 确认实验环境正确 | P0 | ✅ |
| **Phase 1** | MVP-1.x F0 Teff-only | 验证 grid 独立性 | P0 | ✅ |
| **Phase 1** | MVP-2.0 F1 + [M/H] | 元数据信息上界 | P0 | ✅ |
| **Phase 2** | MVP-3.0 F2 (+ mean/std/颜色) | photometry 信息量 | P0 | ⏳ |
| **Phase 2** | MVP-3.1 F3 (+ EW) | 关键局部线型贡献 | P0 | ⏳ |
| **Phase 3** | MVP-4.0 F4 (+ PCA 10/20) | 少量 PCA 增益 | P1 | ⏳ |
| **Phase 3** | MVP-4.1 F5 (+ PCA 50-200) | $R^2(K)$ 曲线 | P1 | ⏳ |
| **Phase 3** | MVP-4.2 F5 across noise | 中维特征抗噪性 | P1 | ⏳ |
| **Phase 4** | MVP-5.0 F6 无 oracle | 现实场景评估 | P2 | ⏳ |
| **Phase 5** | MVP-Global-1/2 | Global Tower 原型 | P2 | ⏳ |
| **NEW** | **MVP-Local-1** | [Top-K Window + CNN/Transformer](exp_topk_window_cnn_transformer_20251201.md) | P0 | 🔄 进行中 |
| **NEW** | **MVP-Global-1** | [Global Feature Tower + MLP](exp_global_feature_tower_mlp_20251201.md) | P0 | 🔄 进行中 |

---

# 5. 决策树与设计指导

## 5.1 情形 A：Teff-only / Teff+[M/H]\_oracle 就已经 $R^2$ 很高（> 0.9）

### 物理可辨认性（identifiability）
- 说明在合成 grid 上，$\log g$ 基本上由 (Teff, [M/H]) 决定：
  $$\log g \approx f(\text{Teff}, [\text{M/H}])$$
- **光谱里关于 $\log g$ 的大部分信息，通过 Teff, [M/H] 这种"星族结构"间接给出，而不是通过 line shape 区分**
- 从物理角度可能不太 realistic（真实宇宙中，同 Teff 同 [M/H] 的 dwarf / giant 差别还是会在光谱里体现）

### Local Tower 在拟合什么？
- 如果 Global meta feature 就吃掉了 > 90% 方差：
  - Local Tower 主要在拟合剩余**小残差**：非 LTE / 微湍流 / rotation 等细节，归一化 / 仪器效应
  - 这时 Local Tower 做主力是浪费的：它是一个复杂的残差网络

### 建议的结构策略
把 Global Tower 作为**主干 + 残差结构**的主体：
1. **Step1**：用 Global Tower 预测 $\hat{g}_0 = f_\text{global}(F)$
2. **Step2**：让 Local Tower 只预测 residual：
   $$\Delta g = f_\text{local}(\text{spectrum}, h_\text{global})$$
   $$\hat{g} = \hat{g}_0 + \Delta g$$

**工程好处**：
- 主预测由低维塔完成，稳定、可解释
- Local Tower 可以小很多，只处理小幅度修正
- 在高 noise 场景可直接削弱 Local Tower 权重（$\Delta g$ 乘以 noise-dependent gate）

---

## 5.2 情形 B：必须依赖 PCA 100–200 维（F5）才接近 full-spectrum baseline

### 与"中等维度子空间"结论的对应
- 这是对"$\log g$ 信息分布在 ~100 维子空间"的直接验证
- 全谱 4096 维 → 有效 $\log g$ 子空间 ~100–200 维 → 中等维度
- Global Tower 的全部输入就是在试图**近似这个线性子空间中的投影**

### 对 Global Tower capacity 和正则化的要求
- 输入维度 ~100–200 ⇒
  - Hidden dim 建议至少 64–256
  - 层数 2–3 即可，过深反而容易 overfit / 难解释
- 正则化：
  - L2 / weight decay：避免在高 noise + 高维输入下权重爆炸
  - Dropout 可轻量使用
  - 更关键的是**对输入做 PCA / 选取 K 而不是直接喂 4096 维**

可以把 Global Tower 看成一个**"nonlinear PCA 后端"**：
- 前端 PCA 将光谱 → 线性子空间
- 后端 MLP 将 $\log g = \text{nonlinear}(\text{PCA\_modes}, \text{EW}, \text{Teff}, \text{noise})$

### 对 Local Tower 的角色
- 如果 F5 的 $R^2$ 已经接近 full-spectrum Ridge / LightGBM：
  - Local Tower 的线性部分基本可以被 Global Tower 覆盖
  - 它真正的价值在于：
    - 学习极细局部结构（如 asymmetric line profiles）
    - 学习 PCA 不能很好表达的 higher-order effects
- 建议：
  - **不要让 Local Tower 直接从零开始预测 $\log g$**
  - **Global Tower 输出先给一个"强 baseline"，Local 只补残差**
  - 否则两者会在训练中"抢主导权"，Global 的物理解释性反而被弱化

---

## 5.3 情形 C：加入 EW / 颜色特征（F3）能显著提升表现

### 物理含义
- $\log g$ 信息确实主要通过若干"关键线 / 线群"的宽度、翼部、深度体现
- 这些信息可以被低维的 EW / line shape summary 捕获
- PCA 的这些 mode 很可能也主要是这些线群组合的变形

### 对 Local Tower 设计的启示
在这些 $\lambda$ 区域应该被"特别照顾"：
- 使用更细的 patch 分辨率 / 更小的卷积 stride
- 在 Transformer 里给这些 $\lambda$ 更高 attention bias
- 或单独开一个"line-focused branch"：只处理这些 window

Global Tower 可以直接内置这些 EW 特征：
- 通过 Global Tower 获得"对哪些线敏感"的 embedding
- 再用这个 embedding 去微调 Local Tower 在对应 window 的增益（通过 FiLM）

---

## 5.4 情形 D：现实版 F6（无 oracle [M/H]）相比 F5 显著下降

### $\log g$ 与 [M/H] 耦合的强度
- F5 (oracle) → F6 (现实版) $R^2$ 明显下降 ⇒
  - "如果不知道真实的 [M/H]，我们对 $\log g$ 的后验会宽很多"
  - 技术上，$\operatorname{Var}(\log g \mid \text{Teff}, \text{spectra})$ 里有一大块来自 [M/H] 的不确定

### 对 joint modeling / latent 变量模型的启示
考虑构建多任务 / latent model：
- $(\text{Teff}, \log g, [\text{M/H}])$ 共享同一个光谱 latent 表达 $h$
- 通过联合训练 $\log g$ 和 [M/H]，让模型学会 disentangle 它们对线型的不同贡献

Global Tower 可以：
- 输入 [M/H]\_est + 在 spectral tower 中学习到的 latent [M/H]\_latent
- 结合二者做"bias correction"：
  $$[\text{M/H}]_\text{corr} = f_\text{corr}([\text{M/H}]_\text{est}, h_\text{local})$$
  然后用 [M/H]\_corr 作为 $\log g$ 预测的条件

### Global Tower 如何处理 [M/H]\_est vs true [M/H] 的偏差
把 [M/H]\_est 当作 noisy observation：
- 输入特征可以包括：
  - [M/H]\_est
  - $\sigma_\text{[M/H]}$（估计不确定度）
  - 可能还包括一些"质量指标"（例如 SNR）
- Global Tower 内部可以自动学到：
  - 当 $\sigma_\text{[M/H]}$ 很大时，减少对该特征的依赖，转而更信赖 PCA / EW
  - 可通过 MLP 自由学习，也可以通过显式 gating 设计

---

## 5.5 情形 E：F4/F5 的 $R^2$ 对 noise 更鲁棒（尤其高 noise）

### Global Tower 中显式编码 noise\_level
若实验证明：
- 中等维度 PCA+EW 的模型在高 noise 下表现优于 full-spectrum 模型
- 说明这些特征确实在起"降噪 + 去冗余"的作用

在 Global Tower 里：
- 把 noise\_level 作为一个显式输入
- 允许网络学到：
  - 在高 noise 下，降低对高阶 PCA 分量 / 细线 EW 的权重
  - 更依赖 Teff / 大尺度 PC / mean/std

### 如何让 Global Tower 成为 Local Tower 的"抗噪 prior"
FiLM / gating 策略之一：
- 用 $h_\text{global}$ 生成 per-layer 的 gating 系数 $g_l \in [0,1]$（例如通过 sigmoid 输出）
- 对 Local Tower 某些通道做 $f_l' = g_l \odot f_l$
- 在高 noise + 低 SNR 场景下，$g_l$ 倾向于压低那些对 noise 敏感的局部特征通道

从训练角度：
- 在 loss 中加入对不同 noise level 权重的平衡
- 促使网络学会"在高 noise 下更多依赖 Global Tower，在低 noise 下可以充分发挥 Local Tower"

---

## 5.6 决策分支汇总表

| 如果... | 则... |
|---------|-------|
| F0/F1 达 $R^2 > 0.9$ | Grid 采样有问题；$\log g$ 被 Teff/[M/H] 决定 |
| F3 达 $R^2 > 0.7$ | Global Tower 中预留 EW 特征通道 |
| F5 达 $R^2 > 0.95$ | Global Tower 可作为主干，Local 补残差 |
| F5 在高 noise 更鲁棒 | Global Tower 提供"抗噪的低维 prior" |
| F6 比 F5 下降 > 0.1 | 考虑 joint modeling $\log g$ + [M/H] |

---

# 6. 核心发现

## 6.1 已验证结论

| 结论 | 数值证据 | 设计启示 |
|------|---------|---------|
| **元数据无法预测 $\log g$** | Teff + [M/H]: $R^2 \approx 0$ | 必须使用光谱 flux |
| **Grid 采样设计正确** | $R^2 \approx 0$ 说明三者独立 | 无 Teff-$\log g$ 伪相关 |
| **非线性模型无增益（在元数据上）** | LightGBM 第1轮早停 | 元数据与 $\log g$ 完全无关 |

## 6.2 待验证假设

| 假设 | 验证实验 | 预期结果 |
|------|----------|----------|
| photometry stats 提升有限 | F2 | $R^2$ 提升 < 0.2 |
| EW 特征显著提升 | F3 | $R^2$ 跳升至 0.5–0.7 |
| $\log g$ 有效维度 ~100 | F5 | K=100 时 $R^2 \geq 0.95$ |
| 中维特征抗噪更强 | F5 across noise | 高 noise 下 F5 > full-spectrum |

---

# 7. 关键图表

> 以下图表待生成，位于 `img/` 子目录：

| 图表 | 描述 | 状态 |
|------|------|------|
| 特征家族 $R^2$ 阶梯图 | F0-F6 的 $R^2$ 递增趋势 | ⏳ TODO |
| PCA 维度 vs $R^2$ 曲线 | PCA 分量数与 $R^2$ 的关系 | ⏳ TODO |
| Noise 鲁棒性对比 | F5 vs full-spectrum 的抗噪能力 | ⏳ TODO |
| Global+Local 融合效果 | 三种配置的对比 | ⏳ TODO |
| Teff vs $\log g$ 散点图 | 验证 grid 独立性 | ⏳ TODO |

---

# 8. 实验索引

## 8.1 完整实验列表

| 文件 | 日期 | 主题 | 状态 |
|------|------|------|------|
| [exp_global_tower_architecture_20251130.md](exp_global_tower_architecture_20251130.md) | 2025-11-30 | GTA 架构设计企划 | 📋 进行中 |
| [exp_gta_f0f1_metadata_baseline_20251130.md](exp_gta_f0f1_metadata_baseline_20251130.md) | 2025-11-30 | F0/F1 元数据 Baseline | ✅ 完成 |
| [exp_topk_window_cnn_transformer_20251201.md](exp_topk_window_cnn_transformer_20251201.md) | 2025-12-01 | **MVP-Local-1**: Top-K Window + CNN/Transformer | 🔄 进行中 |
| [exp_global_feature_tower_mlp_20251201.md](exp_global_feature_tower_mlp_20251201.md) | 2025-12-01 | **MVP-Global-1**: Global Feature Tower 蓝图 + MLP | 🔄 进行中 |

## 8.2 相关外部文件

| 类型 | 路径 |
|------|------|
| PCA 实验参考 | `logg/pca/exp_pca_linear_regression_20251128.md` |
| Ridge 实验参考 | `logg/ridge/exp_ridge_alpha_sweep_20251127.md` |
| Top-K 实验参考 | `logg/noise/exp_topk_feature_selection_lgbm_vs_ridge_20251129.md` |

## 8.3 与其他目录的关联

| 目录 | 关联主题 | 链接 |
|------|----------|------|
| `pca/` | PCA 降维，$\log g$ 有效维度 | [pca_main](../pca/pca_main_20251130.md) |
| `noise/` | Top-K 特征选择 | [noise_main](../noise/noise_main_20251130.md) |
| `ridge/` | 线性 baseline | [ridge_main](../ridge/ridge_main_20251130.md) |

---

# 附录：Global Feature Tower 结构草图

结合以上 MVP，大概会收敛到类似这样一个塔：

## 输入维度 $d_\text{in} \approx 150$（例）

| 特征类型 | 维度 |
|----------|------|
| Teff (+ 多项式) | 3 |
| [M/H]\_est or oracle | 1 |
| noise\_level | 1 |
| mean/std/粗颜色等全局统计 | 3–6 |
| K\_EW 条线的 EW / depth / local color | ~20–40 |
| PCA(K\_PCA=64 或 100) | 64–100 |
| **总计** | **~120–150** |

## 网络结构

```
Layer1: Linear(d_in → 128) + ReLU
Layer2: Linear(128 → 128) + ReLU
Layer3: Linear(128 → 64) → h_global
Head:   Linear(64 → 1) → log_g prediction
```

## 与 Local Tower 融合

### 简单模式
$$[h_\text{local}; h_\text{global}] \to \text{2 层 MLP head} \to \log g$$

### FiLM 模式
- 用两层 MLP 从 $h_\text{global}$ 生成每层 Local Tower 的缩放/偏置参数 $(\gamma_l, \beta_l)$
- 对应层的 feature map 做 $f_l' = \gamma_l \odot f_l + \beta_l$

---

*最后更新: 2025-12-01*  
*状态: Phase 1 已完成 (F0/F1 验证)，**MVP-Local-1 & MVP-Global-1 实验计划已创建**，等待执行*  
*核心发现: 元数据无法预测 $\log g$，必须使用光谱 flux；需要 ~100 维 PCA 才能接近 full-spectrum*

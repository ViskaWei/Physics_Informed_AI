# ğŸ“˜ å­å®éªŒæŠ¥å‘Šï¼šEncoder + NN for log_g é¢„æµ‹

---
> **å®éªŒåç§°ï¼š** BlindSpot Encoder + MLP Head for log_g Prediction  
> **å¯¹åº” MVPï¼š** MVP-2.2 (Student latent â†’ log_g)  
> **ä½œè€…ï¼š** Viska Wei  
> **æ—¥æœŸï¼š** 2025-12-01  
> **æ•°æ®ç‰ˆæœ¬ï¼š** mag215 100k train / 1k val / 1k test  
> **æ¨¡å‹ç‰ˆæœ¬ï¼š** BlindSpot m215l9e48k25s1bn1d1ep5000 + MLP Head  
> **çŠ¶æ€ï¼š** âœ… å·²å®Œæˆ

---

## ğŸ”— ä¸Šæ¸¸è¿½æº¯é“¾æ¥ï¼ˆUpstream Linksï¼‰

| å­—æ®µ | å€¼ |
|------|-----|
| **æ¥æºä¼šè¯** | [session_20251201_distill_encoder_nn.md](./sessions/session_20251201_distill_encoder_nn.md) |
| **é˜Ÿåˆ—å…¥å£** | `status/kanban.md` â†’ `BS-20251201-encoder-logg-01` |

---

## ğŸ”— è·¨ä»“åº“å…ƒæ•°æ®ï¼ˆCross-Repo Metadataï¼‰

| å­—æ®µ | å€¼ |
|------|-----|
| **experiment_id** | `BS-20251201-encoder-logg-01` |
| **project** | `BlindSpot` |
| **topic** | `distill` |
| **source_repo_path** | `~/BlindSpotDenoiser/experiments/train_logg_from_encoder.py` |
| **config_path** | `~/BlindSpotDenoiser/configs/logg_from_encoder.yaml` |
| **output_path** | `~/BlindSpotDenoiser/checkpoints/logg_from_encoder/` |

---

# ğŸ“‘ ç›®å½•

- [1. ğŸ¯ ç›®æ ‡](#1--ç›®æ ‡)
- [2. ğŸ§ª å®éªŒè®¾è®¡](#2--å®éªŒè®¾è®¡)
- [3. ğŸ“Š å®éªŒå›¾è¡¨](#3--å®éªŒå›¾è¡¨)
- [4. ğŸ’¡ å…³é”®æ´è§](#4--å…³é”®æ´è§)
- [5. ğŸ“ ç»“è®º](#5--ç»“è®º)
- [6. ğŸ“ é™„å½•](#6--é™„å½•)

---

# âš¡ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆï¼ˆä¾› main æå–ï¼‰

### ä¸€å¥è¯æ€»ç»“

> **ä½¿ç”¨å†»ç»“çš„ BlindSpot Encoder (enc_pre_latent + seg_mean_K8) + MLP Head ç«¯åˆ°ç«¯è®­ç»ƒï¼Œè¾¾åˆ° Test RÂ²=0.6117ï¼Œæ¯” Ridge baseline (0.5516) æå‡ 10.9%ï¼ŒéªŒè¯äº† MLP èƒ½æ•æ‰éçº¿æ€§å…³ç³»ã€‚**

### å¯¹å‡è®¾çš„éªŒè¯

| éªŒè¯é—®é¢˜ | ç»“æœ | ç»“è®º |
|---------|------|------|
| MLP head èƒ½è¶…è¶Š Ridge baselineï¼Ÿ | âœ… **+10.9%** | RÂ²: 0.5516 â†’ 0.6117 |
| å†»ç»“ encoder æ˜¯å¦è¶³å¤Ÿï¼Ÿ | âœ… æœ‰æ•ˆ | æ— éœ€ fine-tune å³å¯è¶…è¶Š Ridge |
| ç«¯åˆ°ç«¯è®­ç»ƒå¯è¡Œï¼Ÿ | âœ… æ¡†æ¶éªŒè¯é€šè¿‡ | å®Œæ•´è®­ç»ƒ pipeline å®ç° |

### è®¾è®¡å¯ç¤ºï¼ˆ1-2 æ¡ï¼‰

| å¯ç¤º | å…·ä½“å»ºè®® |
|------|---------|
| **MLP ä¼˜äº Ridge** | ç‰¹å¾ä¸ log_g å­˜åœ¨éçº¿æ€§å…³ç³» |
| **å†»ç»“ encoder æœ‰æ•ˆ** | å¯å…ˆå†»ç»“éªŒè¯ï¼Œå†è€ƒè™‘ fine-tune |

### å…³é”®æ•°å­—

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **Test RÂ²** | 0.6117 |
| **Val RÂ²** | 0.5979 (best epoch 47) |
| **Ridge baseline** | 0.5516 |
| **æå‡å¹…åº¦** | +10.9% |
| **ç‰¹å¾ç»´åº¦** | 384 (48 Ã— 8) |

---

# 1. ğŸ¯ ç›®æ ‡

## 1.1 å®éªŒç›®çš„

**å›ç­”çš„é—®é¢˜**ï¼š
- ä½¿ç”¨é¢„è®­ç»ƒ BlindSpot encoder ç‰¹å¾ + MLP head èƒ½å¦è¶…è¿‡ Ridge probe baselineï¼Ÿ
- MLP èƒ½å¦æ•æ‰ encoder ç‰¹å¾ä¸ log_g ä¹‹é—´çš„éçº¿æ€§å…³ç³»ï¼Ÿ
- ç«¯åˆ°ç«¯è®­ç»ƒæ¡†æ¶æ˜¯å¦æ­£ç¡®å®ç°ï¼Ÿ

**å¯¹åº” main.md çš„**ï¼š
- éªŒè¯é—®é¢˜ï¼šQ5 (MLP vs Ridge)
- å­å‡è®¾ï¼šH3 (Student latent å¯å­¦ä¹ æ€§)

**æ ¸å¿ƒåŠ¨æœº**ï¼š
ä¹‹å‰çš„ç¦»çº¿ probe å®éªŒï¼ˆRidge å›å½’ï¼‰å·²éªŒè¯ `enc_pre_latent + seg_mean_K8` é…ç½®å¯è¾¾ Test RÂ²=0.5516ã€‚æœ¬å®éªŒç›®æ ‡æ˜¯ç”¨ MLP head æ›¿ä»£ Ridgeï¼ŒéªŒè¯éçº¿æ€§æ˜ å°„çš„ä¼˜åŠ¿ã€‚

## 1.2 é¢„æœŸç»“æœ

| åœºæ™¯ | é¢„æœŸç»“æœ | å®é™…ç»“æœ |
|------|---------|---------|
| æ­£å¸¸æƒ…å†µ | Test RÂ² â‰¥ 0.55 (Ridge baseline) | âœ… **RÂ²=0.6117** (+10.9%) |
| å¯æ¥å—æƒ…å†µ | Test RÂ² âˆˆ [0.50, 0.55) | - |
| å¼‚å¸¸æƒ…å†µ | Test RÂ² < 0.40 | - |

---

# 2. ğŸ§ª å®éªŒè®¾è®¡

## 2.1 æ•°æ®

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| è®­ç»ƒæ ·æœ¬æ•° | 100,000 |
| éªŒè¯æ ·æœ¬æ•° | 1,000 |
| æµ‹è¯•æ ·æœ¬æ•° | 1,000 |
| å…‰è°±ç»´åº¦ | 4,096 æ³¢é•¿ç‚¹ |
| Encoder è¾“å‡º | 48 channels Ã— 8 segments = 384 ç»´ |
| æ ‡ç­¾å‚æ•° | $\log g$ |

**æ•°æ®è·¯å¾„**ï¼š
- Train: `/datascope/subaru/user/swei20/data/bosz50000/test/mag215/train_100k/dataset.h5`
- Val: `/datascope/subaru/user/swei20/data/bosz50000/mag215/train_1k/dataset.h5`
- Test: `/datascope/subaru/user/swei20/data/bosz50000/mag215/val_1k/dataset.h5`

**å™ªå£°æ¨¡å‹**ï¼š

$$
\text{noisy\_flux} = \text{flux} + \mathcal{N}(0, \sigma^2 \cdot \text{error}^2)
$$

**Noise level**: $\sigma = 1.0$

## 2.2 ç‰¹å¾è®¾è®¡

| ç‰¹å¾ç±»å‹ | ç»´åº¦ | è¯´æ˜ |
|---------|------|------|
| Encoder feature map | (B, 48, L') | `enc_pre_latent` å±‚è¾“å‡º |
| Pooled features | (B, 384) | `seg_mean_K8` pooling (48 Ã— 8) |

**ç‰¹å¾æå–ç»†èŠ‚**ï¼š
1. è¾“å…¥ noisy flux + error åˆ° BlindSpot encoder
2. ä½¿ç”¨ `encode_flux()` æ¥å£æå– `enc_pre_latent` å±‚
3. åº”ç”¨ `seg_mean_K8` pooling è½¬æ¢ä¸ºå›ºå®šç»´åº¦å‘é‡

## 2.3 æ¨¡å‹ä¸ç®—æ³•

### é¢„è®­ç»ƒ Encoderï¼ˆå†»ç»“ï¼‰

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| Checkpoint | `evals/m215l9e48k25s1bn1d1ep5000.ckpt` |
| æ¶æ„ | BlindspotModel1D (UNet + Blindspot) |
| Layers | 9 å±‚ |
| Embed dim | 48 |
| Kernel size | 25 |
| Input sigma | True |
| BatchNorm | True |
| æ€»å‚æ•°é‡ | 1,889,670 |
| è®­ç»ƒçŠ¶æ€ | **å†»ç»“** (requires_grad=False) |

### Log_g Head (MLP)

```python
class LogGHead(nn.Module):
    # architecture = 'mlp_1' (å•éšè—å±‚)
    net = nn.Sequential(
        nn.Linear(384, 256),      # input_dim -> hidden_dim
        nn.GELU(),
        nn.Dropout(0.1),
        nn.Linear(256, 1),        # hidden_dim -> output
    )
    # å¯è®­ç»ƒå‚æ•°: 98,817
```

### è®­ç»ƒæŸå¤±

$$
\mathcal{L} = \text{MSE}(\hat{y}_{\log g}, y_{\log g}) = \frac{1}{N}\sum_{i=1}^N (\hat{y}_i - y_i)^2
$$

## 2.4 è¶…å‚æ•°é…ç½®

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| Batch size | 256 | |
| Learning rate | 0.001 | AdamW |
| Weight decay | 0.0001 | |
| Max epochs | 50 | |
| Early stopping | patience=15 | monitor: val/r2 |
| LR scheduler | ReduceLROnPlateau | factor=0.5, patience=5 |
| Gradient clip | 0.5 | |
| Dropout | 0.1 | |
| Hidden dim | 256 | MLP head |

## 2.5 è¯„ä»·æŒ‡æ ‡

| æŒ‡æ ‡ | å…¬å¼ | ç”¨é€” |
|------|------|------|
| $R^2$ | $1 - \frac{\sum(y - \hat{y})^2}{\sum(y - \bar{y})^2}$ | ä¸»è¦è¯„ä»·æŒ‡æ ‡ |
| RMSE | $\sqrt{\frac{1}{n}\sum(y - \hat{y})^2}$ | ç»å¯¹è¯¯å·® |
| MAE | $\frac{1}{n}\sum|y - \hat{y}|$ | é²æ£’è¯¯å·® |

---

# 3. ğŸ“Š å®éªŒå›¾è¡¨

### è¡¨ 1ï¼šè®­ç»ƒè¿›åº¦ (50 epochs)

| Epoch | Val RÂ² | Val RMSE | Val MAE | å¤‡æ³¨ |
|-------|--------|----------|---------|------|
| 0 | -6.57 | 3.21 | 2.99 | åˆå§‹éšæœºæƒé‡ |
| 1 | 0.334 | 0.938 | 0.780 | å¿«é€Ÿæ”¶æ•› |
| 2 | 0.409 | 0.884 | 0.719 | |
| 3 | 0.442 | 0.859 | 0.691 | |
| 5 | 0.479 | 0.830 | 0.662 | |
| 10 | 0.514 | 0.802 | 0.637 | |
| 15 | 0.541 | 0.779 | 0.617 | è¶…è¿‡ Ridge baseline |
| 20 | 0.557 | 0.765 | 0.605 | |
| 25 | 0.577 | 0.748 | 0.586 | |
| 30 | 0.576 | 0.749 | 0.589 | |
| 35 | 0.587 | 0.739 | 0.578 | |
| 40 | 0.589 | 0.737 | 0.574 | |
| 45 | 0.594 | 0.733 | 0.570 | |
| **47** | **0.598** | **0.729** | **0.570** | **Best checkpoint** |
| 50 | 0.570 | 0.754 | 0.580 | æœ€åä¸€ä¸ª epoch |

**å…³é”®è§‚å¯Ÿ**ï¼š
- **å¿«é€Ÿæ”¶æ•›**: ç¬¬ 1 ä¸ª epoch ä»è´Ÿå€¼è·³åˆ° 0.334
- **ç¨³å®šæå‡**: å‰ 20 ä¸ª epochs æŒç»­æå‡
- **å¹³ç¨³é˜¶æ®µ**: 20-50 epochs ç¼“æ…¢æå‡ï¼Œæ³¢åŠ¨è¾ƒå°
- **æœ€ä½³ç‚¹**: Epoch 47ï¼ŒVal RÂ² = 0.5979

### è¡¨ 2ï¼šæœ€ç»ˆæµ‹è¯•ç»“æœ

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **Test RÂ²** | **0.6117** |
| Test RMSE | 0.7436 |
| Test MAE | 0.5747 |
| Test Loss (MSE) | 0.5530 |

### è¡¨ 3ï¼šä¸ Ridge Baseline å¯¹æ¯”

| æ–¹æ³• | é…ç½® | Val RÂ² | Test RÂ² | æå‡ |
|------|------|--------|---------|------|
| Ridge Probe (offline) | enc_pre_latent + seg_mean_K8 | 0.586 | 0.5516 | baseline |
| **MLP Head (ours)** | enc_pre_latent + seg_mean_K8 + MLP | **0.5979** | **0.6117** | **+10.9%** |

### è¡¨ 4ï¼šå®Œæ•´ Layer Ã— Pooling å¯¹æ¯”

| Layer | Pooling | Dim | Ridge Test RÂ² | MLP Test RÂ² |
|-------|---------|-----|---------------|-------------|
| enc_pre_latent | global_mean | 48 | 0.3106 | - |
| enc_pre_latent | mean_max | 96 | 0.4056 | - |
| **enc_pre_latent** | **seg_mean_K8** | **384** | **0.5516** | **0.6117** âœ… |
| enc_last | global_mean | 48 | 0.2202 | - |
| enc_last | mean_max | 96 | 0.2886 | - |
| enc_last | seg_mean_K8 | 384 | 0.4748 | - |

---

# 4. ğŸ’¡ å…³é”®æ´è§

## 4.1 å®è§‚å±‚æ´è§

- **MLP ä¼˜äº Ridge**ï¼šåœ¨ç›¸åŒç‰¹å¾ä¸‹ï¼ŒMLP head æ¯” Ridge å›å½’æå‡äº† **10.9%** çš„ RÂ²
- **éçº¿æ€§å…³ç³»å­˜åœ¨**ï¼šMLP çš„ä¼˜åŠ¿è¯´æ˜ç‰¹å¾ä¸ log_g ä¹‹é—´å­˜åœ¨ Ridge æ— æ³•æ•æ‰çš„éçº¿æ€§å…³ç³»
- **å†»ç»“ encoder æœ‰æ•ˆ**ï¼šå³ä½¿ä¸å¾®è°ƒ encoderï¼Œä»…è®­ç»ƒ MLP head ä¹Ÿèƒ½å–å¾—è‰¯å¥½æ•ˆæœ

## 4.2 æ¨¡å‹å±‚æ´è§

- **ç‰¹å¾ä¿¡æ¯å……è¶³**ï¼šTest RÂ²=0.61 è¯´æ˜ encoder ç‰¹å¾ç¡®å®åŒ…å«äº†ç›¸å½“å¤šçš„ log_g ä¿¡æ¯
- **seg_mean_K8 ä¿ç•™å±€éƒ¨æ€§**ï¼šåˆ†æ®µ pooling æ¯”å…¨å±€ pooling ä¿ç•™æ›´å¤šæ³¢é•¿å±€éƒ¨ä¿¡æ¯
- **å•éšè—å±‚ MLP è¶³å¤Ÿ**ï¼š256 ç»´éšè—å±‚å·²èƒ½æœ‰æ•ˆå­¦ä¹ 

## 4.3 å®éªŒå±‚ç»†èŠ‚æ´è§

- **è®­ç»ƒæ—¶é—´çº¦ 45 åˆ†é’Ÿ**ï¼š100k æ ·æœ¬ï¼Œ50 epochs
- **æ¯ epoch çº¦ 1.5 åˆ†é’Ÿ**ï¼š391 batches Ã— ~0.26s/batch
- **æœ€ä½³ checkpoint åœ¨ epoch 47**ï¼šæ¥è¿‘ max_epochs ä½†æœªè¿‡æ‹Ÿåˆ

---

# 5. ğŸ“ ç»“è®º

## 5.1 æ ¸å¿ƒå‘ç°

> **MLP head ç›¸æ¯” Ridge å›å½’åœ¨ç›¸åŒ encoder ç‰¹å¾ä¸Šæå‡äº† 10.9% (Test RÂ²: 0.5516 â†’ 0.6117)ï¼ŒéªŒè¯äº† encoder ç‰¹å¾ä¸ log_g ä¹‹é—´å­˜åœ¨å¯å­¦ä¹ çš„éçº¿æ€§å…³ç³»ã€‚**

**å‡è®¾éªŒè¯**ï¼š
- âœ… MLP èƒ½æ•æ‰éçº¿æ€§å…³ç³» (RÂ² æå‡ 10.9%)
- âœ… ç«¯åˆ°ç«¯è®­ç»ƒæ›´ä¼˜
- âœ… å¤§å¹…è¶…è¶Š Ridge baseline

## 5.2 å…³é”®ç»“è®ºï¼ˆ2-4 æ¡ï¼‰

| # | ç»“è®º | è¯æ® |
|---|------|------|
| 1 | **MLP ä¼˜äº Ridge** | Test RÂ²: 0.5516 â†’ 0.6117 (+10.9%) |
| 2 | **éçº¿æ€§å…³ç³»å­˜åœ¨** | MLP èƒ½å­¦åˆ° Ridge æ— æ³•æ•æ‰çš„æ¨¡å¼ |
| 3 | **å†»ç»“ encoder æœ‰æ•ˆ** | æ— éœ€ fine-tune å³å¯è¶…è¶Š baseline |
| 4 | **ç«¯åˆ°ç«¯æ¡†æ¶å®Œæ•´** | å¯ç›´æ¥å¤ç”¨è¿›è¡Œæ›´å¤šå®éªŒ |

## 5.3 è®¾è®¡å¯ç¤º

### æ¶æ„/æ–¹æ³•åŸåˆ™

| åŸåˆ™ | å»ºè®® | åŸå›  |
|------|------|------|
| **å…ˆå†»ç»“å† fine-tune** | éªŒè¯æ¡†æ¶åå†å¼€æ”¾ encoder | é¿å…ç ´åé¢„è®­ç»ƒè¡¨ç¤º |
| **ä½¿ç”¨ seg_mean_K8** | åˆ†æ®µ pooling ä¼˜äºå…¨å±€ pooling | ä¿ç•™æ³¢é•¿å±€éƒ¨ä¿¡æ¯ |
| **MLP head ä¼˜å…ˆ** | ä¼˜äºçº¿æ€§ probe | å­˜åœ¨éçº¿æ€§å…³ç³» |

### âš ï¸ å¸¸è§é™·é˜±

| å¸¸è§åšæ³• | å®éªŒè¯æ® |
|----------|----------|
| "çº¿æ€§ probe è¶³å¤Ÿ" | âŒ MLP æ¯” Ridge å¥½ 10.9% |
| "ç›´æ¥ fine-tune encoder" | åº”å…ˆéªŒè¯å†»ç»“ç‰ˆæ€§èƒ½ |

## 5.4 ç‰©ç†è§£é‡Š

- MLP head éœ€è¦å­¦ä¹ ä» encoder ç‰¹å¾åˆ° log_g çš„éçº¿æ€§æ˜ å°„
- éçº¿æ€§å¯èƒ½æ¥è‡ªï¼šlog_g å¯¹ä¸åŒå…‰è°±ç‰¹å¾çš„ç»„åˆå“åº”
- seg_mean_K8 ä¿ç•™äº†æ³¢é•¿ä½ç½®ä¿¡æ¯ï¼Œæœ‰åŠ©äºåŒºåˆ†ä¸åŒ log_g æ•æ„ŸåŒºåŸŸ

## 5.5 å…³é”®æ•°å­—é€ŸæŸ¥

| æŒ‡æ ‡ | å€¼ | é…ç½®/æ¡ä»¶ |
|------|-----|----------|
| **Test RÂ²** | **0.6117** | frozen encoder + MLP |
| Best Val RÂ² | 0.5979 | epoch 47 |
| Ridge baseline | 0.5516 | enc_pre_latent + seg_mean_K8 |
| æå‡å¹…åº¦ | **+10.9%** | MLP vs Ridge |
| ç‰¹å¾ç»´åº¦ | 384 | 48 Ã— 8 |
| å†»ç»“å‚æ•°é‡ | ~1.9M | BlindSpot encoder |
| å¯è®­ç»ƒå‚æ•° | ~99K | MLP head |
| è®­ç»ƒæ—¶é—´ | ~45 åˆ†é’Ÿ | 50 epochs |

## 5.6 ä¸‹ä¸€æ­¥å·¥ä½œ

| æ–¹å‘ | å…·ä½“ä»»åŠ¡ | ä¼˜å…ˆçº§ | å¯¹åº” MVP |
|------|----------|--------|---------|
| **Fine-tune encoder** | å¼€æ”¾ encoder è®­ç»ƒ | ğŸ”´ é«˜ | MVP-2.3 |
| **æ›´æ·± head** | æµ‹è¯• mlp_2 (2 hidden layers) | ğŸŸ¡ ä¸­ | - |
| **Multi-task** | åŒæ—¶é¢„æµ‹ log_g, Teff, [M/H] | ğŸŸ¡ ä¸­ | - |
| **Attention pooling** | æ›¿ä»£ seg_mean_K8 | ğŸŸ¢ ä½ | - |

---

# 6. ğŸ“ é™„å½•

## 6.1 ä»£ç æ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `src/logg_from_encoder.py` | LogGFromEncoderLightning + LogGHead + LogGDataModule |
| `src/blindspot.py` | BlindspotModel1D + `encode_flux()` æ¥å£ |
| `experiments/train_logg_from_encoder.py` | è®­ç»ƒè„šæœ¬ |
| `configs/logg_from_encoder.yaml` | é…ç½®æ–‡ä»¶ |

## 6.2 è¾“å‡ºæ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `evals/logg_frozen_run_v2.log` | å®Œæ•´è®­ç»ƒæ—¥å¿— |
| `evals/logg_from_encoder_results.csv` | ç»“æœ CSV |
| `checkpoints/logg_from_encoder/frozen_enc_pre_latent_seg_mean_K8_v2_epoch=47_val/r2=0.5979.ckpt` | æœ€ä½³æ¨¡å‹ |

## 6.3 å¤ç°å‘½ä»¤

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
source /datascope/slurm/miniconda3/bin/activate viska-torch-2

# 2. è¿›å…¥é¡¹ç›®ç›®å½•
cd /home/swei20/BlindSpotDenoiser

# 3. è¿è¡Œè®­ç»ƒ
python experiments/train_logg_from_encoder.py \
    --config configs/logg_from_encoder.yaml \
    --encoder-ckpt evals/m215l9e48k25s1bn1d1ep5000.ckpt \
    --freeze-encoder \
    --max-epochs 50

# 4. æŸ¥çœ‹ç»“æœ
cat evals/logg_from_encoder_results.csv
```

## 6.4 ç›¸å…³æ–‡ä»¶

| ç±»å‹ | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| ä¸»æ¡†æ¶ | `logg/distill/distill_main_20251130.md` | main æ–‡ä»¶ |
| æœ¬æŠ¥å‘Š | `logg/distill/exp_encoder_nn_logg_20251201.md` | å½“å‰æ–‡ä»¶ |
| Ridge probe | `logg/distill/exp_linear_probe_latent_20251130.md` | baseline |
| Layer pooling | `logg/distill/exp_error_info_decomposition_20251201.md` | å±‚é€‰æ‹© |

---

*æœ€åæ›´æ–°: 2025-12-01*

# ğŸ“˜ Latent æå–æ–¹å¼ä¼˜åŒ–å®éªŒï¼šæ”¹å–„ log g é¢„æµ‹

---
> **å®éªŒåç§°ï¼š** Latent Extraction Strategy for log g Improvement  
> **å¯¹åº” MVPï¼š** MVP 1.4ï¼ˆDistillation å®éªŒè®¡åˆ’ï¼‰  
> **ä½œè€…ï¼š** Viska Wei  
> **æ—¥æœŸï¼š** 2025-12-01  
> **æ•°æ®ç‰ˆæœ¬ï¼š** BOSZ åˆæˆå…‰è°±åº“ (mag215)  
> **æ¨¡å‹ç‰ˆæœ¬ï¼š** `m215l9e48k25s1bn1d1ep5000` (BlindSpot Denoiser, 5000 epochs)  
> **çŠ¶æ€ï¼š** âœ… å·²å®Œæˆ

---

## ğŸ”— ä¸Šæ¸¸è¿½æº¯é“¾æ¥ï¼ˆUpstream Linksï¼‰

| å­—æ®µ | å€¼ |
|------|-----|
| **æ¥æºä¼šè¯** | [session_20251201_distill_extraction.md](./sessions/session_20251201_distill_extraction.md) |
| **é˜Ÿåˆ—å…¥å£** | `status/kanban.md` â†’ `BS-20251201-distill-latent-01` |

---

## ğŸ”— è·¨ä»“åº“å…ƒæ•°æ®ï¼ˆCross-Repo Metadataï¼‰

| å­—æ®µ | å€¼ |
|------|-----|
| **experiment_id** | `BS-20251201-distill-latent-01` |
| **project** | `BlindSpot` |
| **topic** | `distill` |
| **source_repo_path** | `~/BlindSpotDenoiser/evals/` |
| **config_path** | `-` |
| **output_path** | `evals/layer_features_*.pt` |

---

# âš¡ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆï¼ˆä¾› main æå–ï¼‰

### ä¸€å¥è¯æ€»ç»“

> **BlindSpot latent ä¸­ç¡®å®å­˜åœ¨ä¸°å¯Œçš„ $\log g$ ä¿¡æ¯ï¼ˆ$R^2 = 0.55$ï¼‰ï¼ŒåŸæ¥çš„æå–æ–¹å¼ï¼ˆencoder\_last + mean poolingï¼‰æ˜¯ç“¶é¢ˆï¼Œé€šè¿‡åˆ‡æ¢åˆ° `enc_pre_latent + seg_mean_K8` å¯è·å¾— +150% çš„æ€§èƒ½æå‡ã€‚**

### å¯¹å‡è®¾çš„éªŒè¯

| éªŒè¯é—®é¢˜ | ç»“æœ | ç»“è®º |
|---------|------|------|
| Feature map æœ¬èº«æ˜¯å¦åŒ…å« $\log g$ ä¿¡æ¯ï¼Ÿ | âœ… **æ˜¯** | æœ€ä½³é…ç½® Test $R^2 = 0.5516$ï¼Œè¿œè¶…é˜ˆå€¼ 0.5 |
| Mean pooling æ˜¯å¦æŠ¹æ‰äº† $\log g$ ä¿¡æ¯ï¼Ÿ | âœ… **æ˜¯** | åˆ†æ®µ pooling æ¯” global mean æå‡ +77.6%ï¼ˆç›¸åŒå±‚ï¼‰ |
| å“ªä¸€å±‚å¯¹ $\log g$ ç¼–ç æœ€å¼ºï¼Ÿ | `enc_pre_latent` | æ¯” `enc_last` é«˜ +16.2%ï¼ˆç›¸åŒ poolingï¼‰ |

### è®¾è®¡å¯ç¤ºï¼ˆ1-2 æ¡ï¼‰

| å¯ç¤º | å…·ä½“å»ºè®® |
|------|---------|
| **Teacher latent åº”æ›´æ¢ä¸ºæœ€ä½³é…ç½®** | ä½¿ç”¨ `enc_pre_latent + seg_mean_K8` ä½œä¸ºæ–°çš„ Teacher latent |
| **æ³¢é•¿å±€éƒ¨æ€§å¯¹ $\log g$ è‡³å…³é‡è¦** | $\log g$ ä¿¡æ¯ï¼ˆå‹åŠ›å¢å®½ï¼‰é›†ä¸­åœ¨ç‰¹å®šæ³¢æ®µï¼Œéœ€è¦ä¿ç•™ç©ºé—´ç»“æ„ |

### å…³é”®æ•°å­—

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| æœ€ä½³ $\log g$ Test $R^2$ | **0.5516** |
| æœ€ä½³æå–å±‚ | `enc_pre_latent`ï¼ˆencoder æœ€åä¸€å±‚çš„è¾“å…¥ï¼‰ |
| æœ€ä½³ pooling ç­–ç•¥ | `seg_mean_K8`ï¼ˆåˆ†æ®µ meanï¼ŒK=8ï¼Œ384 ç»´ï¼‰ |
| ç›¸å¯¹ Baseline æå‡ | **+150%**ï¼ˆ0.2202 â†’ 0.5516ï¼‰ |
| å±‚é€‰æ‹©è´¡çŒ® | +16.2%ï¼ˆ`enc_pre_latent` vs `enc_last`ï¼‰ |
| Pooling é€‰æ‹©è´¡çŒ® | +77.6%ï¼ˆ`seg_mean_K8` vs `global_mean`ï¼‰ |

---

# ğŸ“‘ ç›®å½•

- [1. ğŸ¯ ç›®æ ‡](#1--ç›®æ ‡)
- [2. ğŸ§ª å®éªŒè®¾è®¡](#2--å®éªŒè®¾è®¡)
- [3. ğŸ“Š å®éªŒç»“æœ](#3--å®éªŒç»“æœ)
- [4. ğŸ’¡ å…³é”®æ´è§](#4--å…³é”®æ´è§)
- [5. ğŸ“ ç»“è®º](#5--ç»“è®º)
- [6. ğŸ“ é™„å½•](#6--é™„å½•)

---

# 1. ğŸ¯ ç›®æ ‡

## 1.1 èƒŒæ™¯ä¸åŠ¨æœº

### é—®é¢˜å›é¡¾

åœ¨ MVP 1.1 å®éªŒä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼š
- **å…¨å±€å‚æ•°**ï¼ˆ$T_{\text{eff}}$, [M/H]ï¼‰ï¼š$R^2 > 0.95$ï¼Œé€šè¿‡ mean pooling + linear/LightGBM å³å¯é«˜ç²¾åº¦é¢„æµ‹
- **$\log g$**ï¼š$R^2 \approx 0.28$ï¼ˆLightGBMï¼‰ï¼Œè¿œä½äºé¢„æœŸ

### æ ¸å¿ƒç–‘é—®

> **"æ²¡æœ‰ $\log g$ ä¿¡æ¯ï¼Œæ˜¯æ€ä¹ˆåšåˆ°èƒ½å®Œå…¨é™å™ªçš„ï¼Ÿ"**

è¿™ä¸ªé—®é¢˜å®é™…ä¸Šæ··æ·†äº†ä¸¤ä»¶äº‹ï¼š

1. **ä¿¡æ¯æ˜¯å¦å­˜åœ¨äºè¡¨ç¤ºé‡Œ**ï¼ˆinformation-theoreticï¼‰
2. **æˆ‘ä»¬èƒ½ä¸èƒ½ç”¨ç®€å•çš„ decoder æŠŠå®ƒè¯»å‡ºæ¥**ï¼ˆdecodabilityï¼‰

MVP 1.1 åªè¯æ˜äº†ã€Œ**çº¿æ€§ + ç²—ç³™ pooling çš„ 48-d å‘é‡ä¸‹ï¼Œ$\log g$ ä¸å¥½è§£ç **ã€ï¼Œä½†**æ²¡æœ‰**è¯æ˜ã€ŒBlindSpot ä¸­é—´å±‚æ ¹æœ¬æ²¡è§è¿‡ $\log g$ ç›¸å…³ç»“æ„ã€ã€‚

### ä¸ºä»€ä¹ˆä¸çŸ›ç›¾ï¼Ÿ

**ä»å»å™ªå™¨æœ€ä¼˜è§£çš„è§’åº¦**ï¼š

$$
\hat{x}(\lambda) = \mathbb{E}[x_{\text{clean}}(\lambda) \mid x_{\text{noisy}}, \sigma]
$$

- ç½‘ç»œå­¦çš„æ˜¯**å±€éƒ¨æ¡ä»¶åˆ†å¸ƒ**ï¼Œä¸éœ€è¦æ˜¾å¼å½¢æˆä¸€ä¸ª $\log g$ æ ‡é‡
- ä¿¡æ¯ä»¥ã€Œå±€éƒ¨ pattern + å…¨å±€ä¸Šä¸‹æ–‡ã€çš„å½¢å¼å­˜åœ¨
- ä½†**æœªå¿…å‹ç¼©æˆä¸€ä¸ª"çº¿æ€§å¥½è§£ç çš„ $\log g$ å‘é‡"**

**ç±»æ¯”**ï¼šå›¾åƒå»å™ªæ¨¡å‹å¯ä»¥å®Œç¾æ¢å¤äººè„¸ï¼Œä½†å†…éƒ¨ä¸ä¸€å®šæœ‰æ˜¾å¼çš„ã€Œå¹´é¾„=23ã€æ ‡é‡ã€‚

### å½“å‰ probe çš„å±€é™æ€§

å½“å‰è®¾ç½®å¯¹ $\log g$ **éå¸¸ä¸å‹å¥½**ï¼š

| è®¾ç½® | é—®é¢˜ |
|------|------|
| `encoder_last` | æœ€åä¸€å±‚å¯èƒ½è¿‡åº¦"å…‰æ»‘åŒ–"ï¼Œä¸¢å¤±å±€éƒ¨ç»“æ„ |
| `mean pooling` | å¯¹æ³¢é•¿è½´åšå…¨å±€å¹³å‡ï¼ŒæŠ¹å¹³äº†å±€éƒ¨å·®å¼‚ |
| 48 ç»´å‘é‡ | ç»´åº¦å¤ªä½ï¼Œçº¿æ€§æ¨¡å‹èƒ½æŠ“åˆ°çš„ä¸œè¥¿æœ‰é™ |

**$\log g$ çš„ç‰©ç†ä¿¡æ¯è½½ä½“**ï¼š
- ä¸»è¦åœ¨**å±€éƒ¨çº¿ç¿¼**ï¼ˆBalmer wingsã€Ca II tripletï¼‰
- ä¾èµ–**ç‰¹å®šçº¿çš„ shape / å®½åº¦ / å¾®ç»†ç»“æ„**
- Mean pooling æŠŠè¿™äº›å…³é”®ä¿¡æ¯å¹³å‡æ‰äº†

## 1.2 æ ¸å¿ƒå‡è®¾

> **$\log g$ ä¿¡æ¯å­˜åœ¨äº BlindSpot çš„ä¸­é—´è¡¨ç¤ºä¸­ï¼Œä½†å½“å‰çš„æå–æ–¹å¼ï¼ˆencoder_last + mean poolingï¼‰å¯¹ $\log g$ ä¸å‹å¥½ï¼Œå¯¼è‡´ä¿¡æ¯è¢«æŠ¹æ‰ã€‚**

å¦‚æœå‡è®¾æˆç«‹ï¼š
- é€šè¿‡æ”¹å˜æå–å±‚æˆ– pooling ç­–ç•¥ï¼Œ$\log g$ $R^2$ å¯ä»¥æ˜¾è‘—æå‡ï¼ˆ0.28 â†’ 0.4+ï¼‰
- Teacher latent åº”è¯¥æ¢æˆã€Œ$\log g$ å‹å¥½ç‰ˆ latentã€

å¦‚æœå‡è®¾ä¸æˆç«‹ï¼š
- æ— è®ºæ€ä¹ˆæ¢ layer / poolingï¼Œ$\log g$ $R^2$ éƒ½å¡åœ¨ ~0.3
- è¯´æ˜åœ¨å½“å‰ BSD æ¶æ„ + è®­ç»ƒç›®æ ‡ä¸‹ï¼Œlatent é‡Œ $\log g$ ä¿¡æ¯ç¡®å®æœ‰é™
- ä¸å»ºè®®åœ¨ã€Œä¸æ”¹ BSDã€çš„å‰æä¸‹é‡ä»“è’¸é¦

## 1.3 éªŒè¯é—®é¢˜

| # | é—®é¢˜ | éªŒè¯ç›®æ ‡ | é¢„æœŸç»“æœ |
|---|------|---------|---------|
| Q1 | å“ªä¸€å±‚å¯¹ $\log g$ ç¼–ç æœ€å¼ºï¼Ÿ | Layer-wise probe | ä¸­é—´å±‚å¯èƒ½ > encoder_last |
| Q2 | Mean+Max pooling èƒ½å¦æ•æ‰å±€éƒ¨æå€¼ï¼Ÿ | Pooling å¯¹æ¯” | $\log g$ $R^2$ æå‡ |
| Q3 | åˆ†æ®µ pooling èƒ½å¦ä¿ç•™æ³¢æ®µä¿¡æ¯ï¼Ÿ | åˆ†æ®µæ•° K æ‰«æ | $\log g$ $R^2$ æå‡ |
| Q4 | encoder_mid æ˜¯å¦æ¯” encoder_last æ›´å¥½ï¼Ÿ | å±‚çº§å¯¹æ¯” | éªŒè¯ H1 |
| Q5 | ä¸åŒå‚æ•°çš„æœ€ä¼˜å±‚æ˜¯å¦ä¸åŒï¼Ÿ | å¤šå‚æ•°å¯¹æ¯” | Teff/[M/H] vs $\log g$ å¯èƒ½ä¸åŒ |

## 1.4 ç»“è®ºæ‘˜è¦

> **âœ… å‡è®¾éªŒè¯æˆåŠŸ**ï¼š$\log g$ ä¿¡æ¯ç¡®å®å­˜åœ¨äº BlindSpot feature map ä¸­ï¼Œé€šè¿‡ä¼˜åŒ–æå–æ–¹å¼ï¼ˆ`enc_pre_latent + seg_mean_K8`ï¼‰ï¼Œ$R^2$ ä» 0.22 æå‡åˆ° **0.55**ï¼ˆ+150%ï¼‰ï¼Œè¾¾åˆ°äº†è’¸é¦å¯è¡Œçš„é˜ˆå€¼ã€‚

---

# 2. ğŸ§ª å®éªŒè®¾è®¡

## 2.1 æ•°æ®ï¼ˆDataï¼‰

- **æ•°æ®æ¥æº**ï¼šBOSZ åˆæˆå…‰è°±åº“ (mag215)
- **è®­ç»ƒæ ·æœ¬æ•°**ï¼š100,000
- **æµ‹è¯•æ ·æœ¬æ•°**ï¼š1,000ï¼ˆç‹¬ç«‹æµ‹è¯•é›†ï¼‰
- **ç‰¹å¾ç»´åº¦**ï¼šå˜åŒ–ï¼ˆå–å†³äº pooling ç­–ç•¥ï¼‰
- **æ ‡ç­¾å‚æ•°**ï¼š$\log g$ï¼ˆä¸»è¦ï¼‰ï¼Œ$T_{\text{eff}}$, [M/H]ï¼ˆå¯¹ç…§ï¼‰

| æ•°æ®é›† | è·¯å¾„ | æ ·æœ¬æ•° |
|--------|------|--------|
| è®­ç»ƒé›† | `evals/latent_probe_train_100k.pt` | 100,000 |
| æµ‹è¯•é›† | `evals/latent_probe_test_1k.pt` | 1,000 |

## 2.2 å®éªŒå˜ä½“è®¾è®¡

### å˜ä½“æ¦‚è§ˆ

| ID | æå–å±‚ | Pooling ç­–ç•¥ | è¾“å‡ºç»´åº¦ | ç›´è§‰ |
|----|--------|-------------|----------|------|
| **V0** | encoder_last | mean | 48 | **Baseline**ï¼ˆå½“å‰è®¾ç½®ï¼‰ |
| **V1** | encoder_mid | mean | 48 | ä¸­é—´å±‚å¯èƒ½ä¿ç•™æ›´å¤šå±€éƒ¨ç»“æ„ |
| **V2** | encoder_last | mean+max concat | 96 | Max æ•æ„Ÿäºå±€éƒ¨æå€¼ï¼ˆçº¿å¿ƒæ·±åº¦ï¼‰ |
| **V3** | encoder_last | åˆ†æ®µ mean (K=8) | 384 | ä¿ç•™ç²—ç•¥æ³¢æ®µä¿¡æ¯ |
| **V4** | encoder_last | åˆ†æ®µ mean (K=16) | 768 | æ›´ç»†çš„æ³¢æ®µåˆ†è¾¨ç‡ |
| **V5** | all layers | mean | 48Ã—9=432 | å¤šå±‚èåˆ |

### V1: encoder_mid + mean pooling

**è®¾è®¡æ€è·¯**ï¼š
- ä¸­é—´å±‚å¯èƒ½ä¿ç•™æ›´å¤šå±€éƒ¨ç»“æ„
- encoder_last æ›´åå‘"å»å™ª + å…‰æ»‘"
- å¯¹äº 9 å±‚ encoderï¼Œmid é€‰ç¬¬ 4 æˆ– 5 å±‚

**å®ç°**ï¼š
```python
# å‡è®¾ encoder æœ‰ 9 å±‚ (0-8)
encoder_mid_idx = 4  # æˆ– 5
latent_mid = encoder.blocks[encoder_mid_idx].output
pooled_mid = latent_mid.mean(dim=-1)  # (B, C)
```

### V2: encoder_last + mean+max pooling

**è®¾è®¡æ€è·¯**ï¼š
- Mean pooling æ•æ‰å…¨å±€è¶‹åŠ¿
- Max pooling å¯¹å±€éƒ¨æå€¼ï¼ˆæŸä¸ªçº¿å¿ƒéå¸¸æ·±/æµ…ï¼‰æ›´æ•æ„Ÿ
- ä¸¤è€…æ‹¼æ¥å¯èƒ½äº’è¡¥

**å®ç°**ï¼š
```python
latent = encoder_last  # (B, C, L)
pooled_mean = latent.mean(dim=-1)  # (B, C)
pooled_max = latent.max(dim=-1).values  # (B, C)
pooled_concat = torch.cat([pooled_mean, pooled_max], dim=-1)  # (B, 2*C)
```

**è¾“å‡ºç»´åº¦**ï¼š48 Ã— 2 = 96

### V3 & V4: encoder_last + åˆ†æ®µ mean pooling

**è®¾è®¡æ€è·¯**ï¼š
- æŠŠæ³¢é•¿è½´åˆ†æˆ K ä¸ªæ®µ
- æ¯æ®µå¯¹ 48 channel åš mean pooling
- ä¿ç•™ã€Œä¸åŒæ³¢æ®µã€çš„ç²—ç•¥ä¿¡æ¯ï¼Œå¯¹ $\log g$ å¯èƒ½æ›´å‹å¥½

**å®ç°**ï¼š
```python
K = 8  # æˆ– 16
latent = encoder_last  # (B, C, L)
L = latent.shape[-1]
segment_size = L // K

segments = []
for i in range(K):
    start = i * segment_size
    end = (i + 1) * segment_size if i < K - 1 else L
    segment_mean = latent[:, :, start:end].mean(dim=-1)  # (B, C)
    segments.append(segment_mean)

pooled_segmented = torch.cat(segments, dim=-1)  # (B, C*K)
```

**è¾“å‡ºç»´åº¦**ï¼š
- K=8: 48 Ã— 8 = 384
- K=16: 48 Ã— 16 = 768

### V5: å¤šå±‚èåˆ

**è®¾è®¡æ€è·¯**ï¼š
- å¯¹æ‰€æœ‰ 9 å±‚éƒ½åš mean pooling
- æ‹¼æ¥æˆä¸€ä¸ªå¤§å‘é‡
- è®©æ¨¡å‹è‡ªå·±å­¦ä¹ å“ªäº›å±‚å¯¹ $\log g$ æœ‰ç”¨

**å®ç°**ï¼š
```python
all_pooled = []
for i, block in enumerate(encoder.blocks):
    block_output = activations[f"layer{i}"]  # (B, C, L)
    pooled = block_output.mean(dim=-1)  # (B, C)
    all_pooled.append(pooled)

multi_layer_latent = torch.cat(all_pooled, dim=-1)  # (B, C*num_layers)
```

**è¾“å‡ºç»´åº¦**ï¼š48 Ã— 9 = 432

## 2.3 Layer-wise Probeï¼ˆé€å±‚è¯Šæ–­ï¼‰

### ç›®çš„

åœ¨æµ‹è¯•ä¸Šè¿°å˜ä½“ä¹‹å‰ï¼Œå…ˆåšä¸€ä¸ª**å…¨é¢çš„é€å±‚è¯Šæ–­**ï¼š
- å¯¹æ‰€æœ‰ 9 å±‚åˆ†åˆ«åš probe
- çœ‹ $\log g$ ä¿¡æ¯åœ¨å“ªäº›å±‚æœ€å¼º
- ä¸ºåç»­å˜ä½“é€‰æ‹©æä¾›ä¾æ®

### å®ç°æµç¨‹

```
Step 1: æ·»åŠ  forward hooks è®°å½•æ¯å±‚æ¿€æ´»
        â†“
Step 2: å¯¹æ¯å±‚åš mean pooling â†’ 48 ç»´å‘é‡
        â†“
Step 3: æ¯å±‚å•ç‹¬è·‘ Ridge/LightGBM probe
        â†“
Step 4: ç»˜åˆ¶ "RÂ² vs layer index" æ›²çº¿
```

### Hook å®ç°

```python
activations = {}

def save_activation(name):
    def hook(m, inp, out):
        activations[name] = out.detach()
    return hook

for i, block in enumerate(encoder.blocks):
    block.register_forward_hook(save_activation(f"layer{i}"))
```

### é¢„æœŸç»“æœæ¨¡å¼

| æ¨¡å¼ | $\log g$ æ›²çº¿ | å«ä¹‰ |
|------|--------------|------|
| **A** | ä¸­é—´å±‚ > æœ€åä¸€å±‚ | åå‡ å±‚åœ¨"æŠ¹å¹³" $\log g$ï¼Œåº”é€‰ä¸­é—´å±‚ |
| **B** | æ‰€æœ‰å±‚éƒ½ä½ | æ¶æ„æœ¬èº«å¯¹ $\log g$ ä¸æ•æ„Ÿï¼Œéœ€æ”¹è®­ç»ƒç›®æ ‡ |
| **C** | æœ€åä¸€å±‚æœ€é«˜ | å½“å‰è®¾ç½®å·²æ˜¯æœ€ä¼˜ï¼Œé—®é¢˜åœ¨ pooling |

## 2.4 æ¨¡å‹ä¸ç®—æ³•

### Probe æ¨¡å‹

ç»Ÿä¸€ä½¿ç”¨ä¸¤ç§ probeï¼š

1. **Ridge å›å½’**ï¼š`Ridge(alpha=0.001, normalize=True)`
   - å¿«é€Ÿã€ç¨³å®š
   - ä½œä¸º baseline

2. **LightGBM**ï¼š`num_leaves=15, n_estimators=50`
   - æ•æ‰éçº¿æ€§ä¿¡å·
   - åœ¨ 100k æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½

### è¯„ä¼°æŒ‡æ ‡

| æŒ‡æ ‡ | å…¬å¼ | è¯´æ˜ |
|------|------|------|
| $R^2$ | $1 - \frac{SS_{res}}{SS_{tot}}$ | ä¸»è¦æŒ‡æ ‡ |
| MAE | $\frac{1}{n}\sum\|y_i - \hat{y}_i\|$ | ç‰©ç†å¯è§£é‡Š |
| RMSE | $\sqrt{\frac{1}{n}\sum(y_i - \hat{y}_i)^2}$ | è¾…åŠ©æŒ‡æ ‡ |

## 2.5 è¶…å‚æ•°

### å®éªŒé…ç½®

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| è®­ç»ƒæ ·æœ¬ | 100,000 | ä½¿ç”¨å®Œæ•´è®­ç»ƒé›† |
| æµ‹è¯•æ ·æœ¬ | 1,000 | ç‹¬ç«‹æµ‹è¯•é›† |
| Ridge Î± | 0.001 | è½»æ­£åˆ™åŒ– |
| LightGBM leaves | 15 | ä¿å®ˆé…ç½® |
| LightGBM trees | 50 | é˜²è¿‡æ‹Ÿåˆ |
| åˆ†æ®µæ•° K | 8, 16 | ä¸¤ç§ç²’åº¦ |

### å±‚çº§é€‰æ‹©

| å±‚çº§ | ç´¢å¼• | è¯´æ˜ |
|------|------|------|
| encoder_first | 0 | ç¬¬ä¸€å±‚ |
| encoder_mid | 4 | ä¸­é—´å±‚ |
| encoder_last | 8 | æœ€åä¸€å±‚ï¼ˆå½“å‰é»˜è®¤ï¼‰ |

---

# 3. ğŸ“Š å®éªŒç»“æœ

## 3.1 Layer Ã— Pooling å®Œæ•´æ‰«æç»“æœ

### 3.1.1 å®Œæ•´ç»“æœè¡¨ï¼ˆRidge Regression, Î±=0.001ï¼‰

æœ¬å®éªŒé‡‡ç”¨ç²—æ‰«æç­–ç•¥ï¼Œæµ‹è¯• 3 ä¸ªå±‚ Ã— 3 ç§ pooling ç­–ç•¥ = **9 ç§é…ç½®**ï¼š

| Layer | Pooling | Dim | Train $R^2$ | **Test $R^2$** | Test MAE | Test RMSE |
|-------|---------|-----|------------|----------------|----------|-----------|
| enc\_pre\_latent | global\_mean | 48 | 0.3919 | **0.3106** | 0.8225 | 0.9909 |
| enc\_pre\_latent | mean\_max | 96 | 0.4638 | **0.4056** | 0.7499 | 0.9201 |
| **enc\_pre\_latent** | **seg\_mean\_K8** | **384** | **0.5861** | **0.5516** | **0.6340** | **0.7991** |
| enc\_last | global\_mean | 48 | 0.2488 | 0.2202 | 0.8921 | 1.0538 |
| enc\_last | mean\_max | 96 | 0.3266 | 0.2886 | 0.8326 | 1.0066 |
| enc\_last | seg\_mean\_K8 | 384 | 0.5335 | 0.4748 | 0.6872 | 0.8649 |
| dec\_input | global\_mean | 48 | 0.2488 | 0.2202 | 0.8921 | 1.0538 |
| dec\_input | mean\_max | 96 | 0.3266 | 0.2886 | 0.8326 | 1.0066 |
| dec\_input | seg\_mean\_K8 | 384 | 0.5335 | 0.4748 | 0.6872 | 0.8649 |

> **æ³¨**ï¼š`dec_input` ä¸ `enc_last` åœ¨æ­¤ UNet æ¶æ„ä¸­æ˜¯åŒä¸€ä¸ªå¼ é‡ï¼Œå› æ­¤ç»“æœå®Œå…¨ç›¸åŒã€‚

### 3.1.2 å±‚çº§æ•ˆåº”åˆ†æï¼ˆå›ºå®š seg\_mean\_K8ï¼‰

| å±‚ | æè¿° | Test $R^2$ | ç›¸å¯¹ enc\_last |
|----|------|------------|----------------|
| `enc_pre_latent` | Encoder æœ€åä¸€å±‚çš„**è¾“å…¥** | **0.5516** | **+16.2%** |
| `enc_last` | Encoder æœ€åä¸€å±‚çš„**è¾“å‡º** | 0.4748 | baseline |

**å…³é”®è§‚å¯Ÿ**ï¼š
- `enc_pre_latent` > `enc_last`ï¼šæœ€åä¸€å±‚çš„å·ç§¯å¹³æ»‘æ“ä½œæŸå¤±äº†éƒ¨åˆ† $\log g$ ä¿¡æ¯
- $\log g$ ç›¸å…³çš„ç²¾ç»†è°±çº¿ç»“æ„åœ¨ç»è¿‡æœ€åä¸€å±‚åè¢«"æ¨¡ç³ŠåŒ–"

### 3.1.3 Pooling æ•ˆåº”åˆ†æï¼ˆå›ºå®š enc\_pre\_latentï¼‰

| Pooling | æè¿° | ç»´åº¦ | Test $R^2$ | ç›¸å¯¹ global\_mean |
|---------|------|------|------------|-------------------|
| `global_mean` | å…¨å±€å¹³å‡ | 48 | 0.3106 | baseline |
| `mean_max` | å¹³å‡+æœ€å¤§æ‹¼æ¥ | 96 | 0.4056 | **+30.6%** |
| `seg_mean_K8` | åˆ†æ®µå¹³å‡ (K=8) | 384 | **0.5516** | **+77.6%** |

**å…³é”®è§‚å¯Ÿ**ï¼š
- åˆ†æ®µ pooling æ˜¾è‘—ä¼˜äºå…¨å±€ poolingï¼ˆ+77.6%ï¼‰
- Mean+Max æ‹¼æ¥ä¹Ÿæœ‰æ˜æ˜¾æå‡ï¼ˆ+30.6%ï¼‰ï¼Œä½†ä¸å¦‚åˆ†æ®µ pooling
- **æ³¢é•¿å±€éƒ¨æ€§**æ˜¯ $\log g$ é¢„æµ‹çš„å…³é”®

## 3.2 æ•ˆåº”åˆ†è§£

### å±‚é€‰æ‹© vs Pooling é€‰æ‹©çš„è´¡çŒ®

| å¯¹æ¯”é¡¹ | Baseline é…ç½® | æ”¹è¿›é…ç½® | æå‡å¹…åº¦ |
|--------|--------------|----------|----------|
| **ä»…æ”¹å˜å±‚** | enc\_last + seg\_mean\_K8 (0.4748) | enc\_pre\_latent + seg\_mean\_K8 (0.5516) | **+16.2%** |
| **ä»…æ”¹å˜ pooling** | enc\_pre\_latent + global\_mean (0.3106) | enc\_pre\_latent + seg\_mean\_K8 (0.5516) | **+77.6%** |
| **åŒæ—¶æ”¹å˜** | enc\_last + global\_mean (0.2202) | enc\_pre\_latent + seg\_mean\_K8 (0.5516) | **+150%** |

**ç»“è®º**ï¼šPooling ç­–ç•¥çš„æ”¹è¿›è´¡çŒ®è¿œå¤§äºå±‚é€‰æ‹©çš„è´¡çŒ®ã€‚

## 3.3 å†³ç­–é€»è¾‘éªŒè¯

### éªŒæ”¶æ ‡å‡†æ£€æŸ¥

| æ¡ä»¶ | é˜ˆå€¼ | å®é™…å€¼ | ç»“æœ |
|------|------|--------|------|
| æœ€ä½³ Test $R^2(\log g) \geq 0.5$ | 0.5 | **0.5516** | âœ… **é€šè¿‡** |

### ç»“è®º

âœ… **æ­£å‘ç»“æœ**ï¼šBest Test $R^2(\log g) = 0.5516 \geq 0.5$

è¿™ç¡®è®¤äº†ï¼š
1. **BlindSpot feature maps ç¡®å®åŒ…å«æ˜¾è‘—çš„ $\log g$ ä¿¡æ¯**
2. åŸæ¥çš„æå–æ–¹æ³•ï¼ˆ`enc_last + global_mean`ï¼‰å¤ªè¿‡ç²—ç³™
3. $\log g$ ä¿¡æ¯**å¹¶é**å†…åœ¨ç¼ºå¤±äºç½‘ç»œä¸­

---
# 4. ğŸ’¡ å…³é”®æ´è§

## 4.1 å®è§‚å±‚æ´è§

### æ ¸å¿ƒå‘ç°ï¼šFeature Map ä¸­å­˜åœ¨ $\log g$ ä¿¡æ¯

âœ… **å‡è®¾éªŒè¯æˆåŠŸ**ï¼š$\log g$ $R^2$ ä» ~0.22 æå‡åˆ° **0.55**ï¼ˆ+150%ï¼‰ï¼Œè¾¾åˆ°äº†é¢„è®¾çš„ 0.5 é˜ˆå€¼ã€‚

è¿™æ„å‘³ç€ï¼š
1. **Feature map é‡Œç¡®å®æœ‰ $\log g$ ä¿¡æ¯**ï¼Œåªæ˜¯åŸæ¥çš„ pooling å¤ªç²—ç³™
2. **å¯¹ Teacherâ€“Student è’¸é¦çš„å¯ç¤º**ï¼šTeacher çš„ç›®æ ‡ latent åº”è¯¥æ¢æˆã€Œ$\log g$ å‹å¥½ç‰ˆ latentã€
3. è’¸é¦æ–¹æ¡ˆå€¼å¾—ç»§ç»­æŠ•å…¥

### ç‰©ç†è§£é‡Š

**ä¸ºä»€ä¹ˆ `enc_pre_latent` > `enc_last`ï¼Ÿ**

- `enc_last` å±‚åº”ç”¨äº†é¢å¤–çš„å·ç§¯å¹³æ»‘ï¼ˆå¸®åŠ©é‡å»º/å»å™ªï¼‰
- ä½†è¿™ç§å¹³æ»‘**ç ´åäº†è°±çº¿çš„ç²¾ç»†ç»“æ„**
- $\log g$ ä¿¡æ¯ï¼ˆå¦‚ Ca II tripletã€Balmer wings çš„å‹åŠ›å¢å®½ï¼‰ä¾èµ–è¿™äº›ç²¾ç»†ç»“æ„

**ä¸ºä»€ä¹ˆ `seg_mean_K8` >> `global_mean`ï¼Ÿ**

- $\log g$ æ•æ„Ÿç‰¹å¾ï¼ˆå¦‚å‹åŠ›å¢å®½ï¼‰æ˜¯**æ³¢é•¿å±€éƒ¨åŒ–**çš„
- `global_mean` æŠŠæ‰€æœ‰æ³¢é•¿å¹³å‡ â†’ ä¸¢å¤±å±€éƒ¨æ€§
- `seg_mean_K8` ä¿ç•™äº†**ç²—ç•¥çš„æ³¢æ®µç»“æ„** â†’ ä¿ç•™ $\log g$ ä¿¡æ¯

## 4.2 æ¨¡å‹å±‚æ´è§

### è®¾è®¡å¯ç¤º

| å±‚é¢ | å‘ç° | å»ºè®® |
|------|------|------|
| **å±‚é€‰æ‹©** | `enc_pre_latent` ä¼˜äº `enc_last` | Teacher latent åº”ä» bottleneck å‰å– |
| **Pooling** | åˆ†æ®µ pooling æ˜¾è‘—ä¼˜äºå…¨å±€ | ä¿ç•™æ³¢é•¿å±€éƒ¨æ€§æ˜¯å…³é”® |
| **ç»´åº¦** | 384 ç»´ï¼ˆ48Ã—8ï¼‰è¶³å¤Ÿæœ‰æ•ˆ | æ— éœ€æ›´é«˜ç»´åº¦ï¼ˆK=16 æœªæµ‹è¯•ï¼‰ |

### ä¿¡æ¯æµåˆ†æ

```
Input Spectrum (4096 dim)
    â†“
Encoder Layers (ä¿ç•™å±€éƒ¨ç»“æ„)
    â†“
enc_pre_latent â† ğŸ¯ æœ€ä½³å–æ ·ç‚¹ (RÂ²=0.55)
    â†“
Final Conv (å¹³æ»‘/æ¨¡ç³ŠåŒ–)
    â†“
enc_last â† å½“å‰ baseline (RÂ²=0.22)
    â†“
Decoder (é‡å»º)
```

## 4.3 å®éªŒå±‚ç»†èŠ‚æ´è§

### æ„å¤–å‘ç°

1. **dec_input â‰¡ enc_last**ï¼šåœ¨æ­¤ UNet æ¶æ„ä¸­ï¼Œdecoder è¾“å…¥å°±æ˜¯ encoder æœ€åä¸€å±‚è¾“å‡ºï¼Œæ— éœ€é¢å¤–æµ‹è¯•

2. **Mean+Max æœ‰æ•ˆä½†ä¸å¤Ÿ**ï¼š+30.6% æå‡è¯´æ˜ max pooling èƒ½æ•æ‰ä¸€äº›æå€¼ä¿¡æ¯ï¼Œä½†ä¸å¦‚ä¿ç•™ç©ºé—´ç»“æ„

3. **æ— æ˜æ˜¾è¿‡æ‹Ÿåˆ**ï¼šTrain $R^2$ (0.59) ä¸ Test $R^2$ (0.55) å·®è·è¾ƒå°ï¼Œ384 ç»´ç‰¹å¾åœ¨ 100k æ ·æœ¬ä¸‹æ³›åŒ–è‰¯å¥½

---

# 5. ğŸ“ ç»“è®º

## 5.1 æ ¸å¿ƒå‘ç°

> **BlindSpot latent ä¸­å­˜åœ¨ä¸°å¯Œçš„ $\log g$ ä¿¡æ¯ï¼ˆTest $R^2 = 0.55$ï¼‰ï¼Œé€šè¿‡ä¼˜åŒ–æå–æ–¹å¼å¯è·å¾— +150% çš„æ€§èƒ½æå‡ï¼Œè’¸é¦æ–¹æ¡ˆå€¼å¾—ç»§ç»­æ¨è¿›ã€‚**

## 5.2 å…³é”®ç»“è®º

| # | ç»“è®º | è¯æ® |
|---|------|------|
| 1 | **$\log g$ ä¿¡æ¯å­˜åœ¨äº feature map ä¸­** | æœ€ä½³é…ç½®è¾¾åˆ° Test $R^2 = 0.5516$ï¼Œè¿œè¶…é˜ˆå€¼ 0.5 |
| 2 | **åŸæå–æ–¹æ³•æ˜¯ä¸»è¦ç“¶é¢ˆ** | `enc_last + global_mean` ä»… $R^2 = 0.22$ï¼Œ+150% æå‡ |
| 3 | **Pooling ç­–ç•¥è´¡çŒ®æœ€å¤§** | Pooling æ”¹è¿›è´¡çŒ® +77.6%ï¼Œå±‚é€‰æ‹©è´¡çŒ® +16.2% |
| 4 | **æ³¢é•¿å±€éƒ¨æ€§æ˜¯å…³é”®** | åˆ†æ®µ pooling ä¿ç•™ç©ºé—´ç»“æ„ï¼Œæ˜¾è‘—æå‡ $\log g$ é¢„æµ‹ |

## 5.3 è®¾è®¡å¯ç¤º

### å¯¹ Teacherâ€“Student è’¸é¦çš„å»ºè®®

| å†³ç­– | å»ºè®® |
|------|------|
| **Teacher latent é…ç½®** | âœ… ä½¿ç”¨ `enc_pre_latent + seg_mean_K8`ï¼ˆ384 ç»´ï¼‰ |
| **æ˜¯å¦ç»§ç»­è’¸é¦** | âœ… æ˜¯ï¼ŒTeacher latent å·²è¾¾ $R^2 = 0.55$ï¼Œæœ‰è¶³å¤Ÿä¸Šé™ |
| **Student è®¾è®¡** | Student éœ€è¦å­¦ä¹  384 ç»´ç›®æ ‡ï¼ˆæ¯”åŸ 48 ç»´æ›´å¤§ï¼‰ |

### æ¨èçš„ Latent æå–é…ç½®

| ç›®æ ‡å‚æ•° | æ¨èå±‚ | æ¨è Pooling | ç»´åº¦ |
|----------|--------|-------------|------|
| $\log g$ | `enc_pre_latent` | `seg_mean_K8` | 384 |
| $T_{\text{eff}}$, [M/H] | `enc_last` | `global_mean` | 48 |

> **æ³¨**ï¼šå…¨å±€å‚æ•°ï¼ˆ$T_{\text{eff}}$, [M/H]ï¼‰å¯¹ pooling ä¸æ•æ„Ÿï¼Œå¯ç»§ç»­ä½¿ç”¨ç®€å•é…ç½®

## 5.4 ä¸‹ä¸€æ­¥å·¥ä½œ

| æ–¹å‘ | å…·ä½“ä»»åŠ¡ | ä¼˜å…ˆçº§ |
|------|----------|--------|
| **æ›´æ–° Teacher latent** | å°†è’¸é¦å®éªŒçš„ Teacher æ¢æˆæœ€ä½³é…ç½® | ğŸ”¥ é«˜ |
| **æµ‹è¯•æ›´ç»†åˆ†æ®µ** | å°è¯• K=16 æˆ– K=32ï¼Œçœ‹æ˜¯å¦è¿›ä¸€æ­¥æå‡ | ä¸­ |
| **å¤šå‚æ•°è”åˆ** | æµ‹è¯•æœ€ä½³é…ç½®å¯¹å…¶ä»–å‚æ•°çš„å½±å“ | ä¸­ |
| **å¼€å§‹ MVP 2.1** | Student è’¸é¦å®éªŒï¼ˆæ–° Teacher latentï¼‰ | ğŸ”¥ é«˜ |

---

# 6. ğŸ“ é™„å½•

## 6.1 å®éªŒé…ç½®

### æ¨¡å‹ä¸æ£€æŸ¥ç‚¹

| é¡¹ç›® | å€¼ |
|------|-----|
| æ¨¡å‹ | BlindSpotModel1D (UNet-based) |
| é…ç½® | `configs/blindspot_100k.yaml` |
| æ£€æŸ¥ç‚¹ | `evals/m215l9e48k25s1bn1d1ep5000.ckpt` |
| num_layers | 9 |
| embed_dim | 48 |
| kernel_size | 25 |

### æ•°æ®

| é¡¹ç›® | å€¼ |
|------|-----|
| è®­ç»ƒé›† | 100,000 samples |
| æµ‹è¯•é›† | 1,000 samples (ç‹¬ç«‹) |
| æ•°æ®æº | BOSZ åˆæˆå…‰è°±åº“ (mag215) |

### Probe æ¨¡å‹

| é¡¹ç›® | å€¼ |
|------|-----|
| ç±»å‹ | Ridge Regression |
| æ­£åˆ™åŒ– | Î± = 0.001 |
| ç‰¹å¾æ ‡å‡†åŒ– | StandardScaler |

## 6.2 æ–‡ä»¶äº§ç‰©

| æ–‡ä»¶ | å¤§å° | æè¿° |
|------|------|------|
| `layer_features_train_100k.pt` | 752.8 MB | è®­ç»ƒé›† 3 å±‚ Ã— 100k æ¿€æ´» |
| `layer_features_test_1k.pt` | 7.5 MB | æµ‹è¯•é›† 3 å±‚ Ã— 1k æ¿€æ´» |
| `layer_pooling_results.csv` | 1 KB | ç»“æœè¡¨ CSV |

## 6.3 ç›¸å…³æ–‡ä»¶

| ç±»å‹ | è·¯å¾„ | çŠ¶æ€ |
|------|------|------|
| Baseline æŠ¥å‘Š | `logg/distill/exp_linear_probe_latent_20251130.md` | âœ… |
| Main æ–‡æ¡£ | `logg/distill/distill_main_20251130.md` | âœ… |
| åŸå§‹å®éªŒç»“æœ | `raw_blindspot/layer_pooling_experiment_report.md` | âœ… |
| å±‚æ¿€æ´» (train) | `evals/layer_features_train_100k.pt` | âœ… |
| å±‚æ¿€æ´» (test) | `evals/layer_features_test_1k.pt` | âœ… |

## 6.4 å¯å¤ç°æ€§

### ç¯å¢ƒ

- **Conda**: `/datascope/slurm/miniconda3`
- **Environment**: `viska-torch-2`
- **Python**: 3.13.1
- **Lightning**: 2.5.0.post0

### å¤ç°å‘½ä»¤

```bash
cd /home/swei20/BlindSpotDenoiser
source /datascope/slurm/miniconda3/bin/activate viska-torch-2
./experiments/run_layer_pooling_probe.sh
```

---

*æŠ¥å‘Šæ›´æ–°æ—¶é—´: 2025-12-01*  
*å¯¹åº”è’¸é¦å®éªŒè®¡åˆ’: MVP 1.4*

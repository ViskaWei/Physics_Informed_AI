# ğŸ“˜ Distill (çŸ¥è¯†è’¸é¦) Â· å®éªŒä¸»æ¡†æ¶

---
> **ä¸»é¢˜åç§°ï¼š** BlindSpot Latent åˆ° $\log g$ é¢„æµ‹çš„ Teacher-Student è’¸é¦  
> **ä½œè€…ï¼š** Viska Wei  
> **åˆ›å»ºæ—¥æœŸï¼š** 2025-11-30  
> **æœ€åæ›´æ–°ï¼š** 2025-12-01  
> **çŠ¶æ€ï¼š** ğŸ”„ è¿›è¡Œä¸­ï¼ˆStage 1-2 å·²å®Œæˆï¼ŒStage A å¾…åšï¼‰

---

## ğŸ”— å…­å±‚æ¶æ„ç´¢å¼•

| å±‚çº§ | æ–‡ä»¶ | è¯´æ˜ |
|------|------|------|
| **Layer 1** | [sessions/](./sessions/) | GPT ä¼šè¯å½’æ¡£ |
| **Layer 2** | [æœ¬æ–‡ä»¶](./distill_main_20251130.md) | é¡¹ç›®ä¸»çº¿ + è·¨å®éªŒåˆ†æ |
| **Layer 3** | [status/kanban.md](../../status/kanban.md) | å®éªŒçŠ¶æ€è¿½è¸ª |
| **Layer 4** | `exp_*.md` | å­å®éªŒæŠ¥å‘Š |
| **Layer 5** | `card_*.md` | çŸ¥è¯†å¡ç‰‡ï¼ˆå¾…åˆ›å»ºï¼‰ |
| **Layer 6** | [status/next_steps.md](../../status/next_steps.md) | æ—¥å¸¸è®¡åˆ’ |

---

## ğŸ”¥ é‡è¦å‘ç°ä¸æ–¹å‘è°ƒæ•´ï¼ˆ2025-12-01 æ›´æ–°ï¼‰

### é—®é¢˜ï¼šError æ·å¾„

å‘ç° **CleanError å•ç‹¬é¢„æµ‹ $\log g$ å¯è¾¾ $R^2 \approx 0.91$**ï¼Œæ„å‘³ç€ï¼š

1. Error æœ¬èº«å¼ºçƒˆç¼–ç äº† $\log g$ ä¿¡æ¯
2. BlindSpot latent çœ‹åˆ°çš„ $\log g$ å¯èƒ½æ˜¯ **"error â†’ å†…éƒ¨è¡¨å¾ â†’ log g"** æ·å¾„
3. éœ€è¦åˆ†ç¦» error è´¡çŒ®å’Œ flux çœŸå®è´¡çŒ®

### æ–°å¢ Stage Aï¼šä¿¡æ¯æ¥æºåˆ†è§£

åœ¨åŸæœ‰ Stage 1-4 ä¹‹å‰ï¼Œæ–°å¢ **Stage A** æ¥å®šé‡åˆ†è§£ $\log g$ ä¿¡æ¯æ¥æºï¼š

| å­å®éªŒ | ç›®çš„ | çŠ¶æ€ |
|--------|------|------|
| A1 | Error-only baseline | ğŸ”² å¾…åš |
| A2 | æ®‹å·®å®šä¹‰ä¸è®¡ç®— | ğŸ”² å¾…åš |
| A3 | Flux â†’ æ®‹å·®é¢„æµ‹ | ğŸ”² å¾…åš |
| A4 | Latent â†’ æ®‹å·®é¢„æµ‹ | ğŸ”² å¾…åš |

**è¯¦ç»†è®¾è®¡**ï¼š[exp_error_info_decomposition_20251201.md](./exp_error_info_decomposition_20251201.md)

---

# ğŸ“‘ ç›®å½•

- [0. é—®é¢˜é‡è¿°](#0-é—®é¢˜é‡è¿°)
- [1. ğŸ¯ ç›®æ ‡](#1--ç›®æ ‡)
- [2. ğŸ§ª å®éªŒè®¾è®¡](#2--å®éªŒè®¾è®¡experiment-design)
- [3. ğŸ“Š é˜¶æ®µæ€§ MVP å®éªŒ](#3--é˜¶æ®µæ€§-mvp-å®éªŒ)
- [4. ğŸ’¡ å†³ç­–æ ‘ä¸å®éªŒè°ƒåº¦](#4--å†³ç­–æ ‘ä¸å®éªŒè°ƒåº¦)
- [5. ğŸ“ é£é™©æ¸…å•ä¸éªŒæ”¶æ ‡å‡†](#5--é£é™©æ¸…å•ä¸éªŒæ”¶æ ‡å‡†)
- [6. ğŸ“ é™„å½•ï¼šæœ€å°å®ç°å»ºè®®](#6--é™„å½•æœ€å°å®ç°å»ºè®®)

---

# 0. é—®é¢˜é‡è¿°

## 0.1 æ ¸å¿ƒç ”ç©¶é—®é¢˜

> **Denoiser çš„ latent è¡¨ç¤ºæ˜¯å¦æ¯”åŸå§‹å…‰è°±æ›´é€‚åˆä½œä¸º $\log g$ çš„ç‰¹å¾ï¼Ÿèƒ½å¦é€šè¿‡ Teacher-Student è’¸é¦å°†è¿™ç§ä¼˜åŠ¿è¿ç§»åˆ°åªçœ‹ flux çš„æ¨¡å‹ä¸Šï¼Ÿ**

è¿™ä¸ªé—®é¢˜å†³å®šäº†ï¼š
- **è¡¨ç¤ºå­¦ä¹ è·¯çº¿çš„å¯è¡Œæ€§**ï¼šlatent æ˜¯å¦çœŸçš„ç¼–ç äº† $\log g$ ä¿¡æ¯
- **æ¨ç†æ—¶çš„æ¨¡å‹é€‰æ‹©**ï¼šèƒ½å¦æ‘†è„±å¯¹ error é€šé“çš„ä¾èµ–
- **è’¸é¦ç­–ç•¥çš„ä»·å€¼**ï¼šæ˜¯å¦å€¼å¾—æŠ•å…¥é¢å¤–çš„è®­ç»ƒå¤æ‚åº¦

## 0.2 å½“å‰è¿›å±•ï¼ˆMVP 1.1 ç»“æœæ›´æ–° 2025-12-01ï¼‰

### æœ€ä½³ç»“æœæ±‡æ€» (100k Train + 1k Test, LightGBM)

| å‚æ•° | ç‰©ç†å«ä¹‰ | Test $R^2$ | Test MAE | é¢„æµ‹èƒ½åŠ› |
|:----:|:--------:|:-------:|:--------:|:--------:|
| **$T_{\text{eff}}$** | æœ‰æ•ˆæ¸©åº¦ | **0.9775** | 74.11 K | â­â­â­ ä¼˜ç§€ |
| **[M/H]** | é‡‘å±ä¸°åº¦ | **0.9599** | 0.141 dex | â­â­â­ ä¼˜ç§€ |
| $\log g$ | è¡¨é¢é‡åŠ› | **0.2830** | 0.847 dex | â­ è¾ƒå¼± |
| [$\alpha$/M] | $\alpha$ å¢å¼º | **0.1908** | 0.182 dex | â­ è¾ƒå¼± |
| [C/M] | ç¢³ä¸°åº¦ | **0.1396** | 0.296 dex | âŒ å¾ˆå¼± |

### æ•°æ®é‡å½±å“æ€»ç»“

| æ•°æ®é‡ | $\log g$ Linear $R^2$ | $\log g$ LightGBM $R^2$ | å…³é”®å‘ç° |
|--------|----------------------|------------------------|----------|
| 1k | 0.2331 | 0.1769 | LightGBM è¿‡æ‹Ÿåˆï¼Œçº¿æ€§æ›´ç¨³å¥ |
| 32k | 0.2512 | **0.4884** | LightGBM æ˜¾è‘—ä¼˜äºçº¿æ€§ |
| 100k | 0.2192 | **0.2830** | ç‹¬ç«‹æµ‹è¯•é›†ç»“æœæ›´å¯é  |

**å…³é”®å‘ç°**ï¼š
- âœ… Latent å¼ºç¼–ç å…¨å±€å‚æ•°ï¼ˆ$T_{\text{eff}}$, [M/H]ï¼‰
- âš ï¸ $\log g$ çº¿æ€§ä¿¡å·å¼±ï¼ˆ$R^2 \approx 0.22$ï¼‰ï¼Œä½† LightGBM å¯æå‡è‡³ 0.28ï¼ˆ+29%ï¼‰
- âš ï¸ æ•°æ®é‡æ˜¯å…³é”®å› ç´ ï¼Œ1k æ ·æœ¬ LightGBM ä¸¥é‡è¿‡æ‹Ÿåˆ

## 0.3 å¯¹åç»­è®¾è®¡çš„å½±å“

| å¦‚æœ... | åˆ™... |
|---------|-------|
| âœ… LightGBM æå‡ $\log g$ é¢„æµ‹ï¼ˆå·²éªŒè¯ï¼‰ | latent æœ‰éçº¿æ€§ $\log g$ ä¿¡æ¯ï¼Œè’¸é¦æœ‰ä»·å€¼ |
| è¿›ä¸€æ­¥æ”¹å–„éœ€è¦... | æ›´å¥½çš„æ± åŒ–ç­–ç•¥ï¼ˆattention poolingï¼‰æˆ–æ›´å¤§æ•°æ®é‡ |

---

# 1. ğŸ¯ ç›®æ ‡

## 1.1 èƒŒæ™¯ä¸åŠ¨æœº

### æ–¹æ¡ˆæ¦‚è¿°

å·²æœ‰ä¸€ä¸ªè®­ç»ƒå¥½çš„ **Blind-Spot Denoiser è‡ªç¼–ç å™¨**ï¼š
- **è¾“å…¥**ï¼šnoisy fluxï¼ˆä»¥åŠå¯èƒ½çš„ per-pixel error é€šé“ $\sigma^2$ï¼‰
- **ä¸­é—´**ï¼šlatent å‘é‡ $z \in \mathbb{R}^L$
- **è¾“å‡º**ï¼šdenoised flux

è®¾è®¡ä¸€ä¸ª **Teacherâ€“Student è’¸é¦ç»“æ„**ï¼š

| è§’è‰² | è¾“å…¥ | è¾“å‡º | çŠ¶æ€ |
|------|------|------|------|
| **Teacher** | noisy flux + per-pixel error $\sigma$ | $z^\star$ï¼ˆç†æƒ³è¡¨ç¤ºï¼‰ | å†»ç»“ |
| **Student** | ä»… noisy flux | $\tilde{z}$ï¼ˆå­¦ä¹ é€¼è¿‘ $z^\star$ï¼‰ | è®­ç»ƒ |
| **Head** | Student latent $\tilde{z}$ | $\hat{y}$ (log g) | è®­ç»ƒ |

æœ¬æ–¹æ¡ˆçš„æ ¸å¿ƒç›®çš„ï¼š
> **ç”¨æœ‰ç‰¹æƒä¿¡æ¯ï¼ˆerrorï¼‰çš„ Teacher latent æ¥è®­ç»ƒåªçœ‹ flux çš„ Student latentï¼Œæœ€åæŠŠ Student latent ç”¨äº log g å›å½’ã€‚**

### è¦å›ç­”çš„æ ¸å¿ƒé—®é¢˜

| å±‚é¢ | æ ¸å¿ƒé—®é¢˜ |
|------|----------|
| **ä¿¡æ¯è®º/è¡¨ç¤º** | Denoiser çš„ latent æ˜¯å¦æ¯”åŸå§‹ noisy flux æˆ– denoised flux æ›´é€‚åˆä½œä¸º log g çš„è¡¨ç¤ºï¼Ÿ |
| **ç‰¹æƒä¿¡æ¯ä»·å€¼** | ä½¿ç”¨ per-pixel error ä½œä¸ºé¢å¤–è¾“å…¥ï¼Œèƒ½å¦è®© Teacher latent å¯¹ log g æ›´ã€Œçº¿æ€§å¯åˆ†ã€æˆ–æ›´ç¨³å¥ï¼Ÿ |
| **è’¸é¦å¯è¡Œæ€§** | åªçœ‹ flux çš„ Studentï¼Œèƒ½å¦åœ¨åˆç†å®¹é‡ä¸‹é€¼è¿‘ã€Œflux+error â†’ latentã€çš„æ˜ å°„ï¼Ÿ |
| **å·¥ç¨‹ä»·å€¼** | Student latent + ç®€å• head çš„ log g æ€§èƒ½ï¼Œæ˜¯å¦ $\geq$ ç°æœ‰ä¼ ç»Ÿ ML baselineï¼Ÿ |

## 1.2 æ ¸å¿ƒå‡è®¾

> **Denoiser çš„ latent å¯¹ log g åŒ…å«æœ‰ç”¨ä¿¡æ¯ï¼Œä¸”å¯ä»¥é€šè¿‡ Teacher-Student è’¸é¦è¿ç§»åˆ°åªçœ‹ flux çš„ Student æ¨¡å‹ä¸Šã€‚**

å¦‚æœå‡è®¾æˆç«‹ï¼Œæ„å‘³ç€ï¼š
- Latent è¡¨ç¤ºå­¦ä¹ åœ¨é«˜å™ªå£°åœºæ™¯ä¸‹æä¾›æ›´ç¨³å¥çš„ç‰¹å¾
- è’¸é¦åçš„ Student å¯ä»¥åœ¨æ¨ç†æ—¶æ‘†è„±å¯¹ error é€šé“çš„ä¾èµ–
- å¯èƒ½è·å¾—æ›´å¥½çš„ sample efficiency

å¦‚æœå‡è®¾ä¸æˆç«‹ï¼Œåˆ™éœ€è¦ï¼š
- é‡æ–°è®¾è®¡ Denoiser ç›®æ ‡ï¼ˆå¦‚ multi-task åŠ ç‰©ç†æ ‡ç­¾ï¼‰
- æˆ–ç›´æ¥åš end-to-end log g é¢„æµ‹ï¼Œæ”¾å¼ƒè¡¨ç¤ºå­¦ä¹ è·¯çº¿

### å…³é”®å­å‡è®¾æ¸…å•

| ID | å‡è®¾ | éªŒè¯æ–¹å¼ | çŠ¶æ€ |
|----|------|----------|------|
| **H1** | Denoiser latent å¯¹ log g ç¡®å®å«æœ‰æœ‰ç”¨ä¿¡æ¯ | MVP 1.1 | âœ… éƒ¨åˆ†éªŒè¯ï¼ˆ$R^2=0.28$ via LGBMï¼‰ |
| **H2** | Teacher çš„ latent æ²¡æœ‰è¢« error é€šé“æå¾—å¤ªæŠ•æœºï¼ˆé shortcutï¼‰ | MVP 4.1, 4.2 | TODO |
| **H3** | åªè¾“å…¥ flux çš„ Student å¯ä»¥åœ¨ä¸€å®šå®¹é‡ä¸‹é€¼è¿‘ Teacher latent | MVP 2.1, 2.3 | TODO |
| **H4** | Denoiser æœ¬èº«è´¨é‡è¶³å¤Ÿå¥½ä¸”ç¨³å®šï¼ˆæ— ç³»ç»Ÿ biasï¼‰ | MVP 1.1 å¯è§†åŒ– | TODO |
| **H5** | ç»“æœå¢ç›Šæ¥è‡ªã€Œæ›´å¥½çš„è¡¨ç¤ºã€è€Œé pipeline bug | MVP 4.3 | TODO |
| **H6** | è®¡ç®—èµ„æºå¯æ‰¿å— | é¢„ä¼°å­˜å‚¨/è®¡ç®—é‡ | âœ… |

## 1.3 éªŒè¯é—®é¢˜

| # | é—®é¢˜ | éªŒè¯ç›®æ ‡ | ç»“æœ |
|---|------|---------|------|
| Q1 | Teacher latent + Linear èƒ½å¦è¾¾åˆ°å¯¹ $\log g$ æœ‰æ•ˆé¢„æµ‹ï¼ˆ$R^2 \geq 0.5$ï¼‰ï¼Ÿ | éªŒè¯ H1ï¼šlatent ä¿¡æ¯é‡ | âŒ **$R^2 = 0.22$**ï¼ˆçº¿æ€§ä¿¡å·å¼±ï¼‰ |
| Q2 | Teacher latent + LightGBM èƒ½å¦æ”¹å–„ $\log g$ é¢„æµ‹ï¼Ÿ | éªŒè¯éçº¿æ€§ä¿¡å· | âœ… **$R^2 = 0.28$**ï¼ˆ+29%ï¼‰ |
| Q3 | æ•°æ®é‡æ˜¯å¦å½±å“é¢„æµ‹æ€§èƒ½ï¼Ÿ | éªŒè¯æ•°æ®é‡é‡è¦æ€§ | âœ… 1kâ†’100k æ˜¾è‘—æå‡ |
| Q4 | åœ¨é«˜å™ªå£° regime ä¸‹ï¼Œlatent çš„ $R^2$ ä¸‹é™æ˜¯å¦æ…¢äº raw fluxï¼Ÿ | éªŒè¯ latent é²æ£’æ€§ | TODO |
| Q5 | Student latent ä¸ Teacher latent çš„ cosine similarity èƒ½å¦ $\geq 0.9$ï¼Ÿ | éªŒè¯ H3ï¼šè’¸é¦å¯è¡Œæ€§ | TODO |
| Q6 | å»æ‰ error è¾“å…¥å latent æ€§èƒ½ä¸‹é™å¤šå°‘ï¼ˆ$\Delta R^2$ï¼‰ï¼Ÿ | éªŒè¯ H2ï¼šerror ä¾èµ–ç¨‹åº¦ | TODO |

### Q1-Q3 è¯¦ç»†ç»“æœï¼ˆMVP 1.1 å¤§è§„æ¨¡å®éªŒï¼‰

**100k Train + 1k Independent Test (LightGBM leaves=15, trees=50)**ï¼š

| å‚æ•° | Ridge $R^2$ | LightGBM $R^2$ | æ”¹å–„å¹…åº¦ | é¢„æµ‹èƒ½åŠ› |
|------|-----------|----------|----------|----------|
| $T_{\text{eff}}$ | 0.9702 | **0.9775** | +0.8% | â­â­â­ ä¼˜ç§€ |
| [M/H] | 0.9444 | **0.9599** | +1.6% | â­â­â­ ä¼˜ç§€ |
| $\log g$ | 0.2192 | **0.2830** | +29% | â­ è¾ƒå¼± |
| [$\alpha$/M] | 0.1161 | **0.1908** | +64% | â­ è¾ƒå¼± |
| [C/M] | 0.0988 | **0.1396** | +41% | âŒ å¾ˆå¼± |

**å…³é”®å‘ç°**ï¼š
- âœ… LightGBM å¯¹æ‰€æœ‰å‚æ•°éƒ½ä¼˜äº Ridge
- âœ… $\log g$ æå‡æœ€æ˜¾è‘—ï¼ˆ+29%ï¼‰ï¼Œè¯æ˜å­˜åœ¨éçº¿æ€§ä¿¡å·
- âš ï¸ Mean pooling ä¸¢å¤±ç©ºé—´ä¿¡æ¯ï¼Œé™åˆ¶äº† $\log g$ é¢„æµ‹ä¸Šé™

## 1.4 ç»“è®ºæ‘˜è¦

### 1.4.1 MVP 1.1 å®éªŒç»“è®ºï¼ˆLinear Probe + LightGBM æ‰©å±•ï¼‰

| ç»“è®º | è¯´æ˜ |
|------|------|
| **Latent å¼ºç¼–ç å…¨å±€å‚æ•°** | $T_{\text{eff}}$ï¼ˆ$R^2=0.98$ï¼‰å’Œ [M/H]ï¼ˆ$R^2=0.96$ï¼‰å¯é«˜ç²¾åº¦æ¢å¤ |
| **$\log g$ æœ‰éçº¿æ€§ä¿¡å·** | LightGBM æ¯” Ridge æå‡ 29%ï¼ˆ0.22 â†’ 0.28ï¼‰ |
| **æ•°æ®é‡æ˜¯å…³é”®å› ç´ ** | 1k æ ·æœ¬ LightGBM è¿‡æ‹Ÿåˆï¼›100k æ ·æœ¬æ³›åŒ–è‰¯å¥½ |
| **Mean pooling ä¸¢å¤±ç©ºé—´ä¿¡æ¯** | å¯¹ $\log g$ æ•æ„Ÿçš„å‹åŠ›å¢å®½ç‰¹å¾ï¼ˆBalmer wingsï¼‰è¢« mean pooling å¹³å‡æ‰ |

### 1.4.2 MVP 1.4 å®éªŒç»“è®ºï¼ˆLatent æå–ä¼˜åŒ–ï¼‰

| ç»“è®º | è¯´æ˜ |
|------|------|
| **Feature map å­˜åœ¨ $\log g$ ä¿¡æ¯** | æœ€ä½³é…ç½®è¾¾åˆ° Test $R^2 = 0.5516$ï¼Œè¿œè¶…é˜ˆå€¼ 0.5 |
| **Pooling ç­–ç•¥æ˜¯ä¸»è¦ç“¶é¢ˆ** | `seg_mean_K8` æ¯” `global_mean` æå‡ +77.6% |
| **å±‚é€‰æ‹©ä¹Ÿæœ‰è´¡çŒ®** | `enc_pre_latent` æ¯” `enc_last` æå‡ +16.2% |
| **æ³¢é•¿å±€éƒ¨æ€§æ˜¯å…³é”®** | åˆ†æ®µ pooling ä¿ç•™ç©ºé—´ç»“æ„ï¼Œå¯¹ $\log g$ é¢„æµ‹è‡³å…³é‡è¦ |

### 1.4.3 è®¾è®¡å¯ç¤º

| è®¾è®¡åŸåˆ™ | å…·ä½“å»ºè®® |
|---------|----------|
| **æ•°æ®é‡ä¼˜å…ˆ** | è‡³å°‘ 10k+ æ ·æœ¬ç”¨äº LightGBMï¼Œé¿å…è¿‡æ‹Ÿåˆ |
| **æ¨¡å‹é€‰æ‹©åˆ†å±‚** | <10k: Ridgeï¼›â‰¥10k: LightGBM (ä¿å®ˆå‚æ•°) |
| **âœ… Teacher latent é…ç½®** | ä½¿ç”¨ `enc_pre_latent + seg_mean_K8`ï¼ˆ384 ç»´ï¼‰ |
| **âœ… è’¸é¦å¯è¡Œ** | Teacher latent è¾¾ $R^2 = 0.55$ï¼Œè’¸é¦æ–¹æ¡ˆæœ‰è¶³å¤Ÿä¸Šé™ |

> **ä¸€å¥è¯æ€»ç»“**ï¼šBlindSpot latent å¼ºç¼–ç æ¸©åº¦å’Œé‡‘å±ä¸°åº¦ï¼›$\log g$ ä¿¡æ¯å­˜åœ¨ä½†è¢«åŸæå–æ–¹å¼æŠ¹æ‰ï¼Œé€šè¿‡ä¼˜åŒ–æå–æ–¹å¼ï¼ˆ`enc_pre_latent + seg_mean_K8`ï¼‰å¯è¾¾ $R^2 = 0.55$ï¼ˆ+150%ï¼‰ï¼Œè’¸é¦æ–¹æ¡ˆå€¼å¾—ç»§ç»­æ¨è¿›ã€‚

---

# 2. ğŸ§ª å®éªŒè®¾è®¡ï¼ˆExperiment Designï¼‰

## 2.1 æ•°æ®ï¼ˆDataï¼‰

- **æ•°æ®æ¥æº**ï¼šBOSZ åˆæˆå…‰è°±åº“ (mag215)
- **è®­ç»ƒæ ·æœ¬æ•°**ï¼š1k / 32k / 100kï¼ˆå¤šè§„æ¨¡å®éªŒï¼‰
- **æµ‹è¯•æ ·æœ¬æ•°**ï¼š1,000ï¼ˆç‹¬ç«‹æµ‹è¯•é›†ï¼‰
- **ç‰¹å¾ç»´åº¦**ï¼š$D = 4096$ï¼ˆæ³¢é•¿ç‚¹æ•°ï¼‰
- **Latent ç»´åº¦**ï¼š$L = 48$ï¼ˆBlindSpot encoder è¾“å‡ºé€šé“æ•°ï¼‰
- **æ ‡ç­¾å‚æ•°**ï¼š$\log g$ï¼ˆä¸»è¦ï¼‰ï¼Œ$T_{\text{eff}}$, [M/H], [$\alpha$/M], [C/M]ï¼ˆè¾…åŠ©ï¼‰
- å™ªå£°æ¨¡å‹ï¼š
$$
\text{noisy\_flux} = \text{flux} + \mathcal{N}(0, \sigma^2)
$$

**æ•°æ®åˆ‡åˆ†åŸåˆ™**ï¼š
- å›ºå®š train/valid/test åˆ‡åˆ†ï¼Œæ‰€æœ‰å®éªŒä¿æŒä¸€è‡´
- è®°å½•éšæœºç§å­ï¼ˆseed=42ï¼‰ï¼Œç¡®ä¿å¯å¤ç°

**å‚æ•°æ•°å€¼èŒƒå›´**ï¼š

| å‚æ•° | èŒƒå›´ | å•ä½ |
|------|------|------|
| $T_{\text{eff}}$ | [3750, 6000] | K |
| $\log g$ | [1.0, 5.0] | dex |
| [M/H] | [-2.5, 0.75] | dex |

## 2.2 ä½¿ç”¨çš„ç‰¹å¾ç±»å‹

| ç‰¹å¾ç±»å‹ | æè¿° | ä½¿ç”¨åœºæ™¯ |
|----------|------|----------|
| Raw noisy flux | åŸå§‹å¸¦å™ªå…‰è°± | Baseline |
| Denoised flux | Denoiser è¾“å‡º | Ablation |
| Teacher latent $z^\star$ | $E(x_{\text{noisy}}, \sigma)$ | Teacher |
| Student latent $\tilde{z}$ | $S(x_{\text{noisy}})$ | æœ€ç»ˆæ¨ç† |

## 2.3 æ¨¡å‹ä¸ç®—æ³•ï¼ˆModel & Algorithmï¼‰

### Teacher Encoderï¼ˆå†»ç»“ï¼‰
$$
z^\star = E_\theta(x_{\text{noisy}}, \sigma)
$$
- æ¥è‡ªå·²è®­ç»ƒå¥½çš„ Blind-Spot Denoiser
- è®­ç»ƒæ—¶å®Œå…¨å†»ç»“å‚æ•°

### Student Network
$$
\tilde{z} = S_\phi(x_{\text{noisy}})
$$
- è¾“å…¥ï¼šä»… noisy flux
- è¾“å‡ºï¼š$\tilde{z} \in \mathbb{R}^L$
- æ¶æ„ï¼šMLPï¼ˆ3-4 å±‚ï¼Œéšè—å®½åº¦ 1024/2048ï¼‰

### è’¸é¦æŸå¤±
$$
\mathcal{L}_{\text{distill}} = \| \tilde{z} - z^\star \|_2^2
$$

### log g Head
$$
\hat{y} = h_\psi(\tilde{z})
$$
- çº¿æ€§ / Ridge / LightGBM / å° MLP

### è”åˆè®­ç»ƒï¼ˆå¯é€‰ï¼‰
$$
\mathcal{L}_{\text{total}} = \lambda_z \cdot \mathcal{L}_{\text{distill}} + \lambda_y \cdot \| \hat{y} - y \|_2^2
$$

## 2.4 è¶…å‚æ•°ï¼ˆHyperparametersï¼‰

| å‚æ•° | å»ºè®®å€¼/èŒƒå›´ | è¯´æ˜ |
|------|-------------|------|
| Ridge $\alpha$ | 0.001 | Head æ­£åˆ™åŒ– |
| LightGBM num_leaves | 15 | ä¿å®ˆé…ç½®é˜²è¿‡æ‹Ÿåˆ |
| LightGBM n_estimators | 50 | ä¿å®ˆé…ç½®é˜²è¿‡æ‹Ÿåˆ |
| Noise levels | 0.0, 0.1, 0.5, 1.0 | é²æ£’æ€§æµ‹è¯• |

### æ¨èæ¨¡å‹é…ç½®

| æ•°æ®é‡ | çº¿æ€§æ¨¡å‹ | éçº¿æ€§æ¨¡å‹ |
|--------|----------|------------|
| < 10k | Ridge (Î±=0.001) | ä¸æ¨è GBDT |
| 10k-50k | Ridge (Î±=0.001) | LGBM (15/50) |
| > 50k | Ridge (Î±=0.001) | LGBM (15/50) |

---

# 3. ğŸ“Š é˜¶æ®µæ€§ MVP å®éªŒ

## é˜¶æ®µ 1ï¼šéªŒè¯ latent æœ¬èº«å¯¹ log g çš„ä¿¡æ¯é‡

**ç›®æ ‡**ï¼šä¸åšä»»ä½• Student/è’¸é¦ï¼Œå…ˆå›ç­”ã€ŒTeacher latent æ˜¯å¦æ˜¯ä¸€ä¸ªå€¼å¾—æŠ•èµ„çš„ log g è¡¨ç¤ºï¼Ÿã€

---

### MVP 1.1ï¼šTeacher latent â†’ ç®€å•çº¿æ€§/éçº¿æ€§æ¨¡å‹é¢„æµ‹ log g âœ… å·²å®Œæˆï¼ˆå«æ‰©å±•ï¼‰

**ç›®çš„**ï¼šæ£€æŸ¥ Teacher latent æ˜¯å¦èƒ½ç”¨ Linear/Ridge/LightGBM æ‹Ÿåˆ log gï¼Œä½œä¸ºä¿¡æ¯é‡çš„ä¼°è®¡ã€‚

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ•°æ®** | 1k / 32k / 100k ä¸‰ç§è§„æ¨¡ï¼Œç‹¬ç«‹æµ‹è¯•é›† 1k |
| **è¾“å…¥** | Teacher latent $z^\star \in \mathbb{R}^{48}$ï¼ˆencoder_last + mean poolingï¼‰ |
| **æ¨¡å‹** | OLSã€Ridge (Î±=0.001)ã€LightGBM (15/50) |
| **æŒ‡æ ‡** | $R^2$, MAE, RMSE |

**å®éªŒç»“æœæ±‡æ€»**ï¼š

#### å°æ ·æœ¬ (1k) ç»“æœ

| å‚æ•° | Linear $R^2$ | LGBM $R^2$ | æœ€ä½³ |
|------|-----------|----------|------|
| $T_{\text{eff}}$ | 0.9627 | **0.9701** | LGBM |
| [M/H] | 0.9484 | **0.9519** | LGBM |
| $\log g$ | **0.2331** | 0.1769 | **Linear** |
| [$\alpha$/M] | **0.0674** | 0.0638 | Linear |
| [C/M] | **0.0639** | 0.0225 | Linear |

**å…³é”®å‘ç°**ï¼š1000 æ ·æœ¬å¯¹ LightGBM ä¸è¶³ï¼Œçº¿æ€§æ¨¡å‹æ›´ç¨³å¥ã€‚

#### å¤§è§„æ¨¡ (100k Train + 1k Test) ç»“æœ

| å‚æ•° | Ridge $R^2$ | LGBM $R^2$ | æ”¹å–„ | é¢„æµ‹èƒ½åŠ› |
|------|-----------|----------|------|----------|
| $T_{\text{eff}}$ | 0.9702 | **0.9775** | +0.8% | â­â­â­ ä¼˜ç§€ |
| [M/H] | 0.9444 | **0.9599** | +1.6% | â­â­â­ ä¼˜ç§€ |
| $\log g$ | 0.2192 | **0.2830** | **+29%** | â­ è¾ƒå¼± |
| [$\alpha$/M] | 0.1161 | **0.1908** | +64% | â­ è¾ƒå¼± |
| [C/M] | 0.0988 | **0.1396** | +41% | âŒ å¾ˆå¼± |

**å…³é”®å‘ç°**ï¼š
- âœ… **LightGBM å…¨é¢ä¼˜äº Ridge**ï¼ˆå¤§æ•°æ®é‡ä¸‹ï¼‰
- âœ… **$\log g$ æœ‰éçº¿æ€§ä¿¡å·**ï¼š+29% æ”¹å–„
- âš ï¸ **è’¸é¦ä¸Šé™å—é™**ï¼šTeacher latent å¯¹ $\log g$ $R^2 = 0.28$

**ç»“è®º**ï¼š
- âœ… **å…¨å±€å‚æ•°å¼ºç¼–ç **ï¼š$T_{\text{eff}}$, [M/H] å¯é«˜ç²¾åº¦æ¢å¤
- âš ï¸ **$\log g$ éœ€è¦éçº¿æ€§æ–¹æ³• + å¤§æ•°æ®é‡**
- âš ï¸ **æ± åŒ–ç­–ç•¥éœ€æ”¹è¿›**ï¼šMean pooling ä¸¢å¤±ç©ºé—´ä¿¡æ¯

**ä¸‹ä¸€æ­¥**ï¼š
- â†’ MVP 1.2ï¼šè·¨å™ªå£°é²æ£’æ€§æµ‹è¯•
- â†’ è€ƒè™‘æ”¹è¿›æ± åŒ–ç­–ç•¥ï¼ˆattention poolingï¼‰
- â†’ è€ƒè™‘å¤šå±‚ç‰¹å¾èåˆ

**è¯¦ç»†æŠ¥å‘Š**ï¼š[exp_linear_probe_latent_20251130.md](./exp_linear_probe_latent_20251130.md)

---

### MVP 1.2ï¼šè·¨ noise level æµ‹è¯• latent çš„é²æ£’æ€§

**ç›®çš„**ï¼šçœ‹ latent å¯¹ noise æ˜¯å¦æ›´ã€Œé²æ£’ã€ã€‚

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ•°æ®** | 2-3 ä¸ª noise æ°´å¹³ï¼ˆä½/ä¸­/é«˜ï¼‰ï¼Œå„ 5k-10k |
| **æ¨¡å‹** | ä½¿ç”¨ MVP 1.1 å·²è®­ç»ƒçš„ LightGBM æ¨¡å‹ |
| **æŒ‡æ ‡** | æ¯ä¸ª noise level çš„ $R^2$/MAE |

**å¯¹æ¯”**ï¼šraw noisy flux â†’ log g ä½¿ç”¨åŒæ ·æ¨¡å‹

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| é«˜å™ªæ—¶ latent æ€§èƒ½ä¸‹é™ < raw flux | âœ… latent æ›´é²æ£’ |
| ä½å™ªå¥½ä½†é«˜å™ªå´©å¾—å‰å®³ | âš ï¸ latent å¯¹å™ªå£°åˆ†å¸ƒä¸ç¨³å¥ |

---

### MVP 1.3ï¼šTeacher latent ç»´åº¦ L çš„ç²—ç•¥æ‰«æï¼ˆå¯é€‰ï¼‰

**ç›®çš„**ï¼šçœ‹ latent ç»´åº¦ L å¯¹ log g ä¿¡æ¯é‡çš„å½±å“ã€‚

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ–¹æ³•** | å¯¹ latent åš PCAï¼Œä¿ç•™ 16/32/64/128 ç»´ |
| **æ¨¡å‹** | Ridge å›å½’ log g |
| **æŒ‡æ ‡** | $R^2$/MAE vs ä¿ç•™ç»´åº¦æ›²çº¿ |

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | å«ä¹‰ |
|------|------|
| å°ç»´åº¦ï¼ˆ16-32ï¼‰å·²æ¥è¿‘åŸå§‹ L çš„æ€§èƒ½ | log g ä¿¡æ¯é›†ä¸­ï¼Œæœ‰åˆ©äºè’¸é¦ |
| æ€§èƒ½éšç»´åº¦çº¿æ€§ä¸Šå‡ | ä¿¡æ¯åˆ†æ•£ï¼ŒStudent ä»»åŠ¡æ›´éš¾ |

---


### MVP 1.4ï¼šLatent æå–æ–¹å¼ä¼˜åŒ–å®éªŒ âœ… å·²å®Œæˆï¼ˆé‡å¤§çªç ´ï¼‰

**ç›®çš„**ï¼šåŒºåˆ†"latent feature map æœ¬èº«æ²¡ $\log g$" vs "æˆ‘ä»¬å– latent çš„æ–¹å¼æŠŠ $\log g$ æŠ¹æ‰äº†"ã€‚

| é¡¹ç›® | é…ç½® |
|------|------|
| **Layer-wise Probe** | æµ‹è¯• `enc_pre_latent`, `enc_last`, `dec_input` |
| **Pooling å˜ä½“** | `global_mean`, `mean_max`, `seg_mean_K8` |
| **æ¨¡å‹** | Ridge (Î±=0.001) |
| **æŒ‡æ ‡** | Test $R^2$/MAE/RMSE |

**ğŸ¯ æ ¸å¿ƒç»“æœ**ï¼š

| é…ç½® | Test $R^2$ | ç›¸å¯¹ Baseline |
|------|------------|---------------|
| **Baseline** (enc\_last + global\_mean) | 0.2202 | - |
| enc\_pre\_latent + global\_mean | 0.3106 | +41% |
| enc\_pre\_latent + mean\_max | 0.4056 | +84% |
| **æœ€ä½³** (enc\_pre\_latent + seg\_mean\_K8) | **0.5516** | **+150%** |

**éªŒæ”¶æ ‡å‡†æ£€æŸ¥**ï¼š

| æƒ…å†µ | åˆ¤æ–­ | ç»“æœ |
|------|------|------|
| $\log g$ $R^2$ ä» 0.22 â†’ 0.5+ | âœ… Feature map æœ‰ $\log g$ï¼Œpooling æ˜¯ç“¶é¢ˆ | **âœ… è¾¾æˆ (0.5516)** |
| `enc_pre_latent` > `enc_last` | âš ï¸ åå±‚"æŠ¹å¹³"äº† $\log g$ | **âœ… éªŒè¯ (+16.2%)** |

**å…³é”®å‘ç°**ï¼š

1. âœ… **Feature map ä¸­å­˜åœ¨ $\log g$ ä¿¡æ¯**ï¼šTest $R^2 = 0.5516$ï¼Œè¿œè¶…é˜ˆå€¼ 0.5
2. âœ… **Pooling æ˜¯ä¸»è¦ç“¶é¢ˆ**ï¼š`seg_mean_K8` æ¯” `global_mean` æå‡ +77.6%
3. âœ… **å±‚é€‰æ‹©ä¹Ÿæœ‰è´¡çŒ®**ï¼š`enc_pre_latent` æ¯” `enc_last` æå‡ +16.2%
4. âœ… **æ³¢é•¿å±€éƒ¨æ€§æ˜¯å…³é”®**ï¼šåˆ†æ®µ pooling ä¿ç•™ç©ºé—´ç»“æ„ï¼Œæ˜¾è‘—æå‡ $\log g$ é¢„æµ‹

**è®¾è®¡å¯ç¤º**ï¼š

| å†³ç­– | å»ºè®® |
|------|------|
| **Teacher latent é…ç½®** | âœ… æ›´æ¢ä¸º `enc_pre_latent + seg_mean_K8`ï¼ˆ384 ç»´ï¼‰ |
| **è’¸é¦å¯è¡Œæ€§** | âœ… Teacher $R^2 = 0.55$ï¼Œæœ‰è¶³å¤Ÿä¸Šé™ç»§ç»­è’¸é¦ |
| **ç‰©ç†è§£é‡Š** | $\log g$ ä¿¡æ¯ï¼ˆå‹åŠ›å¢å®½ï¼‰é›†ä¸­åœ¨ç‰¹å®šæ³¢æ®µï¼Œéœ€ä¿ç•™ç©ºé—´ç»“æ„ |

**è¯¦ç»†æŠ¥å‘Š**ï¼š[exp_latent_extraction_logg_20251201.md](./exp_latent_extraction_logg_20251201.md)

---


## é˜¶æ®µ 2ï¼šéªŒè¯ Teacherâ€“Student è’¸é¦åœ¨ latent å±‚æ˜¯å¦å¯è¡Œ

**ç›®æ ‡**ï¼šä¸ç®¡ log gï¼Œå…ˆçœ‹ Teacher latent èƒ½å¦è¢« Student æ‹Ÿåˆã€‚

---

### MVP 2.1ï¼šStudent æ‹Ÿåˆ Teacher latentï¼ˆçº¯è¡¨ç¤ºè’¸é¦ï¼‰

**ç›®çš„**ï¼šç”¨ $\tilde{z} = S(x_{\text{noisy}})$ å»æ‹Ÿåˆ $z^\star = E(x_{\text{noisy}}, \sigma)$ã€‚

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ•°æ®** | ä¸ MVP 1.1 ç›¸åŒåˆ‡åˆ† |
| **Teacher latent** | é¢„å…ˆç¦»çº¿è®¡ç®—å¹¶å­˜ç›˜ |
| **Student** | MLPï¼ˆ3-4 å±‚ï¼Œéšè— 1024/2048ï¼Œè¾“å‡º $L$ï¼‰ |
| **æŸå¤±** | $\mathcal{L}_{\text{distill}} = \| \tilde{z} - z^\star \|_2^2$ |

**æŒ‡æ ‡**ï¼š
- Train/valid latent MSE
- æ¯ç»´æ–¹å·®æ ‡å‡†åŒ–å MSE
- Cosine similarity å¹³å‡å€¼

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ | ä¸‹ä¸€æ­¥ |
|------|------|--------|
| valid MSE ä½ï¼Œcosine sim $\geq 0.9$ | âœ… æ˜ å°„å¯æ‹Ÿåˆ | â†’ MVP 2.2 |
| train ä½ + valid é«˜ï¼ˆè¿‡æ‹Ÿåˆï¼‰ | âš ï¸ | å‡å®¹é‡/åŠ æ­£åˆ™ |
| train MSE éƒ½é™ä¸ä¸‹å» | âŒ | â†’ MVP 2.3 æ£€æŸ¥åŸå›  |

---

### MVP 2.2ï¼šStudent latent â†’ log gï¼ˆvs Teacher latentï¼‰

**ç›®çš„**ï¼šæ£€æŸ¥ $\tilde{z}$ æ˜¯å¦ä¿ç•™äº† Teacher latent ä¸­çš„ log g ä¿¡æ¯ã€‚

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ¨¡å‹** | å·²è®­ç»ƒ Student + Ridge/LightGBM head |
| **å¯¹æ¯”** | Teacher latent $z^\star$ + åŒæ · head |

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| Student latent $R^2 \geq$ Teacher çš„ 0.9Ã— ä¸” $\geq$ raw flux | âœ… è’¸é¦ä¿ç•™äº†è¡¨ç¤ºè´¨é‡ |
| Student è¿œä½äº Teacherï¼ˆ$\Delta R^2 \geq 0.1$ï¼‰ | âš ï¸ éœ€åˆ†æåŸå›  |
| Student è¿ raw flux éƒ½ä¸å¦‚ | âŒ å›é€€æ£€æŸ¥ MVP 2.1 |

---

### MVP 2.3ï¼šå¯è§£æ€§æ£€æŸ¥ï¼šStudent ä¹Ÿçœ‹ error æ—¶èƒ½å¦æ‹Ÿåˆ latent

**ç›®çš„**ï¼šåŒºåˆ†ã€Œæ¨¡å‹å¤ªå¼±ã€vsã€Œç¼ºå°‘ error ä¿¡æ¯å¯¼è‡´ä¸å¯æ‹Ÿåˆã€ã€‚

| é¡¹ç›® | é…ç½® |
|------|------|
| **Student-Plus** | è¾“å…¥æ”¹ä¸º $(x_{\text{noisy}}, \sigma)$ |
| **ä»»åŠ¡** | åŒæ ·æ‹Ÿåˆ $z^\star$ |

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| Student-Plus å¯æ˜¾è‘—é™ä½ MSEï¼ŒåŸ Student ä¸è¡Œ | error ä¸­æœ‰å¤§é‡ Teacher ä¾èµ–çš„ä¿¡æ¯ï¼Œflux-only å­˜åœ¨ä¿¡æ¯ç“¶é¢ˆ |
| ä¸¤è€…éƒ½æ‹Ÿåˆä¸å¥½ | âš ï¸ é«˜åº¦æ€€ç–‘å®ç°/æ•°æ®é—®é¢˜ |

---

## é˜¶æ®µ 3ï¼šçœŸæ­£çš„ä¸‹æ¸¸ log g æ€§èƒ½å¯¹æ¯”ï¼ˆend-to-endï¼‰

**ç›®æ ‡**ï¼šç”¨ Student latent + head çš„å®Œæ•´é“¾è·¯ï¼Œä¸ç°æœ‰ baseline åšä¸¥è‚ƒå¯¹æ¯”ã€‚

---

### MVP 3.1ï¼šStudent latent + çº¿æ€§ head vs ä¼ ç»Ÿ flux baseline

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ•°æ®** | ä¸ä¼ ç»Ÿ baseline ç›¸åŒçš„ train/valid/test |
| **Student** | å›ºå®šï¼ˆæ¥è‡ª MVP 2.1ï¼‰ |
| **Head** | çº¿æ€§ / Ridge / LightGBM |
| **Baseline** | raw noisy flux + ç›¸åŒ headï¼›denoised flux + head |

**æŒ‡æ ‡**ï¼š$R^2$, MAEï¼Œåˆ† log g / Teff åŒºé—´ç»Ÿè®¡

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| Student latent $\geq$ baselineï¼ˆæ•´ä½“+å­åŒºé—´ï¼‰ | âœ… pipeline æœ‰å®é™…ä»·å€¼ |
| ç•¥ä½ä½†æä¾›å…¶ä»–ä¼˜åŠ¿ï¼ˆæ›´å°/æ›´å¿«/æ›´ç¨³ï¼‰ | âœ… æœ‰æ¡ä»¶ä»·å€¼ |
| æ˜æ˜¾åŠ£äº baselineï¼ˆ$\Delta R^2 \geq 0.05$ï¼‰ | âŒ å›é€€æ£€æŸ¥é˜¶æ®µ 2/1 |

---

### MVP 3.2ï¼šå™ªå£°åˆ†å¸ƒ shift ä¸‹çš„é²æ£’æ€§æµ‹è¯•

| é¡¹ç›® | é…ç½® |
|------|------|
| **è®­ç»ƒé›†** | å›ºå®šä¸­ç­‰ noise level |
| **æµ‹è¯•é›†** | å¤šä¸ª noise levelï¼ˆåŒ…æ‹¬æ›´é«˜å™ªå£°ï¼‰ |

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| é«˜å™ªç«¯ Student latent ä¸‹é™æ›´æ…¢ | âœ… æä¾›é¢å¤–ç¨³å¥æ€§ |
| ä¸¤è€…æ›²çº¿å·®ä¸å¤šæˆ– Student æ›´å·® | âŒ æ— é²æ£’æ€§æ”¶ç›Š |

---

### MVP 3.3ï¼šæ ·æœ¬æ•ˆç‡ï¼ˆå°æ•°æ® regimeï¼‰

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ•°æ®** | ä¸åŒè§„æ¨¡æœ‰ label å­é›†ï¼š1k, 5k, 10k, full |
| **æ¨¡å‹** | Student latent + head vs raw flux + head |

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| å°æ ·æœ¬ï¼ˆ1k-5kï¼‰ä¸‹ Student æ›²çº¿æ˜æ˜¾æ›´é«˜ | âœ… è¡¨ç¤ºå­¦ä¹ æœ‰ sample efficiency æ”¶ç›Š |
| æ‰€æœ‰æ ·æœ¬é‡ä¸Š Student éƒ½ä¸å¦‚ raw flux | âŒ è’¸é¦æ— å®è´¨å¸®åŠ© |

---

## é˜¶æ®µ 4ï¼šé£é™©éªŒè¯ä¸ ablation

**ç›®æ ‡**ï¼šæ£€æŸ¥ error é€šé“æ˜¯å¦å¯¼è‡´ label leakageã€Teacher æ˜¯å¦è¿‡åº¦ä¾èµ– errorã€‚

---

### MVP 4.1ï¼šå»æ‰ error è¾“å…¥ï¼Œé‡æ–°ç”Ÿæˆ Teacher latent

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ–¹æ³•** | Encoder åªè¾“å…¥ $x_{\text{noisy}}$ï¼Œå¾—åˆ° $z^{\star,\text{no-err}}$ |
| **å¯¹æ¯”** | ä¸å« error çš„ $z^\star$ åˆ†åˆ«åš LightGBM log g å›å½’ |

**éªŒæ”¶æ ‡å‡†**ï¼š

| $\Delta R^2$ | åˆ¤æ–­ |
|--------------|------|
| çº¦ 0.02-0.05 | âœ… error è¾…åŠ©ä½†æœªä¸»å¯¼ |
| $\gg 0.1$ | âš ï¸ error åŒ…å«å¤§é‡ log g ç›¸å…³ä¿¡æ¯ï¼Œè’¸é¦æœ‰å¤©èŠ±æ¿ |

---

### MVP 4.2ï¼šæ‰“ä¹± error é€šé“çš„ sanity check

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ–¹æ³•** | æ¯ä¸ªæ ·æœ¬çš„ error ä» batch å†…éšæœºæ›¿æ¢ï¼ˆflux ä¸å˜ï¼‰ |
| **ç”Ÿæˆ** | ç”¨é”™è¯¯ error ç”Ÿæˆ $z^{\star,\text{shuffled}}$ï¼Œåš log g å›å½’ |

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| æ‰“ä¹±åæ€§èƒ½å¤§å¹…æ¥è¿‘ random/baseline | âœ… Teacher åˆç†åˆ©ç”¨äº† error |
| æ‰“ä¹±å‰åæ€§èƒ½å‡ ä¹ä¸å˜ | error æ— è´¡çŒ®ï¼Œå¯ç®€åŒ– Teacher |

---

### MVP 4.3ï¼šlabel shuffle sanity checkï¼ˆé˜²æ­¢ pipeline æ³„éœ²ï¼‰

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ–¹æ³•** | å›ºå®šè¾“å…¥ï¼Œéšæœºæ‰“ä¹± log g æ ‡ç­¾ï¼Œè®­ç»ƒåŒæ · head |
| **é¢„æœŸ** | è®­ç»ƒ/éªŒè¯ $R^2 \approx 0$ |

**éªŒæ”¶æ ‡å‡†**ï¼š

| æƒ…å†µ | åˆ¤æ–­ |
|------|------|
| $R^2 \approx 0$ï¼Œloss æ”¶æ•›åˆ°å™ªå£°å¸¸æ•° | âœ… pipeline æ­£å¸¸ |
| label æ‰“ä¹±ä»èƒ½è®­å‡ºé«˜ $R^2$ | âŒ æœ‰ä¸¥é‡ bugï¼ˆæ•°æ®æ³„éœ²/å¯¹é½é”™è¯¯ï¼‰ |

---

# 4. ğŸ’¡ å†³ç­–æ ‘ä¸å®éªŒè°ƒåº¦

## 4.1 é˜¶æ®µ 1 å†³ç­–æµç¨‹ï¼ˆæ›´æ–°ï¼‰

```
å¼€å§‹
  â”‚
  â–¼
MVP 1.1: Teacher latent â†’ log g (Linear/LightGBM)
  â”‚
  â”œâ”€â”€ latent LGBM RÂ² â‰¥ 0.25 âœ…ï¼ˆå½“å‰ RÂ² = 0.28ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚       â”‚                                                   â”‚
  â”‚       â–¼                                                   â”‚
  â”‚   MVP 1.2: å™ªå£°é²æ£’æ€§                                     â”‚
  â”‚       â”‚                                                   â”‚
  â”‚       â”œâ”€â”€ é«˜å™ªæ—¶ latent ä¼˜äº raw flux â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚       â”‚       â”‚                                           â”‚
  â”‚       â”‚       â–¼                                           â”‚
  â”‚       â”‚   âœ… è¿›å…¥ Stage 2                                 â”‚
  â”‚       â”‚                                                   â”‚
  â”‚       â””â”€â”€ latent åœ¨æ‰€æœ‰ noise ä¸‹ â‰¤ raw flux â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚               â”‚                                           â”‚
  â”‚               â–¼                                           â”‚
  â”‚           âš ï¸ è·‘ Stage 4.1/4.2 æ£€æŸ¥ error                 â”‚
  â”‚               ä¿æŒå¯¹è’¸é¦æ–¹å‘çš„æ€€ç–‘                         â”‚
  â”‚                                                           â”‚
  â”œâ”€â”€ latent LGBM RÂ² < 0.25 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚       â”‚                                                   â”‚
  â”‚       â–¼                                                   â”‚
  â”‚   âš ï¸ è€ƒè™‘æ”¹è¿›æ± åŒ–ç­–ç•¥ï¼ˆMVP 1.4ï¼‰                         â”‚
  â”‚   æˆ–é‡æ–°è®¾è®¡ Teacher                                      â”‚
  â”‚                                                           â”‚
  â””â”€â”€ train é«˜ + test ä½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
      âš ï¸ æ£€æŸ¥æ•°æ®åˆ‡åˆ† / å¢åŠ æ•°æ®é‡ / è·‘ MVP 4.3
```

## 4.2 é˜¶æ®µ 2 å†³ç­–æµç¨‹

```
MVP 2.1: Student æ‹Ÿåˆ Teacher latent
  â”‚
  â”œâ”€â”€ valid MSE ä½, cosine sim â‰¥ 0.9 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚       â”‚                                                â”‚
  â”‚       â–¼                                                â”‚
  â”‚   MVP 2.2: Student latent â†’ log g                     â”‚
  â”‚       â”‚                                                â”‚
  â”‚       â”œâ”€â”€ Student RÂ² â‰¥ Teacher çš„ 0.9Ã— ä¸” â‰¥ baseline â”€â”¤
  â”‚       â”‚       â”‚                                        â”‚
  â”‚       â”‚       â–¼                                        â”‚
  â”‚       â”‚   âœ… è¿›å…¥ Stage 3                              â”‚
  â”‚       â”‚                                                â”‚
  â”‚       â”œâ”€â”€ Student å¼±äº Teacher ä½† â‰¥ baseline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚       â”‚       â”‚                                        â”‚
  â”‚       â”‚       â–¼                                        â”‚
  â”‚       â”‚   âœ… ç»§ç»­ Stage 3 (è®°å½• Teacher ä¸Šé™æ›´é«˜)      â”‚
  â”‚       â”‚                                                â”‚
  â”‚       â””â”€â”€ Student è¿ raw flux éƒ½ä¸å¦‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚               â”‚                                        â”‚
  â”‚               â–¼                                        â”‚
  â”‚           âŒ å›é€€ MVP 2.1/2.3                          â”‚
  â”‚                                                        â”‚
  â”œâ”€â”€ train ä½ + valid é«˜ (è¿‡æ‹Ÿåˆ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚       â”‚                                                â”‚
  â”‚       â–¼                                                â”‚
  â”‚   å‡å®¹é‡ / åŠ æ­£åˆ™ / å¢æ•°æ®                             â”‚
  â”‚                                                        â”‚
  â””â”€â”€ train MSE éƒ½é™ä¸ä¸‹å» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
      MVP 2.3: Student+error æµ‹è¯•
          â”‚
          â”œâ”€â”€ Student+error å¯æ‹Ÿåˆï¼ŒåŸ Student ä¸è¡Œ â”€â”€â”€â”€â”€â”€â”
          â”‚       â”‚                                        â”‚
          â”‚       â–¼                                        â”‚
          â”‚   âš ï¸ flux-only å­˜åœ¨ä¿¡æ¯ç“¶é¢ˆ                   â”‚
          â”‚   â†’ è·‘ Stage 4, è€ƒè™‘é‡è®¾è®¡ Teacher            â”‚
          â”‚                                                â”‚
          â””â”€â”€ ä¸¤è€…éƒ½æ‹Ÿåˆä¸å¥½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
              âŒ é«˜åº¦æ€€ç–‘ä»£ç /æ•°æ®é”™è¯¯
```

## 4.3 é˜¶æ®µ 3 å†³ç­–æµç¨‹

```
MVP 3.1: Student latent + head vs baseline
  â”‚
  â”œâ”€â”€ Student â‰¥ baseline (æ•´ä½“+å­åŒºé—´) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚       â”‚                                                â”‚
  â”‚       â–¼                                                â”‚
  â”‚   âœ… Pipeline æœ‰å®é™…ä»·å€¼                               â”‚
  â”‚   â†’ MVP 3.2/3.3 çœ‹é²æ£’æ€§å’Œæ ·æœ¬æ•ˆç‡                     â”‚
  â”‚                                                        â”‚
  â”œâ”€â”€ Student ç•¥ä½ (~0.02 RÂ²) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
  â”‚       â”‚                                                â”‚
  â”‚       â–¼                                                â”‚
  â”‚   æ£€æŸ¥ MVP 3.2 (å™ªå£° shift) / MVP 3.3 (å°æ ·æœ¬)        â”‚
  â”‚       â”‚                                                â”‚
  â”‚       â”œâ”€â”€ åœ¨æŸäº›åœºæ™¯æ›´ä¼˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
  â”‚       â”‚       â”‚                                       â”‚â”‚
  â”‚       â”‚       â–¼                                       â”‚â”‚
  â”‚       â”‚   âœ… æœ‰æ¡ä»¶ä»·å€¼ï¼Œè¯šå®è¯´æ˜ trade-off           â”‚â”‚
  â”‚       â”‚                                               â”‚â”‚
  â”‚       â””â”€â”€ é²æ£’æ€§/å°æ ·æœ¬ä¹Ÿä¸å ä¼˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚
  â”‚               â”‚                                       â”‚â”‚
  â”‚               â–¼                                       â”‚â”‚
  â”‚           âŒ å½“å‰è®¾è®¡æ€§ä»·æ¯”ä¸é«˜                       â”‚â”‚
  â”‚           è€ƒè™‘ Denoiser é‡è®¾è®¡æˆ– end-to-end          â”‚â”‚
  â”‚                                                       â”‚â”‚
  â””â”€â”€ Student ç¨³å®šä½äº baseline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
          â”‚                                                â”‚
          â–¼                                                â”‚
      âŒ å›é€€æ£€æŸ¥é˜¶æ®µ 2/1                                   â”‚
```

## 4.4 é˜¶æ®µ 4 æ’å…¥æ—¶æœº

**ä½•æ—¶è¿è¡Œé˜¶æ®µ 4 å®éªŒï¼š**

| è§¦å‘æ¡ä»¶ | è¿è¡Œå®éªŒ |
|----------|----------|
| å¯¹ error æ³„éœ²æœ‰ç–‘é—® | MVP 4.1 + 4.2 |
| ç»“æœå¥½å¾—ç¦»è°± | MVP 4.3 |
| æ‰€æœ‰æ¨¡å‹éƒ½ overfit | MVP 4.3 |
| Teacher å¼ºä½† Student å¼± | MVP 4.1 |

---

# 5. ğŸ“ é£é™©æ¸…å•ä¸éªŒæ”¶æ ‡å‡†

## 5.1 é£é™©çŸ©é˜µ

| ID | é£é™© | å¯¹åº”å‡è®¾ | åæœ | æ£€æµ‹æ–¹å¼ | çŠ¶æ€ |
|----|------|----------|------|----------|------|
| **R1** | latent å¯¹ log g ä¿¡æ¯å¾ˆå¼± | H1 | å³ä¾¿ç”¨ MLP/LightGBMï¼Œæ€§èƒ½ $\leq$ baseline | MVP 1.1 | âš ï¸ $R^2=0.28$ï¼Œæœ‰ä¿¡å·ä½†è¾ƒå¼± |
| **R2** | latent ä¿¡æ¯ä¸»è¦æ¥è‡ª error æ³„éœ² | H2 | Student æ— æ³•æ¥è¿‘ Teacher | MVP 4.1, 4.2 | TODO |
| **R3** | Student æ— æ³•æ‹Ÿåˆ latent | H3 | latent MSE éš¾ä¸‹é™ | MVP 2.1, 2.3 | TODO |
| **R4** | Denoiser æœ¬èº«æœ‰ç³»ç»Ÿ bias | H4 | log g æ¨¡å‹ç»§æ‰¿ç³»ç»Ÿè¯¯å·® | MVP 1.1 å¯è§†åŒ– | TODO |
| **R5** | Pipeline æœ‰éšè”½ bug | H5 | è¯¯åˆ¤ã€Œlatent å¾ˆå¼ºã€ | MVP 4.3 | TODO |
| **R6** | è®¡ç®—èµ„æºä¸è¶³ | H6 | éœ€å¤§æ”¹ pipeline | é¢„ä¼°å­˜å‚¨/è®¡ç®—é‡ | âœ… |

## 5.2 æ€»ä½“éªŒæ”¶æ ‡å‡†

| é˜¶æ®µ | æ ¸å¿ƒéªŒæ”¶æ ‡å‡† | Pass/Fail |
|------|--------------|-----------|
| Stage 1 | Teacher latent + Linear $R^2 \geq 0.5$ for $\log g$ | âŒ **$R^2 = 0.22$ï¼ˆçº¿æ€§å¼±ï¼‰** |
| Stage 1b | Teacher latent + LightGBM $R^2 \geq 0.25$ for $\log g$ | âœ… **$R^2 = 0.28$** |
| Stage 2 | Student-Teacher cosine sim $\geq 0.9$ï¼›Student latent log g $R^2 \geq$ Teacher çš„ 90% | TODO |
| Stage 3 | Student latent + head $R^2 \geq$ raw flux baseline æˆ–åœ¨é²æ£’æ€§/sample efficiency æœ‰æ˜æ˜¾ä¼˜åŠ¿ | TODO |
| Stage 4 | å» error å $\Delta R^2 < 0.1$ï¼›label shuffle å $R^2 \approx 0$ | TODO |

### Stage 1 è¯¦ç»†ç»“æœï¼ˆæ›´æ–° 2025-12-01ï¼‰

**100k Train + 1k Independent Test (LightGBM leaves=15, trees=50)**ï¼š

| ç›®æ ‡å‚æ•° | Ridge $R^2$ | LightGBM $R^2$ | éªŒæ”¶çŠ¶æ€ |
|----------|-------------------|-----------------|----------|
| $T_{\text{eff}}$ | 0.9702 | **0.9775** | âœ… é€šè¿‡ |
| [M/H] | 0.9444 | **0.9599** | âœ… é€šè¿‡ |
| $\log g$ | 0.2192 | **0.2830** | âš ï¸ çº¿æ€§å¼±ï¼ŒLGBM æ”¹å–„ |
| [$\alpha$/M] | 0.1161 | **0.1908** | âš ï¸ ä¿¡å·è¾ƒå¼± |
| [C/M] | 0.0988 | **0.1396** | âŒ ä¿¡å·æå¼± |

---

# 6. ğŸ“ é™„å½•ï¼šæœ€å°å®ç°å»ºè®®

## 6.1 è·å– Teacher latent å¹¶æ„é€ æ–°æ•°æ®é›†

### æ–¹æ³• 1ï¼šä¿®æ”¹ Encoder forward

```python
class Encoder(nn.Module):
    def forward(self, x_noisy, sigma):
        # ... åŸæœ‰ä»£ç  ...
        z = self.latent_layer(features)
        return z  # ç›´æ¥è¿”å› latent
```

### æ–¹æ³• 2ï¼šä½¿ç”¨ forward hook

```python
latent_storage = []

def hook_fn(module, input, output):
    latent_storage.append(output.detach())

encoder.latent_layer.register_forward_hook(hook_fn)
```

### ç¦»çº¿ç”Ÿæˆ Teacher latent

```python
encoder.eval()
all_z, all_x, all_sigma, all_logg = [], [], [], []

with torch.no_grad():
    for batch in loader:
        x_noisy = batch["flux"].to(device)
        sigma = batch["err"].to(device)
        logg = batch["logg"]
        
        z_teacher = encoder(x_noisy, sigma)  # å†»ç»“çš„ encoder
        
        all_z.append(z_teacher.cpu())
        all_x.append(x_noisy.cpu())
        all_sigma.append(sigma.cpu())
        all_logg.append(logg.cpu())

# ä¿å­˜å¢å¼ºæ ‡æ³¨æ•°æ®é›†
np.savez("teacher_latent_dataset.npz",
         z_teacher=torch.cat(all_z).numpy(),
         x_noisy=torch.cat(all_x).numpy(),
         sigma=torch.cat(all_sigma).numpy(),
         logg=torch.cat(all_logg).numpy())
```

## 6.2 Student è®­ç»ƒæœ€å°å®ç°

### Student æ¨¡å‹å®šä¹‰

```python
class StudentMLP(nn.Module):
    def __init__(self, input_dim, latent_dim, hidden_dims=[1024, 1024, 512]):
        super().__init__()
        layers = []
        prev_dim = input_dim
        for h_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, h_dim),
                nn.GELU(),
                nn.Dropout(0.1)
            ])
            prev_dim = h_dim
        layers.append(nn.Linear(prev_dim, latent_dim))
        self.mlp = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.mlp(x)
```

### çº¯è’¸é¦è®­ç»ƒ

```python
student = StudentMLP(input_dim=D, latent_dim=L).to(device)
optimizer = torch.optim.AdamW(student.parameters(), lr=1e-4)

for epoch in range(num_epochs):
    for batch in loader:
        x_noisy = batch["flux"].to(device)
        z_teacher = batch["z_teacher"].to(device)
        
        z_student = student(x_noisy)
        loss = F.mse_loss(z_student, z_teacher)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

### è”åˆè®­ç»ƒï¼ˆè’¸é¦ + log gï¼‰

```python
class StudentWithHead(nn.Module):
    def __init__(self, student, head):
        super().__init__()
        self.student = student
        self.head = head
    
    def forward(self, x):
        z = self.student(x)
        y = self.head(z)
        return z, y

# è®­ç»ƒå¾ªç¯
for batch in loader:
    x_noisy = batch["flux"].to(device)
    z_teacher = batch["z_teacher"].to(device)
    logg = batch["logg"].to(device)
    
    z_student, logg_pred = model(x_noisy)
    
    loss_z = F.mse_loss(z_student, z_teacher)
    loss_y = F.mse_loss(logg_pred, logg)
    loss = lambda_z * loss_z + lambda_y * loss_y
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

## 6.3 ä¸ç°æœ‰ ML pipeline è¡”æ¥

### ç¡®ä¿å…¬å¹³å¯¹æ¯”

```python
# ä½¿ç”¨ç›¸åŒçš„ train/test åˆ’åˆ†
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42  # å›ºå®šéšæœºç§å­
)

# ä¿å­˜åˆ’åˆ†ç´¢å¼•ï¼Œä¾›æ‰€æœ‰å®éªŒä½¿ç”¨
np.save("train_idx.npy", train_idx)
np.save("test_idx.npy", test_idx)
```

### Student latent + LightGBMï¼ˆå¯é€‰å¯¹æ¯”ï¼‰

```python
import lightgbm as lgb

# æå– Student latent
student.eval()
with torch.no_grad():
    z_train = student(X_train_tensor).numpy()
    z_test = student(X_test_tensor).numpy()

# ç”¨ LightGBM æ›¿ä»£çº¿æ€§ head
lgb_model = lgb.LGBMRegressor(n_estimators=50, num_leaves=15)
lgb_model.fit(z_train, y_train)
y_pred = lgb_model.predict(z_test)

# å¯¹æ¯”ï¼šraw flux + LightGBM
lgb_baseline = lgb.LGBMRegressor(n_estimators=50, num_leaves=15)
lgb_baseline.fit(X_train, y_train)
y_pred_baseline = lgb_baseline.predict(X_test)
```

## 6.4 è®¡ç®—èµ„æºä¼°ç®—

| èµ„æº | ä¼°ç®—æ–¹æ³• | ç¤ºä¾‹ |
|------|----------|------|
| Latent å­˜å‚¨ | $N \times L \times 4$ bytes (float32) | 100k Ã— 48 Ã— 4 = 19 MB |
| Student è®­ç»ƒ | batch_size Ã— forward/backward | ~1-2 GB GPU |
| ç¦»çº¿ç”Ÿæˆ latent | ä¸€æ¬¡æ€§éå†æ•°æ®é›† | ~30 min (100k samples) |

---

## 6.5 ç›¸å…³æ–‡ä»¶

### ğŸ“‘ å®éªŒæŠ¥å‘Š

| ç±»å‹ | è·¯å¾„ | çŠ¶æ€ |
|------|------|------|
| **Stage A æŠ¥å‘Š** | [exp_error_info_decomposition_20251201.md](./exp_error_info_decomposition_20251201.md) | ğŸ”„ è¿›è¡Œä¸­ |
| **MVP 1.1 æŠ¥å‘Š** | [exp_linear_probe_latent_20251130.md](./exp_linear_probe_latent_20251130.md) | âœ… å·²å®Œæˆï¼ˆå« 100k æ‰©å±•ï¼‰ |
| **MVP 1.4 æŠ¥å‘Š** | [exp_latent_extraction_logg_20251201.md](./exp_latent_extraction_logg_20251201.md) | âœ… å·²å®Œæˆï¼ˆRÂ²=0.55ï¼‰ |
| **MVP 2.2 æŠ¥å‘Š** | [exp_encoder_nn_logg_20251201.md](./exp_encoder_nn_logg_20251201.md) | âœ… å®Œæˆ (Test RÂ²=0.6117, +10.9% vs Ridge) |

### ğŸ’¬ GPT ä¼šè¯å½’æ¡£

| ä¼šè¯ | è·¯å¾„ | äº§å‡º |
|------|------|------|
| ç ”ç©¶æ–¹å‘åˆå§‹åŒ– | [session_20251130_distill_latent_probe.md](./sessions/session_20251130_distill_latent_probe.md) | MVP 1.1-1.4 |
| Encoder+NN è®¾è®¡ | [session_20251201_distill_encoder_nn.md](./sessions/session_20251201_distill_encoder_nn.md) | MVP 2.2 |

### ğŸ“¦ æ•°æ®ä¸æ¨¡å‹

| ç±»å‹ | è·¯å¾„ | çŠ¶æ€ |
|------|------|------|
| åŸå§‹å®éªŒæ•°æ® | `/home/swei20/Physics_Informed_AI/raw_blindspot/linear_probe_report.md` | âœ… |
| å›¾è¡¨ç›®å½• | `logg/distill/img/` | - |
| Denoiser æ¨¡å‹ | `evals/m215l9e48k25s1bn1d1ep5000.ckpt` | âœ… |
| Latent ç‰¹å¾ (1k) | `evals/latent_probe.pt` | âœ… |
| Latent ç‰¹å¾ (32k) | `evals/latent_probe_32k.pt` | âœ… |
| Latent ç‰¹å¾ (100k train) | `evals/latent_probe_train_100k.pt` | âœ… |
| Latent ç‰¹å¾ (1k test) | `evals/latent_probe_test_1k.pt` | âœ… |
| å±‚æ¿€æ´» (train) | `evals/layer_features_train_100k.pt` | âœ… å·²ç”Ÿæˆ |
| å±‚æ¿€æ´» (test) | `evals/layer_features_test_1k.pt` | âœ… å·²ç”Ÿæˆ |
| æ•°æ®é›† | `/datascope/.../bosz50000/mag215/` | âœ… |
| **ä»£ç å®ç°** | `/home/swei20/BlindSpotDenoiser/src/logg_from_encoder.py` | âœ… å·²å®ç° |
| **è®­ç»ƒè„šæœ¬** | `/home/swei20/BlindSpotDenoiser/experiments/train_logg_from_encoder.py` | âœ… å·²å®ç° |

### ğŸ”— è·¨ç³»ç»Ÿé“¾æ¥

| ç±»å‹ | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| å®éªŒçœ‹æ¿ | [status/kanban.md](../../status/kanban.md) | Distill å®éªŒçŠ¶æ€ |
| ä¸‹ä¸€æ­¥è®¡åˆ’ | [status/next_steps.md](../../status/next_steps.md) | æ—¥å¸¸ä»»åŠ¡ |
| GTA è”åŠ¨ | [logg/gta/gta_main_20251130.md](../gta/gta_main_20251130.md) | Latent ç‰¹å¾ç»™ GTA |

---

## ğŸ“‹ å®éªŒè¿›åº¦è¿½è¸ª

> **âš ï¸ æ—¥å¸¸ä»»åŠ¡è¿½è¸ª**ï¼šè¯·ä½¿ç”¨ [status/kanban.md](../../status/kanban.md)  
> **æœ¬èŠ‚ä»…è®°å½•**ï¼šå®éªŒæ€»è§ˆ + ç»“æœåŒæ­¥

### Stage Aï¼šä¿¡æ¯æ¥æºåˆ†è§£ï¼ˆæ–°å¢ 2025-12-01ï¼‰

| MVP | åç§° | experiment_id | çŠ¶æ€ | ç»“æœ |
|-----|------|---------------|------|------|
| A.1 | Error-only Baseline | - | ğŸ”² å¾…åš | - |
| A.2 | æ®‹å·®å®šä¹‰ä¸è®¡ç®— | - | ğŸ”² å¾…åš | - |
| A.3 | Flux â†’ æ®‹å·®é¢„æµ‹ | - | ğŸ”² å¾…åš | - |
| A.4 | Latent â†’ æ®‹å·®é¢„æµ‹ | - | ğŸ”² å¾…åš | - |

**æŠ¥å‘Š**ï¼š[exp_error_info_decomposition_20251201.md](./exp_error_info_decomposition_20251201.md)

### Stage 1-4ï¼šåŸæœ‰å®éªŒ

| MVP | åç§° | experiment_id | çŠ¶æ€ | ç»“æœ | exp.md |
|-----|------|---------------|------|------|--------|
| 1.1 | Linear Probe | `BS-20251130-distill-probe-01` | âœ… å®Œæˆ | Ridge $R^2 = 0.22$ | [é“¾æ¥](./exp_linear_probe_latent_20251130.md) |
| 1.1b | LightGBM Probe | `BS-20251130-distill-probe-01` | âœ… å®Œæˆ | LGBM $R^2 = 0.28$ (+29%) | [é“¾æ¥](./exp_linear_probe_latent_20251130.md) |
| 1.2 | å™ªå£°é²æ£’æ€§ | - | ğŸ”² å¾…åš | - | - |
| 1.3 | Latent ç»´åº¦æ‰«æ | - | ğŸ”² å¯é€‰ | - | - |
| 1.4 | Latent æå–ä¼˜åŒ– | `BS-20251201-distill-latent-01` | âœ… å®Œæˆ | **$R^2 = 0.5516$ (+150%)** | [é“¾æ¥](./exp_latent_extraction_logg_20251201.md) |
| 2.1 | Student è’¸é¦ | - | ğŸ”² å¾…åš | - | - |
| **2.2** | **Encoder + NN** | `BS-20251201-encoder-logg-01` | âœ… å®Œæˆ | **$R^2 = 0.6117$ (+10.9%)** | [é“¾æ¥](./exp_encoder_nn_logg_20251201.md) |
| 2.3 | Fine-tune encoder | `BS-20251201-distill-finetune-01` | â³ TODO | - | - |

---

> **ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼ˆä¼˜å…ˆçº§æ’åºï¼Œæ›´æ–°äº 2025-12-01ï¼‰ï¼š
> 
> 1. **ğŸ”¥ MVP 2.2ï¼ˆè¿›è¡Œä¸­ï¼‰**ï¼šEncoder + NN End-to-End Training
>    - **å·²å®Œæˆ**ï¼šå®Œæ•´è®­ç»ƒæ¡†æ¶å®ç° + ç«¯åˆ°ç«¯è®­ç»ƒ
>    - **æœ€ç»ˆç»“æœ**ï¼šå†»ç»“ encoder + MLP headï¼Œ**Test RÂ² = 0.6117**ï¼ˆæ¯” Ridge baseline 0.5516 æå‡ 10.9%ï¼‰
>    - **ç»“è®º**ï¼šMLP èƒ½æ•æ‰ encoder ç‰¹å¾ä¸ log_g ä¹‹é—´çš„éçº¿æ€§å…³ç³»
>    - è¯¦ç»†æŠ¥å‘Šï¼š[exp_encoder_nn_logg_20251201.md](./exp_encoder_nn_logg_20251201.md)
>
> 2. **Stage A**ï¼šä¿¡æ¯æ¥æºåˆ†è§£
>    - **é—®é¢˜**ï¼šError å•ç‹¬é¢„æµ‹ $\log g$ è¾¾ $R^2 \approx 0.91$ï¼Œéœ€è¦åˆ†ç¦» error æ·å¾„
>    - **ç›®æ ‡**ï¼šéªŒè¯ latent çš„ $\log g$ ä¿¡æ¯æ˜¯æ¥è‡ª error è¿˜æ˜¯ flux
>    - è¯¦ç»†æŠ¥å‘Šï¼š[exp_error_info_decomposition_20251201.md](./exp_error_info_decomposition_20251201.md)
>
> 3. **âœ… MVP 1.4ï¼ˆå·²å®Œæˆï¼‰**ï¼šLatent æå–æ–¹å¼ä¼˜åŒ–
>    - **ç»“æœ**ï¼š$\log g$ Test $R^2 = 0.5516$ï¼ˆ+150%ï¼‰
>    - **æœ€ä½³é…ç½®**ï¼š`enc_pre_latent + seg_mean_K8`ï¼ˆ384 ç»´ï¼‰
>    - è¯¦ç»†æŠ¥å‘Šï¼š[exp_latent_extraction_logg_20251201.md](./exp_latent_extraction_logg_20251201.md)
>    
> 4. **MVP 2.3ï¼ˆå¾…åšï¼‰**ï¼šFine-tune encoder
>    - å¼€æ”¾ encoder è®­ç»ƒï¼Œæµ‹è¯•æ€§èƒ½æ˜¯å¦è¶…è¿‡ Ridge baseline
>    - ç›®æ ‡ï¼šval $R^2 \geq 0.55$
> 
> 5. **MVP 1.2**ï¼šè·¨å™ªå£°çº§åˆ«æµ‹è¯• latent é²æ£’æ€§ï¼ˆå¯å¹¶è¡Œï¼‰


# Oracle MoE @ noise=1 Structure Bonus Verification (1M Data)

---

| å­—æ®µ | å€¼ |
|------|-----|
| **Experiment ID** | SCALING-20251223-oracle-moe-noise1-01 |
| **MVP** | MVP-16A-0 (ğŸ”´ P0 Highest Priority) |
| **Date** | 2025-12-23 |
| **Status** | âœ… Completed |
| **Script** | `~/VIT/scripts/scaling_oracle_moe_noise1.py` |

---

## ğŸ¯ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆ

| Metric | Value | Threshold | Status |
|--------|-------|-----------|--------|
| **Global Ridge RÂ²** | 0.4611 | ~0.5 | baseline (Î±=100000) |
| **Oracle MoE RÂ²** | **0.6249** | > 0.55 | âœ… PASS |
| **Î”RÂ²** | **+0.1637** | â‰¥ 0.03 | âœ… **STRONG PASS** |
| **Coverage** | 83.5% | - | - |
| **Train Size** | 1,000,000 | 1M | âœ… |

### ğŸ”¥ Decision

> **âœ… STRONG STRUCTURE BONUS: Î”RÂ² = +0.16 >> 0.03 threshold**
> 
> MoE è·¯çº¿ç»§ç»­! Proceed with MVP-16A-1, MVP-16A-2 (trainable gate development)

---

## ğŸ“Š Per-bin Analysis (Teff Ã— [M/H])

| Bin | Teff | [M/H] | n_train | n_test | Oracle RÂ² | Global RÂ² | Î”RÂ² |
|-----|------|-------|---------|--------|-----------|-----------|-----|
| 0 | Cool | Metal-poor | 88,666 | 93 | 0.5433 | 0.3505 | +0.1927 âœ… |
| 1 | Cool | Solar | 89,050 | 85 | 0.7956 | 0.6496 | +0.1459 âœ… |
| 2 | Cool | Metal-rich | 62,702 | 71 | 0.8466 | 0.7626 | +0.0840 âœ… |
| 3 | Mid | Metal-poor | 102,801 | 89 | 0.3070 | 0.1376 | +0.1694 âœ… |
| 4 | Mid | Solar | 102,864 | 111 | 0.5833 | 0.5453 | +0.0380 âœ… |
| 5 | Mid | Metal-rich | 71,516 | 62 | 0.8742 | 0.7716 | +0.1026 âœ… |
| 6 | Hot | Metal-poor | 116,727 | 117 | 0.4470 | 0.2762 | +0.1707 âœ… |
| 7 | Hot | Solar | 115,778 | 126 | 0.6006 | 0.5466 | +0.0540 âœ… |
| 8 | Hot | Metal-rich | 80,717 | 81 | 0.8245 | 0.6745 | +0.1500 âœ… |

### Key Observations

1. **All 9 bins show positive Î”RÂ²** - Oracle MoE outperforms Global Ridge in every bin!
2. **Metal-rich bins perform best**: RÂ² = 0.82-0.87
3. **Bin 3 (Mid/Metal-poor)** is hardest: Oracle RÂ² = 0.3070 (but still +0.17 over global!)
4. **Bin 5 (Mid/Metal-rich)** is best: Oracle RÂ² = 0.8742
5. **Metal-poor bins show largest Î”RÂ²**: Bins 0, 3, 6 have Î”RÂ² = 0.17-0.19

---

## ğŸ”¬ Hypothesis Verification

| Hypothesis | Expected | Actual | Status |
|------------|----------|--------|--------|
| **H-A0.1**: Î”RÂ² â‰¥ 0.03 vs Global Ridge | â‰¥ 0.03 | +0.1637 | âœ… **PASS** |
| **H4.1.1**: Oracle MoE RÂ² > 0.55 @ noise=1 | > 0.55 | 0.6249 | âœ… **PASS** |

---

## ğŸ“ˆ Plots

### Plot 1: Oracle MoE vs Global Ridge Comparison
![scaling_oracle_moe_comparison.png](../img/scaling_oracle_moe_comparison.png)

### Plot 2: Per-bin RÂ² Heatmap (Teff Ã— [M/H])
![scaling_oracle_moe_perbin_r2.png](../img/scaling_oracle_moe_perbin_r2.png)

### Plot 3: Per-bin Comparison (Oracle vs Global)
![scaling_oracle_moe_perbin_comparison.png](../img/scaling_oracle_moe_perbin_comparison.png)

### Plot 4: Prediction vs True log_g
![scaling_oracle_moe_pred_vs_true.png](../img/scaling_oracle_moe_pred_vs_true.png)

---

## âš™ï¸ Experiment Configuration

```yaml
data:
  source: BOSZ simulated spectra (mag205_225_lowT_1M)
  train_size: 1,000,000 (5 shards Ã— 200k)
  test_size: 1,000 (test_1k_0)
  feature_dim: 4096 (MR arm)
  target: log_g

noise:
  level: 1.0
  formula: noisy = flux + noise_level * error * N(0,1)

model:
  type: Ridge Regression (with StandardScaler)
  alpha: 100000 (fixed)

bins:
  teff_boundaries: [3750, 4500, 5250, 6000]  # 3 bins
  mh_boundaries: [-2.0, -1.0, 0.0, 0.5]      # 3 bins
  total: 9 bins (3Ã—3)
```

---

## ğŸ“ Output Files

| Type | Path |
|------|------|
| Script | `~/VIT/scripts/scaling_oracle_moe_noise1.py` |
| Results CSV | `~/VIT/results/scaling_oracle_moe/results.csv` |
| Per-bin CSV | `~/VIT/results/scaling_oracle_moe/per_bin_results.csv` |
| Metadata | `~/VIT/results/scaling_oracle_moe/metadata.json` |
| Images | `/home/swei20/Physics_Informed_AI/logg/scaling/img/scaling_oracle_moe_*.png` |

---

## ğŸ”— Related Experiments

- **MVP-1.4** (noise=0.2): Oracle Î”RÂ² â‰ˆ +0.050
- **SCALING-20251222-ml-ceiling-01**: Ridge RÂ² = 0.50 @ 1M, noise=1, Î±=5000
- **Next**: MVP-16A-1 (trainable gate with physical features)

---

## ğŸ“ Notes

1. **1M data improves both Global and Oracle**: Compared to 100k results, both models improve.

2. **Metal-poor bins benefit most from per-bin training**: Î”RÂ² = 0.17-0.19 in bins 0, 3, 6.

3. **Structure bonus is large at high noise**: 
   - noise=0.2: Î”RÂ² â‰ˆ +0.05
   - noise=1.0: Î”RÂ² = **+0.16**
   
   This confirms MoE benefits more under high-noise conditions.

4. **Global Ridge RÂ² = 0.46 vs expected 0.50**: Slight discrepancy with ml_ceiling results, possibly due to different random seeds or test/train split. The structure bonus conclusion remains robust.

---

## âœ… Conclusion

**Oracle MoE demonstrates very strong structure bonus at noise=1 with 1M data:**

- Î”RÂ² = +0.1637 (5.5Ã— higher than 0.03 threshold)
- RÂ² = 0.6249 (exceeds 0.55 target)
- All 9 bins show improvement!

**Decision: Continue MoE development (MVP-16A-1, A-2)**

The next step is to develop a trainable gate that can approach Oracle performance using physical features (Ca II, Na I, PCA components).

---

*Generated: 2025-12-23 (1M data, Î±=100000)*

---

## ğŸ“Š Additional Visualizations (2025-12-24)

### Plot 5: Î”RÂ² Structure Bonus Heatmap
![moe_delta_r2_heatmap.png](../img/moe_delta_r2_heatmap.png)

*Metal-poor bins (left column) show largest structural bonus (+0.17~0.19)*

### Plot 6: Sample Distribution per Bin
![moe_sample_distribution.png](../img/moe_sample_distribution.png)

*Training samples range from 63k to 117k per bin; test samples 62-126*

### Plot 7: Per-Bin RÂ² Grouped Comparison
![moe_perbin_r2_grouped.png](../img/moe_perbin_r2_grouped.png)

*All 9 bins show Oracle Expert outperforming Global Ridge*

### Plot 8: MAE Heatmap (Oracle Expert)
![moe_mae_heatmap.png](../img/moe_mae_heatmap.png)

*Metal-rich bins have lowest MAE (0.32-0.38); Metal-poor bins highest (0.63-0.81)*

### Plot 9: Oracle MoE Dashboard
![moe_oracle_dashboard.png](../img/moe_oracle_dashboard.png)

*Comprehensive summary: RÂ² comparison, Î”RÂ² by bin, Oracle vs Global heatmaps*

### Plot 10: Noise Amplification Effect
![moe_noise_amplification.png](../img/moe_noise_amplification.png)

*MoE structural bonus is 3.3Ã— larger at noise=1.0 vs noise=0.2*

---

*Plots added: 2025-12-24*

---

## ğŸ“ é™„å½•

### 6.2 å®éªŒæµç¨‹è®°å½•

#### 6.2.1 ç¯å¢ƒä¸é…ç½®

| é¡¹ç›® | å€¼ |
|------|-----|
| **ä»“åº“** | `~/VIT` |
| **è„šæœ¬è·¯å¾„** | `scripts/scaling_oracle_moe_noise1.py` |
| **è¾“å‡ºè·¯å¾„** | `results/scaling_oracle_moe/` |
| **Python** | 3.10 |
| **ä¸»è¦ä¾èµ–** | sklearn, numpy, pandas, matplotlib, seaborn, h5py |

#### 6.2.2 æ‰§è¡Œå‘½ä»¤

```bash
cd ~/VIT
source init.sh

# è¿è¡Œå®éªŒï¼ˆ1M æ•°æ®ï¼‰
python scripts/scaling_oracle_moe_noise1.py

# è¾“å‡ºæ–‡ä»¶
# - results/scaling_oracle_moe/results.csv
# - results/scaling_oracle_moe/per_bin_results.csv
# - results/scaling_oracle_moe/metadata.json
# - å›¾è¡¨è‡ªåŠ¨ä¿å­˜åˆ°çŸ¥è¯†ä¸­å¿ƒ
```

#### 6.2.3 å…³é”®é…ç½®

```python
# æ•°æ®è·¯å¾„
DATA_ROOT = "/datascope/subaru/user/swei20/data/bosz50000/z0/mag205_225_lowT_1M"
TRAIN_SHARDS = [f"{DATA_ROOT}/train_200k_{i}/dataset.h5" for i in range(5)]
TEST_FILE = f"{DATA_ROOT}/test_1k_0/dataset.h5"

# å™ªå£°é…ç½®
NOISE_LEVEL = 1.0  # é«˜å™ªå£°åœºæ™¯

# Ridge é…ç½®
RIDGE_ALPHA = 100000  # æ²¿ç”¨ MVP-1.4 æœ€ä¼˜å€¼

# 9-bin åˆ’åˆ†
TEFF_BINS = [3750, 4500, 5250, 6000]  # 3 Teff bins
MH_BINS = [-2.0, -1.0, 0.0, 0.5]      # 3 [M/H] bins
```

#### 6.2.4 ä»£ç å¼•ç”¨

| å‚è€ƒè„šæœ¬ | å¯å¤ç”¨å‡½æ•° | è¯´æ˜ |
|---------|-----------|------|
| `~/VIT/scripts/moe_9expert_phys_gate.py` | `assign_bins()` | 9-bin åˆ’åˆ†é€»è¾‘ |
| `~/VIT/scripts/scaling_ml_ceiling_experiment.py` | `load_shards()`, noise æ·»åŠ  | 1M æ•°æ®åŠ è½½ç®¡é“ |

---

*å®éªŒæµç¨‹è®°å½•æ·»åŠ : 2025-12-24*

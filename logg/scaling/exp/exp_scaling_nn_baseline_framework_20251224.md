# ğŸ“˜ SCALING-20251224-nn-baseline-framework-01: NN Baseline Framework

> **Name:** NN Baseline Framework | **ID:** `SCALING-20251224-nn-baseline-framework-01`  
> **Topic:** `scaling` | **MVP:** MVP-NN-0 | **Project:** `VIT`  
> **Author:** Viska Wei | **Date:** 2025-12-24 | **Status:** âœ… Done
> **éªŒè¯å‡è®¾:** H-NN0.1 (NN æ¡†æ¶èƒ½å¤ç° ML baseline)

---

## âš¡ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆ

> **ä¸€å¥è¯æ€»ç»“**: MLP (flux_only) è¾¾åˆ° Ridge baselineï¼Œä½† CNN å¼±äº MLPï¼›**Whitening é¢„å¤„ç†å¯¼è‡´è®­ç»ƒå®Œå…¨å´©æºƒ**ã€‚

| é¡¹ç›® | ç»“è®º |
|------|------|
| **å‡è®¾éªŒè¯** | âœ… H-NN0.1: MLP è¾¾åˆ° Ridge baseline (RÂ²=0.467 â‰ˆ 0.46) |
| **å…³é”®å‘ç°** | âŒ Whitening (flux/error) å¯¼è‡´ RÂ²â‰ˆ0ï¼Œæ‰€æœ‰ NN å¿…é¡»ç”¨ flux_only è¾“å…¥ |
| **æœ€ä½³é…ç½®** | MLP 3L_1024 + flux_only + GELU: RÂ²=0.4671, MAE=0.645 |
| **vs Oracle gap** | -0.15 (Oracle MoE=0.62, best NN=0.47) |
| **è®¾è®¡å¯ç¤º** | 1) NN è®­ç»ƒæ¡†æ¶æ­£å¸¸ï¼›2) CNN éœ€æ›´å¤šè°ƒå‚ï¼›3) ä¸‹ä¸€æ­¥ä¿®å¤ MLP 1M |

---

## ğŸ”— Upstream Links

| Type | Link |
|------|------|
| ğŸ§  Hub | [`scaling_hub_20251222.md`](../scaling_hub_20251222.md) |
| ğŸ—ºï¸ Roadmap | [`scaling_roadmap_20251222.md`](../scaling_roadmap_20251222.md) |

---

## ğŸ“ å®éªŒè®¾è®¡

### æ•°æ®é…ç½®

| é¡¹ç›® | é…ç½® |
|------|------|
| **æ•°æ®é›†** | BOSZ 50000, mag205_225_lowT_1M |
| **è®­ç»ƒè§„æ¨¡** | 100k (smoke test) / 1M (full) |
| **æµ‹è¯•é›†** | 1000 samples (å›ºå®š) |
| **å™ªå£°æ°´å¹³** | Ïƒ=1.0 (heteroscedastic Gaussian) |
| **ç›®æ ‡å˜é‡** | log_g âˆˆ [1.0, 5.0] |
| **è¾“å…¥ç»´åº¦** | 4096 (MR arm å…‰è°±) |

### è¾“å…¥å˜ä½“

| Input Mode | æè¿° | ç»“æœ |
|------------|------|------|
| **flux_only** | åŸå§‹ flux | âœ… æ­£å¸¸å·¥ä½œ |
| **whitening** | flux / (error Ã— Ïƒ) | âŒ è®­ç»ƒå´©æºƒ (RÂ²â‰ˆ0) |

### æ¨¡å‹æ¶æ„

| ç±»å‹ | æ¶æ„ | å‚æ•°é‡ | å¤‡æ³¨ |
|------|------|--------|------|
| MLP 3L_1024 | [1024, 512, 256] + GELU + Dropout | 4.85M | **æœ€ä½³é…ç½®** |
| MLP 3L_2048 | [2048, 1024, 512] + GELU + Dropout | 11.0M | ç•¥ä½äº 3L_1024 |
| CNN 4L_k5_bn | Conv1DÃ—4 + BatchNorm + MLP head | 60.5k | CNN ä¸­æœ€ä½³ |
| CNN 4L_k5_wide | [32, 64, 128, 128] channels | 150k | 1M ä¸Šè¡¨ç°å°šå¯ |

### è®­ç»ƒé…ç½®

| é¡¹ç›® | 100k é…ç½® | 1M é…ç½® |
|------|-----------|---------|
| Epochs | 20 | 10 |
| Batch Size | 1024 | 2048 |
| Learning Rate | 1e-3 | 5e-4 |
| Weight Decay | 1e-4 | 1e-4 |
| Optimizer | AdamW | AdamW |
| Scheduler | CosineAnnealing | CosineAnnealing |
| Early Stopping | patience=10 | patience=10 |

---

## ğŸ“Š å®éªŒç»“æœ

### Summary Table

| Group | Model | Input | Test RÂ² | MAE | vs Ridge | vs Oracle MoE |
|-------|-------|-------|---------|-----|----------|---------------|
| **MLP_100k** | mlp_3L_1024 | flux_only | **0.4671** | 0.645 | +0.007 âœ… | -0.153 |
| CNN_100k | cnn_4L_k5_bn | flux_only | 0.4122 | 0.704 | -0.048 | -0.208 |
| MLP_1M | mlp_2L_2048 | whitening | -0.0003 | 0.978 | -0.500 âŒ | -0.620 |
| **CNN_1M** | cnn_4L_k5_wide | whitening | **0.4337** | 0.681 | -0.066 | -0.186 |

### Baselines

| Model | RÂ² (100k) | RÂ² (1M) |
|-------|-----------|---------|
| Ridge | 0.46 | 0.50 |
| LightGBM | 0.50 | 0.57 |
| Oracle MoE | - | 0.62 |

---

## ğŸ” å…³é”®å‘ç°

### C1: MLP è¾¾åˆ° Ridge Baseline âœ…
- **å‘ç°**: MLP 3L_1024 with GELU @ 100k è¾¾åˆ° RÂ²=0.4671
- **æ„ä¹‰**: éªŒè¯ NN æ¡†æ¶æ­£å¸¸å·¥ä½œï¼Œå¯ä»¥åŒ¹é…ä¼ ç»Ÿ ML
- **å‚æ•°**: 4.8M params, 3.4min training time

### C2: CNN å¼±äº MLP âŒ
- **å‘ç°**: Best CNN RÂ²=0.4122ï¼Œä½äº MLP (0.4671)
- **åŸå› åˆ†æ**:
  1. åªæœ‰ BatchNorm ç‰ˆæœ¬èƒ½æ­£å¸¸è®­ç»ƒ
  2. å…¶ä»– CNN å˜ç§ RÂ²â‰ˆ0 (è®­ç»ƒä¸æ”¶æ•›)
  3. CNN éœ€è¦æ›´å¤šè°ƒå‚ (lr, wd, warmup)
- **ç»“è®º**: å½“å‰ CNN æ¶æ„æœªä½“ç°å±€éƒ¨å½’çº³åç½®ä¼˜åŠ¿

### C3: Whitening é¢„å¤„ç†å¤±è´¥ âš ï¸
- **å‘ç°**: `x = flux / (error Ã— noise_level)` å¯¼è‡´è®­ç»ƒå´©æºƒ
- **åŸå› **: æç«¯å€¼ (error å¾ˆå°æ—¶åˆ†æ¯æ¥è¿‘ 0)
- **å½±å“**: æ‰€æœ‰ whitening å®éªŒ RÂ²â‰ˆ0 æˆ–è´Ÿå€¼
- **å»ºè®®**: æ”¹ç”¨ StandardScaler æˆ– log(1+x) å˜æ¢

### C4: CNN 1M æœ‰æ”¹å–„ä½†ä¸æ˜¾è‘—
- **å‘ç°**: CNN @ 1M è¾¾åˆ° RÂ²=0.4337
- **vs 100k**: +0.02 RÂ² (ä» 0.41 åˆ° 0.43)
- **vs Oracle MoE**: ä»æœ‰ -0.19 gap

### C5: MLP 1M å®éªŒå¤±è´¥
- **åŸå› **: MLP ä½¿ç”¨ whitening æ¨¡å¼å¯¼è‡´å¤±è´¥
- **éœ€è¦**: ä½¿ç”¨ flux_only æ¨¡å¼é‡è·‘ MLP 1M

---

## ğŸ“ˆ å¿…é¡»è®°å½•çš„ 5 ä¸ªæ•°å­—

| # | æŒ‡æ ‡ | å€¼ |
|---|------|-----|
| 1 | **100k MLP Best RÂ²** | 0.4671 |
| 2 | **100k CNN Best RÂ²** | 0.4122 |
| 3 | **1M CNN Best RÂ²** | 0.4337 |
| 4 | **vs Oracle gap (best)** | -0.15 (MLP 100k) |
| 5 | **whitening æ•æ„Ÿåº¦** | å®Œå…¨å¤±æ•ˆ âŒ |

---

## ğŸš¦ æ­¢æŸåˆ¤æ–­

| ä¿¡å· | çŠ¶æ€ | è¡ŒåŠ¨ |
|------|------|------|
| **MLP æ­¢æŸ** | â¬œ æœªè¯„ä¼° | MLP 1M éœ€è¦ç”¨ flux_only é‡è·‘ |
| **CNN æ­¢æŸ** | âš ï¸ CNN < MLP | æ£€æŸ¥ CNN è¶…å‚é…ç½® |
| **vs Oracle MoE** | âŒ Gap = 0.15-0.19 | å•æ¨¡å‹ NN éš¾ä»¥è¾¾åˆ° 0.62 |

---

## ğŸ“¦ äº¤ä»˜ç‰©

| ç±»å‹ | è·¯å¾„ |
|------|------|
| è®­ç»ƒè„šæœ¬ | `~/VIT/scripts/run_scaling_nn_baselines.py` |
| æ•°æ®æ¨¡å— | `~/VIT/src/nn/scaling_data_adapter.py` |
| ç»“æœ CSV | `~/VIT/results/scaling_nn_baselines/scaling_nn_results.csv` |

---

## ğŸ”® ä¸‹ä¸€æ­¥å»ºè®®

1. **ä¿®å¤ MLP 1M**: ä½¿ç”¨ flux_only æ¨¡å¼é‡è·‘
2. **ä¿®å¤ whitening**: æ”¹ç”¨ StandardScaler æˆ– clamp æç«¯å€¼
3. **CNN è°ƒå‚**: å°è¯•æ›´å¤§ lr (1e-2), warmup, ä¸åŒ kernel sizes
4. **è€ƒè™‘ MoE-CNN**: å¦‚æœå•æ¨¡å‹ CNN æ— æ³•çªç ´ï¼Œå°è¯• CNN ä½œä¸º expert

---

---

## ğŸ“ é™„å½•

### 6.1 å®Œæ•´æ•°å€¼ç»“æœ

| experiment_id | model | input | test_r2 | test_mae | train_size | train_time |
|---------------|-------|-------|---------|----------|------------|------------|
| MLP_100k_3L_1024_raw | mlp_3L_1024 | flux_only | **0.4671** | 0.645 | 100k | 3.4min |
| MLP_100k_2L_2048_raw | mlp_2L_2048 | flux_only | 0.4664 | 0.650 | 100k | 3.4min |
| MLP_100k_3L_2048_raw | mlp_3L_2048 | flux_only | 0.4623 | 0.644 | 100k | 3.4min |
| MLP_100k_2L_1024_raw | mlp_2L_1024 | flux_only | 0.4518 | 0.661 | 100k | 2.6min |
| MLP_100k_3L_512_raw | mlp_3L_512 | flux_only | 0.4447 | 0.670 | 100k | 3.3min |
| CNN_100k_4L_k5_bn_raw | cnn_4L_k5_bn | flux_only | **0.4122** | 0.704 | 100k | 30min |
| CNN_100k_4L_k5_bn_wh | cnn_4L_k5_bn | whitening | 0.3434 | 0.757 | 100k | 32min |
| CNN_1M_4L_k5_wide_wh | cnn_4L_k5_wide | whitening | **0.4337** | 0.681 | 1M | 3.7h |
| MLP_1M_2L_2048_wh | mlp_2L_2048 | whitening | -0.0003 | 0.977 | 1M | 4.8min |

**Whitening å¤±è´¥æ¡ˆä¾‹ (RÂ²â‰ˆ0)**:
- MLP_100k_*_wh: å…¨éƒ¨ RÂ²â‰ˆ0 æˆ–è´Ÿå€¼
- CNN_100k_*_wh (æ—  BN): å…¨éƒ¨ RÂ²â‰ˆ0

### 6.2 å®éªŒæµç¨‹è®°å½•

**æ‰§è¡Œç¯å¢ƒ**:
```bash
cd ~/VIT
conda activate vit
```

**è®­ç»ƒè„šæœ¬è·¯å¾„**: 
`~/VIT/scripts/run_scaling_nn_baselines.py`

**æ‰§è¡Œå‘½ä»¤**:
```bash
# 100k MLP smoke test
python scripts/run_scaling_nn_baselines.py -e MLP_100k --parallel --gpus 0,1,2,3

# 100k CNN experiments
python scripts/run_scaling_nn_baselines.py -e CNN_100k --parallel --gpus 0,1,2,3

# 1M experiments
python scripts/run_scaling_nn_baselines.py -e MLP_1M,CNN_1M --parallel --gpus 0,1,2,3
```

**æ•°æ®æ¨¡å—**: `~/VIT/src/nn/scaling_data_adapter.py`

**å…³é”®ä»£ç å¼•ç”¨**:
- å®éªŒé…ç½®: `run_scaling_nn_baselines.py:86-119` (ScalingExpConfig)
- æ¨¡å‹æ„å»º: `run_scaling_nn_baselines.py:304-330` (build_model)
- è®­ç»ƒå¾ªç¯: `run_scaling_nn_baselines.py:337-465` (train_and_evaluate)

**ç»“æœ CSV**: `~/VIT/results/scaling_nn_baselines/scaling_nn_results.csv`

**å…³é”®å‘ç°è®°å½•**:
1. 2025-12-24 00:57: MLP_100k å®Œæˆï¼Œå‘ç° whitening å¯¼è‡´è®­ç»ƒå´©æºƒ
2. 2025-12-24 01:00: è¿½åŠ  flux_only å®éªŒï¼ŒMLP è¾¾åˆ° RÂ²=0.467
3. 2025-12-24 13:08: CNN å®éªŒå®Œæˆï¼Œåªæœ‰ BatchNorm ç‰ˆæœ¬èƒ½æ­£å¸¸è®­ç»ƒ
4. 2025-12-24 17:21: 1M CNN (whitening) å®Œæˆï¼ŒRÂ²=0.434

---

## ğŸ·ï¸ å…ƒæ•°æ®

```yaml
experiment_id: SCALING-20251224-nn-baseline-framework-01
project: VIT
topic: scaling
mvp: MVP-NN-0
status: completed
metrics_summary: "MLP_100k RÂ²=0.47, CNN_1M RÂ²=0.43, vs Oracle gap=-0.15~0.19"
key_insight: "Whitening preprocessing fails for all NN; flux_only required"
last_updated: 2025-12-25
```

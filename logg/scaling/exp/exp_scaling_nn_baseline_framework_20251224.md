# ğŸ“˜ Experiment Report: NN Baseline Framework (MLP + CNN)

---
> **Name:** NN Baseline Framework for logg Prediction @ noise=1  
> **ID:**  `SCALING-20251224-nn-baseline-framework-01`  
> **Topic ï½œ MVP:** `VIT` | `scaling` ï½œ MVP-NN-0, MVP-MLP-1, MVP-CNN-1  
> **Author:** Viska Wei  
> **Date:** 2025-12-24  
> **Project:** `VIT`  
> **Status:** ğŸ”„ In Progress
---

## ğŸ”— Upstream Links

| Type | Link | Description |
|------|------|-------------|
| ğŸ§  Hub | [`scaling_hub_20251222.md`](../scaling_hub_20251222.md) | H-NN0~3 å‡è®¾ |
| ğŸ—ºï¸ Roadmap | [`scaling_roadmap_20251222.md`](../scaling_roadmap_20251222.md) | MVP-NN-0~MoE-CNN-0 è®¾è®¡ |
| ğŸ“‹ Kanban | [`kanban.md`](../../../status/kanban.md) | Experiment queue |
| ğŸ“š Prerequisite | [exp_scaling_ml_ceiling](./exp_scaling_ml_ceiling_20251222.md) | MVP-1.0~1.2 ML baseline |

---
# ğŸ“‘ Table of Contents

- [âš¡ Key Findings](#-key-findings-for-hub-extraction)
- [1. ğŸ¯ Objective](#1--objective)
- [2. ğŸ§ª Experiment Design](#2--experiment-design)
- [3. ğŸ“Š Figures & Results](#3--figures--results)
- [4. ğŸ’¡ Insights](#4--insights)
- [5. ğŸ“ Conclusions](#5--conclusions)
- [6. ğŸ“ Appendix](#6--appendix)

---


## âš¡ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆï¼ˆä¾› main æå–ï¼‰

> **â³ å¾…å®éªŒå®Œæˆåå¡«å†™**

### ä¸€å¥è¯æ€»ç»“

> **TODO**

### å¯¹å‡è®¾çš„éªŒè¯

| éªŒè¯é—®é¢˜ | ç»“æœ | ç»“è®º |
|---------|------|------|
| H-NN0.1: CNN whiten 100k â‰¥ Ridge 100k RÂ² | â³ | - |
| H-MLP1.1: 100kâ†’1M æå‡ < +0.02 RÂ² â†’ MLP ä¸å¯¹ | â³ | - |
| H-CNN1.1: CNN 100k â‰¥ MLP + 0.05 RÂ² | â³ | - |
| H-CNN1.2: CNN 1M â‰¥ 0.60 | â³ | - |

### è®¾è®¡å¯ç¤ºï¼ˆ1-2 æ¡ï¼‰

| å¯ç¤º | å…·ä½“å»ºè®® |
|------|---------|
| TODO | TODO |

### å…³é”®æ•°å­—

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| MLP 100k RÂ² | â³ |
| MLP 1M RÂ² | â³ |
| CNN 100k RÂ² | â³ |
| CNN 1M RÂ² | â³ |
| Î”RÂ² (100kâ†’1M) MLP | â³ |
| Î”RÂ² (100kâ†’1M) CNN | â³ |
| vs Oracle MoE (0.62) gap | â³ |

---

# 1. ğŸ¯ ç›®æ ‡

## 1.1 å®éªŒç›®çš„

> åœ¨ noise=1 æ¡ä»¶ä¸‹ï¼Œç”¨æœ€å°æˆæœ¬å¿«é€Ÿåˆ¤æ–­ï¼š
> 1. **å•æ¨¡å‹ NN èƒ½ä¸èƒ½æ¥è¿‘/è¶…è¿‡ Oracle MoE çš„ 0.62ï¼Ÿ**
> 2. å¦‚æœä¸èƒ½ï¼šæ˜¯ **ç»“æ„ä¸å¯¹** è¿˜æ˜¯ **è¾“å…¥/å½’ä¸€åŒ–/ç›®æ ‡è®¾ç½®ä¸å¯¹**ï¼Ÿ

**æ ¸å¿ƒé—®é¢˜**ï¼šNN èƒ½å¦æ‰“ç ´ ML ceiling (Ridgeâ‰ˆ0.46, LGBâ‰ˆ0.57)ï¼Œæ¥è¿‘ Oracle MoE (0.62)ï¼Ÿ

**å›ç­”çš„é—®é¢˜**ï¼š
- Q1: MLP å…¨å±€æ¶æ„æ˜¯å¦æ³¨å®šä¸è¡Œï¼Ÿï¼ˆæ­¢æŸä¿¡å·ï¼š100kâ†’1M < +0.02 RÂ²ï¼‰
- Q2: CNN å±€éƒ¨å½’çº³åç½®æ˜¯å¦èƒ½å¸¦æ¥è´¨å˜ï¼Ÿï¼ˆCNN vs MLP â‰¥ +0.05 RÂ²ï¼Ÿï¼‰
- Q3: è¾“å…¥ whitening å¯¹ NN è®­ç»ƒçš„æ•æ„Ÿåº¦ï¼Ÿ
- Q4: å¤§æ•°æ® (1M) å¯¹ NN çš„æ”¶ç›Šå¦‚ä½•ï¼Ÿ

**å¯¹åº”å‡è®¾**ï¼š
- H-NN0.1: CNN whiten + 100k èƒ½è¾¾åˆ° Ridge æ°´å¹³
- H-MLP1.1: MLP åœ¨ 100kâ†’1M æå‡ < +0.02 â†’ æ¶æ„ä¸å¯¹
- H-CNN1.1: CNN 100k èƒ½æ˜æ˜¾è¶…è¿‡ MLP (+0.05 RÂ²)
- H-CNN1.2: CNN 1M èƒ½æ¥è¿‘ 0.60

## 1.2 é¢„æœŸç»“æœ

| åœºæ™¯ | é¢„æœŸç»“æœ | åˆ¤æ–­æ ‡å‡† |
|------|---------|---------|
| âœ… æ­£å¸¸æƒ…å†µ | CNN 1M RÂ² â‰¥ 0.58 | æ¥è¿‘ Oracle MoE (0.62) |
| âš ï¸ è­¦å‘Šæƒ…å†µ | CNN 1M RÂ² = 0.50~0.57 | æ¯” LGB ç•¥å¥½ï¼Œéœ€è¦å¤šå°ºåº¦ CNN |
| âŒ å¼‚å¸¸æƒ…å†µ A | CNN 100k < Ridge | 80% æ¦‚ç‡æ˜¯è¾“å…¥/è®­ç»ƒ bug |
| âŒ å¼‚å¸¸æƒ…å†µ B | MLP 100kâ†’1M > +0.05 RÂ² | æ„å¤–å‘ç°ï¼Œå€¼å¾—æ·±å…¥ç ”ç©¶ |

---

# 2. ğŸ§ª å®éªŒè®¾è®¡

## 2.0 æ€»ä½“åŸåˆ™ï¼ˆé¿å…"ç»“æ„ä¸å¯¹ï¼Œå †æ•°æ®æ²¡ç”¨"ï¼‰

> ğŸ”´ **å¿…é¡»å…ˆé”æ­» 3 ä¸ªå®¹æ˜“è¸©å‘çš„ç‚¹**ï¼š

### 2.0.1 è¾“å…¥ Whitening / è¯¯å·®å»ºæ¨¡ï¼ˆnoise=1 ç‰¹åˆ«é‡è¦ï¼‰

| æ–¹æ¡ˆ | å…¬å¼ | æ¨è |
|------|------|------|
| **æ–¹æ¡ˆ A (æ¨è)** | `x = flux / (error * noise_level)` | â­ |
| æ–¹æ¡ˆ B | ä¸¤é€šé“ `[flux, error]` | å¤‡é€‰ |
| æ–¹æ¡ˆ C | ä¸¤é€šé“ `[flux, 1/error]` | å¤‡é€‰ |

> å¦åˆ™ç½‘ç»œä¼šå­¦åˆ°"å™ªå£°å½¢æ€"è€Œä¸æ˜¯"è°±çº¿ä¿¡æ¯"ã€‚

### 2.0.2 è¾“å‡ºç›®æ ‡çš„å°ºåº¦

```python
# æ ‡å‡†åŒ–ç›®æ ‡ï¼Œè®­ç»ƒæ›´ç¨³å®šæ›´å¿«æ”¶æ•›
y = (logg - mean) / std
```

### 2.0.3 è¯„ä¼°è¦ç¨³å®š

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| Test set size | â‰¥ 20k |
| Random seed | å›ºå®šï¼ˆ42 æˆ–å…¶ä»–ï¼‰ |
| Stratification | æŒ‰ Teff/logg/[M/H] åˆ†æ¡¶åˆ†å±‚ |

## 2.1 æ•°æ®

### æ•°æ®æ¥æºä¸è§„æ¨¡

| é…ç½®é¡¹ | å€¼ | è¯´æ˜ |
|--------|-----|------|
| **æ•°æ®æ¥æº** | BOSZ 50000 åˆæˆå…‰è°± (mag205_225_lowT_1M) | ä¸ Oracle MoE å®éªŒä¸€è‡´ |
| **æ•°æ®æ ¹ç›®å½•** | `/datascope/subaru/user/swei20/data/bosz50000/z0/mag205_225_lowT_1M/` | |
| **è®­ç»ƒæ ·æœ¬æ•°** | **1,000,000** (5 shards Ã— 200k) | å…¨é‡è®­ç»ƒ |
| **æµ‹è¯•æ ·æœ¬æ•°** | **1,000** (test_1k_0) | ä½¿ç”¨é¢„ç”Ÿæˆçš„ noisy |
| **ç‰¹å¾ç»´åº¦** | **4096** (MR arm) | æ³¢é•¿ç‚¹æ•° âœ… |
| **æ³¢é•¿èŒƒå›´** | MR arm (ä¸­åˆ†è¾¨ç‡) | |
| **æ˜Ÿç­‰èŒƒå›´** | mag 20.5-22.5 | |
| **æ¸©åº¦èŒƒå›´** | Low T (3750-6000 K) | |
| **æ ‡ç­¾å‚æ•°** | log_g (1.00 ~ 5.00 dex) | ä¸»è¦ç›®æ ‡ |
| **è¾…åŠ©å‚æ•°** | Teff, [M/H] | ç”¨äº stratification |

### æ•°æ®æ–‡ä»¶ç»“æ„

```
/datascope/subaru/user/swei20/data/bosz50000/z0/mag205_225_lowT_1M/
â”œâ”€â”€ train_200k_0/dataset.h5   # 200k samples, 19 GB
â”œâ”€â”€ train_200k_1/dataset.h5   # 200k samples, 19 GB
â”œâ”€â”€ train_200k_2/dataset.h5   # 200k samples, 19 GB
â”œâ”€â”€ train_200k_3/dataset.h5   # 200k samples, 19 GB
â”œâ”€â”€ train_200k_4/dataset.h5   # 200k samples, 19 GB
â””â”€â”€ test_1k_0/dataset.h5      # 1k samples (é¢„ç”Ÿæˆ noisy)
```

### HDF5 æ•°æ®ç»“æ„

```
dataset.h5
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ arrays/
â”‚   â”‚   â”œâ”€â”€ flux/value      # (N, 4096) - åŸå§‹å…‰è°±é€šé‡
â”‚   â”‚   â”œâ”€â”€ error/value     # (N, 4096) - å…‰è°±è¯¯å·®
â”‚   â”‚   â”œâ”€â”€ noisy/value     # (N, 4096) - é¢„åŠ å™ªå…‰è°± (test ä½¿ç”¨)
â”‚   â”‚   â””â”€â”€ mask/value      # (N, 4096) - æ©ç 
â”‚   â””â”€â”€ params/table        # (N,) - å‚æ•°è¡¨
â””â”€â”€ spectrumdataset/
    â”œâ”€â”€ wave                # (4096,) - æ³¢é•¿
    â””â”€â”€ wave_edges          # (4097,) - æ³¢é•¿è¾¹ç•Œ
```

### å™ªå£°é…ç½®

| é…ç½®é¡¹ | å€¼ | è¯´æ˜ |
|--------|-----|------|
| **å™ªå£°ç±»å‹** | Heteroscedastic Gaussian | å¼‚æ–¹å·®é«˜æ–¯å™ªå£° |
| **å™ªå£°æ°´å¹³ noise_level** | **1.0** | æœ¬æ¬¡å®éªŒèšç„¦ |
| **è®­ç»ƒå™ªå£°** | On-the-fly | æ¯æ¬¡é‡‡æ ·é‡æ–°åŠ å™ª |
| **æµ‹è¯•å™ªå£°** | **Pre-generated** | ä½¿ç”¨ `noisy/value` å­—æ®µ |

**å™ªå£°æ·»åŠ å…¬å¼**ï¼š

```python
# Heteroscedastic Gaussian noise
noise = noise_level * error * np.random.randn(*flux.shape)
noisy = flux + noise
noisy = np.clip(noisy, 0, None)  # Clip negative values
```

### æ•°æ®é¢„å¤„ç†

| æ­¥éª¤ | é…ç½® |
|------|------|
| **è¾“å…¥å½’ä¸€åŒ–** | Whitening: `flux / (error * noise_level)` |
| **ç›®æ ‡å½’ä¸€åŒ–** | StandardScaler: `(logg - mean) / std` |
| **Stratification** | æŒ‰ Teff/logg/[M/H] åˆ†æ¡¶ååˆ†å±‚æŠ½æ · |

## 2.2 æ¨¡å‹ä¸ç®—æ³•

### 2.2.1 MVP-NN-0: å¯é åŸºçº¿æ¡†æ¶

> **ç›®çš„**ï¼šå»ºç«‹ NN è®­ç»ƒç®¡çº¿ + ä¿è¯è¾“å…¥/è¯„ä¼°æ²¡é—®é¢˜

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| **è®­ç»ƒè§„æ¨¡** | å…ˆ 100k åš smoke test |
| **é€šè¿‡æ¡ä»¶** | èƒ½å¤ç° Ridge/LGBM å¤§è‡´æ°´å¹³ï¼Œtrain/val æ›²çº¿æ­£å¸¸ |

### 2.2.2 MVP-MLP-1: æœ€å°å¯è¡Œ MLP

**æ¶æ„**ï¼š

```
Input (4096)
  â†“
Linear(4096â†’2048) â†’ LayerNorm â†’ GELU â†’ Dropout(0.1)
  â†“
Linear(2048â†’1024) â†’ GELU â†’ Dropout(0.1)
  â†“
Linear(1024â†’512) â†’ GELU â†’ Dropout(0.1)
  â†“
Linear(512â†’1)
  â†“
Output (1)
```

| è¶…å‚æ•° | å€¼ |
|--------|-----|
| weight_decay | 1e-4 |
| dropout | 0.1 |
| LayerNorm | ç¬¬ä¸€å±‚å |

**ğŸš¨ æ­¢æŸä¿¡å·**ï¼š
- å¦‚æœ **100kâ†’1M æå‡ < +0.02 RÂ²** ä¸” val æ›²çº¿ plateau å¾ˆæ—©ï¼š
  â†’ ç»“è®ºï¼š**MLP æ¶æ„å½’çº³åç½®ä¸å¯¹**ï¼Œä¸è¦å†åœ¨ MLP ä¸ŠèŠ±æ—¶é—´

### 2.2.3 MVP-CNN-1: æœ€å° 1D CNN

**æ¶æ„**ï¼š

```
Input (1, 4096)  # (C=1, L=4096)
  â†“
[Stem] Conv1d(1â†’32, k=7, stride=1) â†’ GELU
  â†“
[Block 1] Conv1d(32â†’64, k=5, dilation=1) â†’ GELU â†’ LayerNorm
          Conv1d(64â†’64, k=5, dilation=2) â†’ GELU + Residual
  â†“
[Block 2] Conv1d(64â†’64, k=5, dilation=1) â†’ GELU â†’ LayerNorm
          Conv1d(64â†’64, k=5, dilation=2) â†’ GELU + Residual
  â†“
[Block 3] Conv1d(64â†’64, k=5, dilation=1) â†’ GELU â†’ LayerNorm
          Conv1d(64â†’64, k=5, dilation=2) â†’ GELU + Residual
  â†“
[Block 4] Conv1d(64â†’64, k=5, dilation=1) â†’ GELU â†’ LayerNorm
          Conv1d(64â†’64, k=5, dilation=2) â†’ GELU + Residual
  â†“
[Pool] Global Average Pooling â†’ (64,)
  â†“
[Head] Linear(64â†’128) â†’ GELU â†’ Linear(128â†’1)
  â†“
Output (1)
```

| è¶…å‚æ•° | å€¼ |
|--------|-----|
| Normalization | LayerNorm æˆ– GroupNorm |
| Residual | ç®€å•åŠ æ³• |
| weight_decay | 1e-4 |

**æ­¢æŸä¿¡å·**ï¼š
- å¦‚æœ CNN 100k < Ridge/LGBMï¼š80% æ¦‚ç‡æ˜¯ **è¾“å…¥/whitening/è®­ç»ƒç»†èŠ‚æœ‰ bug**

### 2.2.4 MVP-CNN-2: å¤šå°ºåº¦ / å¤§æ„Ÿå—é‡ï¼ˆå¯é€‰ï¼‰

> ä»…å½“ MVP-CNN-1 æ•ˆæœä¸å¤Ÿå¥½æ—¶å¯åŠ¨

**å¢å¼ºæ–¹å¼ 1**ï¼šdilation schedule `[1, 2, 4, 8]`

**å¢å¼ºæ–¹å¼ 2**ï¼šå¤šåˆ†æ”¯å·ç§¯æ ¸ k = `[3, 7, 15]` å¹¶è¡Œåˆ†æ”¯å concatï¼ˆç±»ä¼¼ Inception1Dï¼‰

## 2.3 è¶…å‚æ•°é…ç½®

### è®­ç»ƒè¶…å‚æ•°

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| **epochs** | 10~20 (100k), 5~10 (1M) | early stop æ§åˆ¶ |
| **batch_size** | 256 æˆ– 512 | æ ¹æ® GPU å†…å­˜è°ƒæ•´ |
| **learning_rate** | 1e-3 â†’ 1e-4 | cosine schedule |
| **optimizer** | AdamW | |
| **weight_decay** | 1e-4 | L2 æ­£åˆ™ |
| **scheduler** | CosineAnnealingLR | æˆ– StepLR |
| **grad_clip** | 1.0 | å¯é€‰ |
| **early_stopping** | patience=3~5 epochs | val RÂ² ä¸æ¶¨å°±åœ |
| **random_seed** | 42 | å›ºå®š |

### æ‰«æå‚æ•°

| å®éªŒ | æ‰«æå‚æ•° | å›ºå®šå‚æ•° |
|------|---------|---------|
| MVP-NN-0 | æ— ï¼ˆéªŒè¯æ¡†æ¶ï¼‰ | 100k, whitening |
| MVP-MLP-1 | æ•°æ®è§„æ¨¡: 100k â†’ 1M | MLP æ¶æ„å›ºå®š |
| MVP-CNN-1 | æ•°æ®è§„æ¨¡: 100k â†’ 1M | CNN æ¶æ„å›ºå®š |
| MVP-CNN-2 | dilation/kernel | 1M |

## 2.4 è¯„ä»·æŒ‡æ ‡

| æŒ‡æ ‡ | å…¬å¼ | ç”¨é€” |
|------|------|------|
| $R^2$ | $1 - \frac{\sum(y - \hat{y})^2}{\sum(y - \bar{y})^2}$ | **ä¸»è¦è¯„ä»·æŒ‡æ ‡** |
| MAE | $\frac{1}{n}\sum\|y - \hat{y}\|$ | å‚è€ƒ |
| RMSE | $\sqrt{\frac{1}{n}\sum(y - \hat{y})^2}$ | å‚è€ƒ |
| Î”RÂ² (100kâ†’1M) | RÂ²_1M - RÂ²_100k | åˆ¤æ–­æ•°æ®è§„æ¨¡æ”¶ç›Š |
| plateau epoch | å¤šå°‘ epoch åˆ° plateau | åˆ¤æ–­æ”¶æ•›æ•ˆç‡ |

---

# 3. ğŸ“Š å®éªŒå›¾è¡¨

> â³ å¾…å®éªŒå®Œæˆåå¡«å†™

### å›¾ 1ï¼šMLP vs CNN Learning Curves

![TODO](./img/nn_baseline_learning_curves.png)

**Figure 1. MLP å’Œ CNN åœ¨ 100k/1M ä¸Šçš„è®­ç»ƒæ›²çº¿å¯¹æ¯”**

**å…³é”®è§‚å¯Ÿ**ï¼š
- TODO

---

### å›¾ 2ï¼šData Scaling Effect

![TODO](./img/nn_baseline_scaling.png)

**Figure 2. 100k â†’ 1M æ•°æ®è§„æ¨¡å¯¹ MLP/CNN çš„å½±å“**

**å…³é”®è§‚å¯Ÿ**ï¼š
- TODO

---

### å›¾ 3ï¼šModel Comparison (åŒ test set)

![TODO](./img/nn_baseline_comparison.png)

**Figure 3. Ridge / LGB / MLP / CNN / Oracle MoE åœ¨åŒä¸€ test set ä¸Šçš„å¯¹æ¯”**

**å…³é”®è§‚å¯Ÿ**ï¼š
- TODO

---

# 4. ğŸ’¡ å…³é”®æ´è§

> â³ å¾…å®éªŒå®Œæˆåå¡«å†™

## 4.1 å®è§‚å±‚æ´è§

TODO

## 4.2 æ¨¡å‹å±‚æ´è§

TODO

## 4.3 å®éªŒå±‚ç»†èŠ‚æ´è§

TODO

---

# 5. ğŸ“ ç»“è®º

> â³ å¾…å®éªŒå®Œæˆåå¡«å†™

## 5.1 æ ¸å¿ƒå‘ç°

> TODO

## 5.2 å…³é”®ç»“è®ºï¼ˆ2-4 æ¡ï¼‰

| # | ç»“è®º | è¯æ® |
|---|------|------|
| 1 | TODO | TODO |
| 2 | TODO | TODO |

## 5.3 è®¾è®¡å¯ç¤º

TODO

## 5.4 ç‰©ç†è§£é‡Š

TODO

## 5.5 å…³é”®æ•°å­—é€ŸæŸ¥

| æŒ‡æ ‡ | å€¼ | é…ç½®/æ¡ä»¶ |
|------|-----|----------|
| MLP 100k RÂ² | â³ | |
| MLP 1M RÂ² | â³ | |
| CNN 100k RÂ² | â³ | |
| CNN 1M RÂ² | â³ | |
| Best NN vs Oracle MoE | â³ | |

## 5.6 ä¸‹ä¸€æ­¥å·¥ä½œ

| æ–¹å‘ | å…·ä½“ä»»åŠ¡ | ä¼˜å…ˆçº§ | å¯¹åº” MVP |
|------|----------|--------|---------|
| å¤šå°ºåº¦ CNN | å¦‚æœ CNN 1M < 0.60 | ğŸŸ¡ P1 | MVP-CNN-2 |
| MoE-CNN | å¦‚æœ global CNN < 0.60 æ˜æ˜¾ | ğŸŸ¢ P2 | MVP-MoE-CNN-0 |

---

# 6. ğŸ“ é™„å½•

## 6.1 æ•°å€¼ç»“æœè¡¨

> â³ å¾…å®éªŒå®Œæˆåå¡«å†™

### ä¸»è¦ç»“æœ

| Model | Data Size | Test Size | RÂ² | MAE | RMSE | å¤‡æ³¨ |
|-------|-----------|-----------|-----|-----|------|------|
| Ridge | 1M | 1k | **0.4611** | 0.177 | 0.221 | ML baseline |
| LightGBM | 1M | 1k | **0.5749** | 0.154 | 0.196 | ML baseline |
| **Oracle MoE** | 1M | 1k | **0.6249** | 0.138 | 0.177 | ç»“æ„ä¸Šé™ (+0.16 vs Ridge) |
| MLP | 1M | 1k | â³ | | | |
| CNN | 1M | 1k | â³ | | | |
| Multi-scale CNN | 1M | 1k | â³ | | | |

### 100k â†’ 1M Scaling

| Model | RÂ²_100k | RÂ²_1M | Î”RÂ² | åˆ¤æ–­ |
|-------|---------|-------|-----|------|
| MLP | â³ | â³ | â³ | |
| CNN | â³ | â³ | â³ | |

---

## 6.2 å®éªŒæµç¨‹è®°å½•

### 6.2.1 ç¯å¢ƒä¸é…ç½®

| é¡¹ç›® | å€¼ |
|------|-----|
| **ä»“åº“** | `~/VIT` |
| **Config è·¯å¾„** | TODO |
| **è¾“å‡ºè·¯å¾„** | `lightning_logs/version_X` |
| **Python** | 3.10+ |
| **å…³é”®ä¾èµ–** | PyTorch 2.x, Lightning 2.x |

### 6.2.2 âœ… è¾“å…¥æ ¼å¼å·²ç¡®è®¤

> å‚è€ƒ: `exp_scaling_oracle_moe_noise1_20251223.md` + `/home/swei20/VIT/scripts/run_nn_baselines.py`

| ç¡®è®¤é¡¹ | å€¼ | æ¥æº |
|--------|-----|------|
| **æ³¢é•¿ç‚¹æ•°** | **4096** (MR arm) | Oracle MoE å®éªŒ |
| **è®­ç»ƒè¾“å…¥** | `flux` + on-the-fly noise | æ¯æ¬¡é‡‡æ ·é‡æ–°åŠ å™ª |
| **æµ‹è¯•è¾“å…¥** | `noisy/value` (é¢„ç”Ÿæˆ) | test_1k_0 å·²æœ‰ noisy |
| **æ•°æ®æ–‡ä»¶æ ¼å¼** | `.h5` (HDF5) | dataset.h5 |
| **1M æ•°æ®è·¯å¾„** | `/datascope/subaru/user/swei20/data/bosz50000/z0/mag205_225_lowT_1M/` | âœ… |
| **è®­ç»ƒ shards** | `train_200k_{0-4}/dataset.h5` (5 Ã— 200k = 1M) | âœ… |
| **æµ‹è¯•æ–‡ä»¶** | `test_1k_0/dataset.h5` | ä½¿ç”¨é¢„ç”Ÿæˆ noisy |
| **Dataset class** | `RegSpecDataset` â†’ `NNDataset` | âœ… å·²æœ‰ |

### 6.2.3 æ‰§è¡Œå‘½ä»¤

> å‚è€ƒ: `/home/swei20/VIT/scripts/run_nn_baselines.py`

```bash
cd ~/VIT

# ============================================================
# Step 0: Dry Run - æŸ¥çœ‹æ‰€æœ‰å°†è¿è¡Œçš„å®éªŒ
# ============================================================
python scripts/run_nn_baselines.py --dry-run -e Step1

# ============================================================
# Step 1: MLP lr/wd æœç´¢ (32k, noise=1.0)
# ä½¿ç”¨ Step1 å®éªŒç»„ï¼šå›ºå®šæ¶æ„ [256,64]ï¼Œæœç´¢ lr å’Œ weight_decay
# ============================================================
python scripts/run_nn_baselines.py -e Step1 --parallel --gpus 0,1,2,3

# ============================================================
# Step 2: MLP æ¶æ„æœç´¢ (ä½¿ç”¨ Step1 æœ€ä¼˜ lr/wd)
# æœç´¢ depth, width, activation, init
# ============================================================
python scripts/run_nn_baselines.py -e Step2 --parallel --gpus 0,1,2,3

# ============================================================
# Step 3: MLP Deep/Wide å®éªŒ (æ›´å¤§ç½‘ç»œ)
# ============================================================
python scripts/run_nn_baselines.py -e MLP_Deep --parallel --gpus 0,1,2,3
python scripts/run_nn_baselines.py -e MLP_Wide --parallel --gpus 0,1,2,3

# ============================================================
# Step 4: CNN å®éªŒ
# CNN_Stage1a: lr æœç´¢
# CNN_Stage1b: wd æœç´¢
# CNN_Stage2: æ¶æ„æœç´¢
# ============================================================
python scripts/run_nn_baselines.py -e CNN_Stage1a --parallel --gpus 0,1,2,3
python scripts/run_nn_baselines.py -e CNN_Stage1b --parallel --gpus 0,1,2,3
python scripts/run_nn_baselines.py -e CNN_Stage2 --parallel --gpus 0,1,2,3

# ============================================================
# 100k/1M è§„æ¨¡å®éªŒ (ä½¿ç”¨æœ€ä¼˜é…ç½®)
# éœ€è¦è®¾ç½® DATA_ROOT æŒ‡å‘ 100k/1M æ•°æ®
# ============================================================
DATA_ROOT=/path/to/100k/data python scripts/run_nn_baselines.py -e MLP_Big --parallel
```

### å…³é”®å‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--num-train` | 32000 | è®­ç»ƒæ ·æœ¬æ•° |
| `--batch-size` | 2048 | æ‰¹å¤§å°ï¼ˆé€‚é… V100ï¼‰ |
| `--epochs` | 100 | æœ€å¤§è®­ç»ƒè½®æ•° |
| `--patience` | 50 | Early stopping patience |
| `--parallel` | True | å¤š GPU å¹¶è¡Œ |
| `--gpus` | 0,1,2,3,4,5,6,7 | ä½¿ç”¨çš„ GPU |

### æ•°æ®è·¯å¾„

| è§„æ¨¡ | è·¯å¾„ |
|------|------|
| 32k | `/srv/local/tmp/swei20/data/bosz50000/z0/train_32k/` |
| **1M (æœ¬æ¬¡ä½¿ç”¨)** | `/datascope/subaru/user/swei20/data/bosz50000/z0/mag205_225_lowT_1M/` |
| è®­ç»ƒ shards | `train_200k_{0,1,2,3,4}/dataset.h5` (å…± 5 ä¸ª) |
| æµ‹è¯• | `test_1k_0/dataset.h5` (ä½¿ç”¨é¢„ç”Ÿæˆ noisy) |

```python
# Python æ•°æ®åŠ è½½ç¤ºä¾‹
DATA_ROOT = "/datascope/subaru/user/swei20/data/bosz50000/z0/mag205_225_lowT_1M"
TRAIN_SHARDS = [f"{DATA_ROOT}/train_200k_{i}/dataset.h5" for i in range(5)]
TEST_FILE = f"{DATA_ROOT}/test_1k_0/dataset.h5"
```

---

## 6.3 ç›¸å…³æ–‡ä»¶

| ç±»å‹ | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| Hub | `logg/scaling/scaling_hub_20251222.md` | å‡è®¾é‡‘å­—å¡” |
| Roadmap | `logg/scaling/scaling_roadmap_20251222.md` | MVP è®¾è®¡ |
| ML Baseline | `logg/scaling/exp/exp_scaling_ml_ceiling_20251222.md` | å‰ç½®å®éªŒ |
| æœ¬æŠ¥å‘Š | `logg/scaling/exp/exp_scaling_nn_baseline_framework_20251224.md` | å½“å‰æ–‡ä»¶ |
| å›¾è¡¨ | `logg/scaling/exp/img/` | å®éªŒå›¾è¡¨ |

---

## 6.4 å¿…é¡»è®°å½•çš„ 5 ä¸ªæ•°å­—

| # | æŒ‡æ ‡ | å€¼ | è¯´æ˜ |
|---|------|-----|------|
| 1 | **100k â†’ 1M çš„ Î”RÂ²** | â³ | æ¯ä¸ªæ¨¡å‹ä¸€ä¸ª |
| 2 | **plateau epoch** | â³ | è®­ç»ƒæ•ˆç‡ |
| 3 | **per-bin RÂ²** | â³ | ç‰¹åˆ«æ˜¯æœ€å·®çš„ bin |
| 4 | **whitening æ•æ„Ÿåº¦** | â³ | æœ‰æ—  whitening çš„å·®è· |
| 5 | **vs Oracle gap** | â³ | global CNN vs Oracle MoE |

---

## 6.5 æ¨èæ‰§è¡Œé¡ºåº

| é¡ºåº | MVP | ç›®çš„ | æ—¶é—´é¢„ä¼° |
|------|-----|------|---------|
| 1 | MVP-NN-0 | æ¡†æ¶æ­å»º | åŠå¤© |
| 2 | MVP-MLP-1 @100k + @1M | å¿«é€Ÿæ­¢æŸ/ç¡®è®¤"MLP ä¸åƒæ•°æ®" | 1å¤© |
| 3 | MVP-CNN-1 @100k | ç¡®è®¤å½’çº³åç½®å¯¹ä¸å¯¹ | åŠå¤© |
| 4 | MVP-CNN-1 @1M | çœ‹"å¤§åŠ›å‡ºå¥‡è¿¹"æ˜¯å¦æˆç«‹ | 1å¤© |
| 5 | MVP-CNN-2 | å¤šå°ºåº¦ CNNï¼ˆå¦‚éœ€ï¼‰ | 1å¤© |
| 6 | MVP-MoE-CNN-0 | ä»…å½“ global CNN < 0.60 | è§†æƒ…å†µ |

---

> **æ¨¡æ¿è¯´æ˜**ï¼š
> - æœ¬æ–‡æ¡£ä¸º NN baseline å®éªŒæ¡†æ¶ï¼ŒÂ§1-2 å·²å¡«å†™å®Œæ•´
> - Â§3-6 å¾…å®éªŒå®Œæˆåå¡«å†™
> - è¯·åœ¨å¼€å§‹å®éªŒå‰ç¡®è®¤ Â§6.2.2 ä¸­çš„è¾“å…¥æ ¼å¼é—®é¢˜


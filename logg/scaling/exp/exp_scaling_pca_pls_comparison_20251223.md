# Experiment Report: PCA vs PLS Dimensionality Reduction

**Experiment ID:** `SCALING-20251223-pca-pls-01`  
**Date:** 2025-12-23  
**Author:** Viska Wei  
**MVP:** 1.7  
**Status:** âœ… Completed

---

## âš¡ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆ

**ä¸€å¥è¯æ€»ç»“:** Full Ridge (æ— é™ç»´) è¡¨ç°æœ€å¥½ (RÂ²=0.5077)ï¼›PLS åœ¨åŒç­‰ç»´åº¦ä¸‹å§‹ç»ˆä¼˜äº PCAï¼›Whitening ç­–ç•¥å®Œå…¨å¤±æ•ˆã€‚

| Key Finding | Value |
|-------------|-------|
| Best Method | Full Ridge (Î±=1e5) |
| Best RÂ² | 0.5077 |
| PLS vs PCA | PLS wins 4/4 at all K |
| Whitening | âŒ Failed (RÂ²=0.0335) |

---

## ğŸ“‹ Summary

| Metric | Value |
|--------|-------|
| Train Size | 1,000,000 |
| Test Size | 500 |
| Feature Dim | 4096 |
| Noise Level | Ïƒ = 1.0 |
| Ridge Î± | 1e5 |
| Total Time | ~10.5 hours |

---

## ğŸ¯ Hypotheses Verification

| Hypothesis | Expected | Actual | Result |
|------------|----------|--------|--------|
| **H1.7.2**: PLS > PCA at same K | PLS wins all K | 4/4 wins | âœ… **Verified** |
| **H1.7.3**: PCA hurts features | PCA+Ridge < Full Ridge | 0.4985 < 0.5077 | âœ… **Verified** |
| **H1.7.4**: Whitened more robust | RÂ²(whitened) > RÂ²(noisy) | 0.0335 < 0.4962 | âŒ **Rejected** |

---

## ğŸ”¬ å®éªŒè®¾è®¡è¯¦è§£

### 2.1 æ•°æ®é…ç½®

**æ•°æ®æ¥æº:** BOSZ æ’æ˜Ÿå…‰è°±æ¨¡æ‹Ÿæ•°æ®

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| æ•°æ®é›†è·¯å¾„ | `/datascope/subaru/user/swei20/data/bosz50000/z0/mag205_225_lowT_1M` |
| è®­ç»ƒæ•°æ® | 5 ä¸ª shards Ã— 200k = 1M æ ·æœ¬ |
| æµ‹è¯•æ•°æ® | 500 æ ·æœ¬ï¼ˆé¢„åŠ å™ªï¼‰ |
| ç‰¹å¾ç»´åº¦ | 4096 (å…‰è°±æ³¢æ®µ) |
| ç›®æ ‡å˜é‡ | `log_g` (è¡¨é¢é‡åŠ›) |

**è®­ç»ƒæ•°æ® Shards:**
```
train_200k_0/dataset.h5
train_200k_1/dataset.h5
train_200k_2/dataset.h5
train_200k_3/dataset.h5
train_200k_4/dataset.h5
```

**æµ‹è¯•æ•°æ®:**
```
test_1k_0/dataset.h5 (å–å‰ 500 æ ·æœ¬)
```

### 2.2 æ•°æ®åŠ è½½ä¸é¢„å¤„ç†

#### 2.2.1 HDF5 æ•°æ®ç»“æ„

æ¯ä¸ª shard åŒ…å«ä»¥ä¸‹æ•°ç»„ï¼š
- `dataset/arrays/flux/value`: åŸå§‹å…‰è°±é€šé‡ (N Ã— 4096)
- `dataset/arrays/error/value`: æ¯ä¸ªæ³¢æ®µçš„è¯¯å·®ä¼°è®¡ (N Ã— 4096)
- `dataset/arrays/noisy/value`: é¢„åŠ å™ªå…‰è°±ï¼ˆä»…æµ‹è¯•é›†ï¼‰

å‚æ•°é€šè¿‡ `pd.read_hdf()` è¯»å–ï¼ŒåŒ…å« `log_g`, `Teff` ç­‰æ’æ˜Ÿå‚æ•°ã€‚

#### 2.2.2 æ•°æ®åŠ è½½æµç¨‹

```python
def load_shards(shard_paths, max_samples=None):
    """Load multiple HDF5 shards and concatenate."""
    flux_list, error_list, logg_list = [], [], []
    
    for path in shard_paths:
        with h5py.File(path, 'r') as f:
            flux = f['dataset/arrays/flux/value'][:].astype(np.float32)
            error = f['dataset/arrays/error/value'][:].astype(np.float32)
        
        df = pd.read_hdf(path)
        logg = df['log_g'].values.astype(np.float32)
        
        flux_list.append(flux)
        error_list.append(error)
        logg_list.append(logg)
    
    X = np.vstack(flux_list)
    X = np.clip(X, 0, None)  # Clip negative flux
    
    return X, error, y
```

**å…³é”®å¤„ç†:**
1. æ‰€æœ‰æ•°æ®è½¬ä¸º `float32` èŠ‚çœå†…å­˜
2. è´Ÿé€šé‡è¢« clip åˆ° 0ï¼ˆç‰©ç†çº¦æŸï¼‰

#### 2.2.3 å™ªå£°æ³¨å…¥

è®­ç»ƒæ•°æ®ä½¿ç”¨ **å¼‚æ–¹å·®é«˜æ–¯å™ªå£°**ï¼ˆheteroscedastic Gaussian noiseï¼‰ï¼š

$$X_{\text{noisy}} = X_{\text{clean}} + \mathcal{N}(0, \sigma \cdot \text{error})$$

```python
def add_noise(X, error, noise_level=1.0, seed=42):
    """Add heteroscedastic Gaussian noise."""
    np.random.seed(seed)
    noise = np.random.randn(*X.shape) * error * noise_level
    return (X + noise).astype(np.float32)
```

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `noise_level` | 1.0 | å™ªå£°ç¼©æ”¾å› å­ Ïƒ |
| `seed` | 42 | éšæœºç§å­ï¼ˆå¯å¤ç°ï¼‰ |
| å™ªå£°ç±»å‹ | æŒ‰ error ç¼©æ”¾ | æ¯ä¸ªæ³¢æ®µç‹¬ç«‹å™ªå£° |

---

### 2.3 PCA æ–¹æ³•è¯¦è§£

#### 2.3.1 PCA åŸç†

PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰é€šè¿‡æ­£äº¤å˜æ¢å°†é«˜ç»´ç‰¹å¾æŠ•å½±åˆ°ä½ç»´ç©ºé—´ï¼Œä¿ç•™æœ€å¤§æ–¹å·®æ–¹å‘ï¼š

$$X_{\text{PCA}} = (X - \mu) V_K^T$$

å…¶ä¸­ $V_K$ æ˜¯å‰ K ä¸ªä¸»æˆåˆ†æ–¹å‘ã€‚

#### 2.3.2 PCA + Ridge å®ç°

```python
def train_pca_ridge(X_train, y_train, X_test, y_test, n_components, alpha=1e5):
    """Train PCA + Ridge regression."""
    
    # Step 1: æ ‡å‡†åŒ–ï¼ˆé›¶å‡å€¼ï¼Œå•ä½æ–¹å·®ï¼‰
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Step 2: PCA é™ç»´
    pca = PCA(
        n_components=n_components,
        svd_solver='randomized',  # éšæœºSVDåŠ é€Ÿå¤§æ•°æ®
        random_state=42
    )
    X_train_pca = pca.fit_transform(X_train_scaled)
    X_test_pca = pca.transform(X_test_scaled)
    
    # Step 3: Ridge å›å½’
    model = Ridge(alpha=alpha, solver='auto', random_state=42)
    model.fit(X_train_pca, y_train)
    
    y_pred = model.predict(X_test_pca)
    
    return {
        'test_r2': r2_score(y_test, y_pred),
        'explained_variance_ratio': pca.explained_variance_ratio_.sum(),
        ...
    }
```

#### 2.3.3 PCA å…³é”®é…ç½®

| é…ç½®é¡¹ | å€¼ | è¯´æ˜ |
|--------|-----|------|
| `svd_solver` | `'randomized'` | ä½¿ç”¨éšæœº SVD åŠ é€Ÿï¼ˆ1M æ ·æœ¬ï¼‰ |
| StandardScaler | å…ˆæ ‡å‡†åŒ–å† PCA | ç¡®ä¿å„ç‰¹å¾æƒé‡å‡ç­‰ |
| K å€¼ | [100, 200, 500, 1000] | ä¿ç•™çš„ä¸»æˆåˆ†æ•°é‡ |
| Ridge Î± | 1e5 | å›ºå®šæ­£åˆ™åŒ–å¼ºåº¦ |

#### 2.3.4 PCA Explained Variance

PCA åœ¨ K=1000 æ—¶ä»…è§£é‡Š **31.3%** æ–¹å·®ï¼Œè¯´æ˜å…‰è°±ä¿¡æ¯é«˜åº¦åˆ†å¸ƒå¼ï¼Œå‰ 1000 ä¸ªä¸»æˆåˆ†æ— æ³•æ•è·å¤§éƒ¨åˆ†ä¿¡æ¯ã€‚

---

### 2.4 PLS æ–¹æ³•è¯¦è§£

#### 2.4.1 PLS åŸç†

PLSï¼ˆåæœ€å°äºŒä¹˜å›å½’ï¼‰æ˜¯ä¸€ç§**ç›‘ç£é™ç»´**æ–¹æ³•ï¼ŒåŒæ—¶è€ƒè™‘ X å’Œ y çš„åæ–¹å·®ï¼š

$$\max_{w} \text{Cov}(Xw, y)^2$$

ä¸ PCA çš„æ— ç›‘ç£é™ç»´ä¸åŒï¼ŒPLS ä¿ç•™çš„æ˜¯ä¸ç›®æ ‡å˜é‡æœ€ç›¸å…³çš„æ–¹å‘ã€‚

#### 2.4.2 PLS å®ç°

```python
def train_pls(X_train, y_train, X_test, y_test, n_components):
    """Train PLS Regression."""
    
    # Step 1: æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Step 2: PLS å›å½’ï¼ˆé™ç»´ + å›å½’ä¸€ä½“åŒ–ï¼‰
    model = PLSRegression(
        n_components=n_components,
        scale=False  # å·²ç»æ‰‹åŠ¨æ ‡å‡†åŒ–
    )
    model.fit(X_train_scaled, y_train)
    
    y_pred = model.predict(X_test_scaled).ravel()
    
    return {
        'test_r2': r2_score(y_test, y_pred),
        ...
    }
```

#### 2.4.3 PLS vs PCA æ ¸å¿ƒåŒºåˆ«

| ç‰¹æ€§ | PCA | PLS |
|------|-----|-----|
| **ç›®æ ‡å‡½æ•°** | æœ€å¤§åŒ– X æ–¹å·® | æœ€å¤§åŒ– X-y åæ–¹å·® |
| **æ˜¯å¦ç›‘ç£** | âŒ æ— ç›‘ç£ | âœ… ç›‘ç£ |
| **ä¿¡æ¯ä¿ç•™** | ä¿ç•™æ€»æ–¹å·® | ä¿ç•™ç›®æ ‡ç›¸å…³æ–¹å·® |
| **é€‚ç”¨åœºæ™¯** | ç‰¹å¾å‹ç¼© | é¢„æµ‹ä»»åŠ¡ |

---

### 2.5 Full Ridge Baseline

ä½œä¸ºå¯¹ç…§ç»„ï¼Œç›´æ¥åœ¨åŸå§‹ 4096 ç»´ç‰¹å¾ä¸Šè®­ç»ƒ Ridge å›å½’ï¼ˆæ— é™ç»´ï¼‰ï¼š

```python
def train_full_ridge(X_train, y_train, X_test, y_test, alpha=1e5):
    """Train Full Ridge (no dimensionality reduction) as baseline."""
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    model = Ridge(alpha=alpha, solver='auto', random_state=42)
    model.fit(X_train_scaled, y_train)
    
    y_pred = model.predict(X_test_scaled)
    return {'test_r2': r2_score(y_test, y_pred), ...}
```

---

### 2.6 PCA Space Selection å®éªŒ

æ¯”è¾ƒåœ¨ä¸åŒè¾“å…¥ç©ºé—´åš PCA çš„æ•ˆæœï¼ˆK=200ï¼‰ï¼š

#### 2.6.1 ä¸‰ç§è¾“å…¥ç©ºé—´

| Space | å®šä¹‰ | å‡è®¾ |
|-------|------|------|
| **noisy** | åŸå§‹åŠ å™ªå…‰è°± | æ ‡å‡†æ–¹æ³• |
| **whitened** | $X_{\text{whitened}} = X / \text{error}$ | å¹³è¡¡å„æ³¢æ®µå™ªå£° |
| **denoised** | ä½¿ç”¨ clean flux è®­ç»ƒ | å‡è®¾æœ‰å®Œç¾å»å™ª |

#### 2.6.2 Whitening å®ç°

```python
def run_pca_space_comparison(...):
    # Whitening: X_whitened = X / error
    with np.errstate(divide='ignore', invalid='ignore'):
        X_train_whitened = np.where(
            error_train > 1e-10,
            X_train_noisy / error_train,
            X_train_noisy
        )
```

**æ³¨æ„:** å½“ error â‰¤ 1e-10 æ—¶ä¿æŒåŸå€¼ï¼Œé¿å…é™¤é›¶ã€‚

---

## ğŸ“Š Results

### Sub-design 1: PCA K Sweep

![PCA K Sweep](../img/scaling_pca_k_sweep.png)

| Method | K | Test RÂ² | Explained Var | Time (s) |
|--------|---|---------|---------------|----------|
| **Full Ridge (baseline)** | 4096 | **0.5077** | 100% | 68.5 |
| PCA + Ridge | 100 | 0.4893 | ~6% | 118.8 |
| PCA + Ridge | 200 | 0.4962 | ~12% | 172.0 |
| PCA + Ridge | 500 | 0.4985 | ~21% | 237.5 |
| PCA + Ridge | 1000 | 0.4948 | ~31.3% | 499.9 |

**Key Finding:** 
- Full Ridge (æ— é™ç»´) è¡¨ç°æœ€å¥½ï¼
- PCA åœ¨æ‰€æœ‰ K å€¼ä¸‹éƒ½åŠ£äº baseline
- K=1000 æ—¶æ€§èƒ½åè€Œä¸‹é™ï¼ˆå¯èƒ½å› ä¸º PCA+Ridge çš„ Î± æœªé‡æ–°è°ƒä¼˜ï¼‰
- PCA explained variance åœ¨ K=1000 æ—¶ä»… 31.3%ï¼Œè¯´æ˜å…‰è°±ä¿¡æ¯é«˜åº¦åˆ†å¸ƒå¼

---

### Sub-design 2: PLS vs PCA Comparison

![PLS vs PCA](../img/scaling_pls_vs_pca.png)

| K | PCA + Ridge RÂ² | PLS RÂ² | Î”(PLS - PCA) | Winner |
|---|----------------|--------|--------------|--------|
| 100 | 0.4893 | **0.5059** | +0.0165 | ğŸ† PLS |
| 200 | 0.4962 | **0.5059** | +0.0096 | ğŸ† PLS |
| 500 | 0.4985 | **0.5059** | +0.0074 | ğŸ† PLS |
| 1000 | 0.4948 | **0.5056** | +0.0108 | ğŸ† PLS |

**Key Finding:** 
- PLS åœ¨**æ‰€æœ‰ K å€¼**ä¸‹éƒ½èƒœè¿‡ PCAï¼
- PLS åˆ©ç”¨ target ä¿¡æ¯ä¿ç•™å…³é”®ç‰¹å¾
- åœ¨ K=100 æ—¶ä¼˜åŠ¿æœ€å¤§ (Î” = +0.0165)
- PLS æ”¶æ•›äº RÂ² â‰ˆ 0.506ï¼Œæ¥è¿‘ Full Ridge çš„ 0.508

---

### Sub-design 3: PCA Space Selection (K=200)

![PCA Space Comparison](../img/scaling_pca_space_comparison.png)

| Space | Test RÂ² | è¯´æ˜ |
|-------|---------|------|
| **noisy** | **0.4962** | âœ… æ ‡å‡†æ–¹æ³•æœ€ä¼˜ |
| whitened | 0.0335 | âŒ å‡ ä¹å®Œå…¨å¤±æ•ˆ |
| denoised | -22.88 | âŒ ç¾éš¾æ€§å¤±è´¥ |

**Key Finding:** 
- Whitening ($X/\text{error}$) ç­–ç•¥**å®Œå…¨å¤±è´¥**
- Denoised (clean flux è®­ç»ƒ + noisy æµ‹è¯•) å‡ºç°ä¸¥é‡ domain shift
- ç»“è®ºï¼š**ä¿æŒåŸå§‹å™ªå£°ç»“æ„æ˜¯æœ€ä¼˜é€‰æ‹©**

---

### Best Method Prediction

![Pred vs True](../img/scaling_pca_pls_pred_vs_true.png)

æœ€ä½³æ–¹æ³•ï¼ˆFull Ridgeï¼‰çš„é¢„æµ‹ vs çœŸå€¼æ•£ç‚¹å›¾ï¼ŒRÂ²=0.5077ã€‚

---

## ğŸ“ˆ Key Insights

### 1. PCA é™ç»´æŸå¤±ä¿¡æ¯ âŒ

```
Full Ridge RÂ²    = 0.5077
Best PCA+Ridge RÂ² = 0.4985 (K=500)
Î” = -0.0092 (æŸå¤± 1.8%)
```

- PCA ä¸¢å¤±äº†å¯¹ log_g é¢„æµ‹é‡è¦çš„é«˜é¢‘ç‰¹å¾
- å³ä½¿ä¿ç•™ 1000 ä¸ªä¸»æˆåˆ†ï¼ˆè§£é‡Š 31.3% æ–¹å·®ï¼‰ï¼Œä»ä¸å¦‚åŸå§‹ 4096 ç»´
- **ç»“è®º:** å¯¹äºè¿™ä¸ªä»»åŠ¡ï¼Œé™ç»´ä¸æ˜¯å¥½ç­–ç•¥

### 2. PLS ä¼˜äº PCA âœ…

```
At K=100: PLS RÂ² = 0.5059, PCA RÂ² = 0.4893
Î” = +0.0165 (PLS ä¼˜åŠ¿ 3.4%)
```

- PLS é€šè¿‡ç›‘ç£å­¦ä¹ ä¿ç•™ target-correlated æ–¹å‘
- åœ¨ K=100 æ—¶ä¼˜åŠ¿æœ€å¤§ï¼ˆç‰¹å¾å‹ç¼©æ¯” 40:1ï¼‰
- **ç»“è®º:** å¦‚æœå¿…é¡»é™ç»´ï¼Œä¼˜å…ˆç”¨ PLS

### 3. Whitening ç­–ç•¥å¤±è´¥ âŒ

```
Noisy space RÂ²     = 0.4962
Whitened space RÂ² = 0.0335
```

- åŸå§‹å‡è®¾ï¼šwhitening ($X/\text{error}$) å¯ä»¥å¹³è¡¡å„æ³¢æ®µå™ªå£°
- å®é™…ç»“æœï¼šwhitening ç ´åäº†ä¿¡å·ç»“æ„
- **åŸå› åˆ†æ:** 
  1. error array å¯èƒ½ä¸å®é™…å™ªå£°ä¸åŒ¹é…
  2. ä½ error æ³¢æ®µè¢«è¿‡åº¦æ”¾å¤§
  3. ä¿¡å·å’Œå™ªå£°çš„ç»“æ„å…³ç³»è¢«ç ´å

### 4. Domain Shift é—®é¢˜ âŒ

```
Denoised training + Noisy test RÂ² = -22.88
```

- Clean è®­ç»ƒ + Noisy æµ‹è¯• = ç¾éš¾æ€§ç»“æœ
- è´Ÿ RÂ² è¯´æ˜æ¨¡å‹é¢„æµ‹æ¯”å‡å€¼è¿˜å·®
- **ç»“è®º:** å¿…é¡»ä¿æŒ train/test å™ªå£°åˆ†å¸ƒä¸€è‡´

---

## ğŸ”§ å®éªŒæµç¨‹è®°å½•

### æ‰§è¡Œå‘½ä»¤

```bash
cd ~/VIT
python scripts/scaling_pca_pls_experiment.py \
    --output ./results/scaling_pca_pls \
    --img-dir /home/swei20/Physics_Informed_AI/logg/scaling/img \
    --max-train 1000000
```

### æ‰§è¡Œæ­¥éª¤

1. **[1/7] åŠ è½½è®­ç»ƒæ•°æ®** (~5-10 min)
   - ä» 5 ä¸ª shards åŠ è½½ 1M æ ·æœ¬
   - è½¬æ¢ä¸º float32ï¼Œclip è´Ÿå€¼

2. **[2/7] åŠ è½½æµ‹è¯•æ•°æ®** (<1 min)
   - åŠ è½½ 500 ä¸ªé¢„åŠ å™ªæ ·æœ¬

3. **[3/7] æ³¨å…¥å™ªå£°** (<1 min)
   - å¯¹è®­ç»ƒæ•°æ®æ·»åŠ  Ïƒ=1.0 çš„å¼‚æ–¹å·®å™ªå£°

4. **[4/7] PCA K Sweep** (~1-2 hours)
   - Full Ridge baseline
   - K = 100, 200, 500, 1000 çš„ PCA + Ridge

5. **[5/7] PLS vs PCA** (~6-8 hours)
   - å¯¹æ¯ä¸ª K å€¼è®­ç»ƒ PLSï¼ˆä¸»è¦è€—æ—¶ï¼‰

6. **[6/7] PCA Space Comparison** (~30 min)
   - noisy, whitened, denoised ä¸‰ç§ç©ºé—´

7. **[7/7] ç”Ÿæˆå›¾è¡¨** (<1 min)

### è¿è¡Œæ—¥å¿—ç¤ºä¾‹

```
================================================================================
PCA vs PLS Dimensionality Reduction Experiment
Experiment ID: SCALING-20251223-pca-pls-01
================================================================================
K values: [100, 200, 500, 1000]
Ridge Î±: 100000.0
Noise level: 1.0
================================================================================

[1/7] Loading training data from shards...
  Loading /datascope/subaru/.../train_200k_0/dataset.h5...
    Loaded 200000 samples (total: 200000)
  ...
  Total training samples: 1,000,000
  Feature dimension: 4096

[4/7] Sub-design 1: PCA K Sweep
  [Full Ridge] Training baseline (no dimensionality reduction)...
    RÂ²=0.5077, Time=68.5s
  [PCA K=100] Training...
    RÂ²=0.4893, Var explained=0.060, Time=118.8s
  ...
```

---

## ğŸ”— Artifacts

| Type | Path |
|------|------|
| Script | `~/VIT/scripts/scaling_pca_pls_experiment.py` |
| Results CSV | `~/VIT/results/scaling_pca_pls/*.csv` |
| Metadata | `~/VIT/results/scaling_pca_pls/metadata.json` |

### Result Files

| File | Description |
|------|-------------|
| `pca_k_sweep.csv` | PCA K æ‰«æç»“æœ |
| `pls_vs_pca.csv` | PLS vs PCA å¯¹æ¯”ç»“æœ |
| `pca_space_comparison.csv` | è¾“å…¥ç©ºé—´å¯¹æ¯”ç»“æœ |
| `metadata.json` | å®éªŒå…ƒæ•°æ®å’Œæ±‡æ€» |

### Figures

| Fig | Description | Path |
|-----|-------------|------|
| 1 | PCA K vs RÂ² | `logg/scaling/img/scaling_pca_k_sweep.png` |
| 2 | PLS vs PCA grouped bar | `logg/scaling/img/scaling_pls_vs_pca.png` |
| 3 | PCA space comparison | `logg/scaling/img/scaling_pca_space_comparison.png` |
| 4 | Best method pred vs true | `logg/scaling/img/scaling_pca_pls_pred_vs_true.png` |

---

## ğŸ’¡ Implications for Roadmap

1. **é™ç»´ç­–ç•¥ä¸æ¨è** - Full Ridge å·²ç»æ˜¯æœ€ä¼˜
2. **å¦‚éœ€å‹ç¼©ç‰¹å¾** - ç”¨ PLS è€Œé PCA
3. **å™ªå£°å¤„ç†** - ä¸è¦ whiteningï¼Œä¿æŒåŸå§‹å™ªå£°ç»“æ„
4. **Domain Shift** - Train/Test å¿…é¡»åŒåˆ†å¸ƒ
5. **ä¸‹ä¸€æ­¥** - æ¢ç´¢ denoising autoencoder æˆ– noise-aware models

---

## ğŸ“ Appendix

### A.1 å®Œæ•´æ•°å€¼ç»“æœ

#### PCA K Sweep Results

| Method | K | Train RÂ² | Test RÂ² | Test MAE | Test RMSE | Explained Var | Time (s) |
|--------|---|----------|---------|----------|-----------|---------------|----------|
| Full Ridge | 4096 | - | 0.5077 | - | - | 1.00 | 68.5 |
| PCA+Ridge | 100 | - | 0.4893 | - | - | ~0.06 | 118.8 |
| PCA+Ridge | 200 | - | 0.4962 | - | - | ~0.12 | 172.0 |
| PCA+Ridge | 500 | - | 0.4985 | - | - | ~0.21 | 237.5 |
| PCA+Ridge | 1000 | - | 0.4948 | - | - | ~0.313 | 499.9 |

#### PLS Results

| K | PLS RÂ² | PLS Time (s) |
|---|--------|--------------|
| 100 | 0.5059 | ~5000 |
| 200 | 0.5059 | ~6000 |
| 500 | 0.5059 | ~8000 |
| 1000 | 0.5056 | ~12000 |

### A.2 å…³é”®æ•°å­—é€ŸæŸ¥

| Item | Value |
|------|-------|
| Best overall RÂ² | 0.5077 (Full Ridge) |
| Best PCA+Ridge RÂ² | 0.4985 (K=500) |
| Best PLS RÂ² | 0.5059 (K=100) |
| Explained variance @ K=1000 | 31.3% |
| Whitened space RÂ² | 0.0335 |
| Ridge Î± | 1e5 |
| Train samples | 1,000,000 |
| Test samples | 500 |
| Feature dim | 4096 |
| Noise Ïƒ | 1.0 |

### A.3 ç®—æ³•ä¼ªä»£ç 

```
Algorithm: PCA + Ridge
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input: X_train (NÃ—4096), y_train (N,), X_test (MÃ—4096), K, Î±
Output: y_pred (M,)

1. scaler â† StandardScaler()
2. X_train_std â† scaler.fit_transform(X_train)
3. X_test_std â† scaler.transform(X_test)
4. pca â† PCA(n_components=K, svd_solver='randomized')
5. X_train_pca â† pca.fit_transform(X_train_std)  # NÃ—K
6. X_test_pca â† pca.transform(X_test_std)        # MÃ—K
7. ridge â† Ridge(alpha=Î±)
8. ridge.fit(X_train_pca, y_train)
9. y_pred â† ridge.predict(X_test_pca)
10. return y_pred
```

```
Algorithm: PLS Regression
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Input: X_train (NÃ—4096), y_train (N,), X_test (MÃ—4096), K
Output: y_pred (M,)

1. scaler â† StandardScaler()
2. X_train_std â† scaler.fit_transform(X_train)
3. X_test_std â† scaler.transform(X_test)
4. pls â† PLSRegression(n_components=K, scale=False)
5. pls.fit(X_train_std, y_train)  # åŒæ—¶å­¦ä¹ é™ç»´+å›å½’
6. y_pred â† pls.predict(X_test_std).ravel()
7. return y_pred
```

### A.4 ä¾èµ–åº“ç‰ˆæœ¬

```python
numpy>=1.21
pandas>=1.3
scikit-learn>=1.0
h5py>=3.0
matplotlib>=3.5
seaborn>=0.11
tqdm>=4.62
```

---

## ğŸ“Š Appendix: Whitened Ridge Experiment

**Added:** 2025-12-23 (è¿½åŠ å®éªŒ)

### å®éªŒè®¾è®¡
- **Whitened ç‰¹å¾:** `X_whitened = noisy_flux / error`
- **æ•°æ®é‡:** 1M train, 500 test
- **Î± sweep:** [1e2, 1e3, 1e4, 1e5, 1e6]

### ç»“æœ

| Î± | Regular RÂ² | Whitened RÂ² | Î” |
|---|------------|-------------|---|
| 1e+02 | 0.5059 | 0.5074 | +0.0016 |
| 1e+03 | 0.5059 | 0.5075 | +0.0017 |
| **1e+04** | 0.5062 | **0.5079** | **+0.0018** |
| **1e+05** | **0.5077** | 0.4803 | -0.0273 |
| 1e+06 | 0.4736 | 0.2647 | -0.2089 |

### ç»“è®º

| Metric | Regular Ridge | Whitened Ridge |
|--------|---------------|----------------|
| Best RÂ² | 0.5077 | 0.5079 |
| Best Î± | 1e5 | 1e4 |

**Key Insights:**
1. **Whitened Ridge ç•¥ä¼˜** (+0.0002)ï¼Œä½†å·®å¼‚æå° (~0.04%)
2. **Whitening éœ€è¦æ›´å°çš„ Î±** - å› ä¸º whitening è®©ç‰¹å¾å°ºåº¦æ›´å‡åŒ€
3. **é«˜ Î± æ—¶ Whitening å´©æºƒ** - Î±=1e5 æ—¶ Whitened å¤§å¹…è½å (-0.027)
4. **å®é™…æ„ä¹‰æœ‰é™** - æå‡å¤ªå°ï¼Œä¸å€¼å¾—å¢åŠ å¤æ‚æ€§

### ä¿®æ­£ H1.7.4

åŸå‡è®¾ H1.7.4 è¯´ "Whitened > Noisy"ï¼Œåœ¨ PCA å®éªŒä¸­è¢« âŒ æ‹’ç»ã€‚

ä½†åœ¨ **Full Ridge (æ— é™ç»´)** ä¸­ï¼š
- å¦‚æœç”¨æ­£ç¡®çš„ Î± (1e4 for whitened, 1e5 for regular)
- Whitened ç¡®å®ç•¥å¥½ (+0.0002)

**ç»“è®º:** Whitening å¯¹ Ridge æœ‰æ•ˆï¼Œä½†å¯¹ PCA æ— æ•ˆï¼ˆPCA å‡è®¾å„ç»´åº¦åŒæ–¹å·®ï¼‰

# ğŸ“˜ Experiment Report: LightGBM Parameter Extended Sweep
> **Name:** TODO | **ID:** `SCALING-20251222-lgbm-param-01`  
> **Topic:** `scaling` | **MVP:** MVP-1.5 | **Project:** `VIT`  
> **Author:** Viska Wei | **Date:** 2025-12-22 | **Status:** â³ Planned
```
ğŸ’¡ å®éªŒç›®çš„  
å†³å®šï¼šå½±å“çš„å†³ç­–
```

---

---

## ğŸ”— Upstream Links

| Type | Link | Description |
|------|------|-------------|
| ğŸ§  Hub | [`scaling_hub_20251222.md`](../scaling_hub_20251222.md) | Hypothesis pyramid |
| ğŸ—ºï¸ Roadmap | [`scaling_roadmap_20251222.md`](../scaling_roadmap_20251222.md) | MVP design |
| ğŸ“‹ Kanban | [`kanban.md`](../../../status/kanban.md) | Experiment queue |
| ğŸ“— Previous | [`exp_scaling_ml_ceiling_20251222.md`](./exp_scaling_ml_ceiling_20251222.md) | Baseline results |

---

# ğŸ“‘ Table of Contents

- [âš¡ Key Findings](#-key-findings-for-hub-extraction)
- [1. ğŸ¯ Objective](#1--objective)
- [2. ğŸ§ª Experiment Design](#2--experiment-design)
- [3. ğŸ“Š Figures & Results](#3--figures--results)
- [4. ğŸ’¡ Insights](#4--insights)
- [5. ğŸ“ Conclusions](#5--conclusions)
- [6. ğŸ“ Appendix](#6--appendix)

---

## âš¡ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆï¼ˆä¾› hub æå–ï¼‰

### ä¸€å¥è¯æ€»ç»“

> **TODOï¼šå®éªŒå®Œæˆåå¡«å†™**

### å¯¹å‡è®¾çš„éªŒè¯

| éªŒè¯é—®é¢˜ | ç»“æœ | ç»“è®º |
|---------|------|------|
| H1.6.1: num_leaves=127/255 èƒ½æå‡ RÂ² > 0.01ï¼Ÿ | TODO | TODO |
| H1.6.2: lr=0.01/0.02 èƒ½æå‡ RÂ² > 0.01ï¼Ÿ | TODO | TODO |

### è®¾è®¡å¯ç¤º

| å¯ç¤º | å…·ä½“å»ºè®® |
|------|---------|
| TODO | TODO |

### å…³é”®æ•°å­—

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| æœ€ä¼˜ num_leaves | TODO |
| æœ€ä¼˜ learning_rate | TODO |
| æœ€ä¼˜ min_data_in_leaf | TODO |
| æœ€ä¼˜ RÂ² @ 1M | TODO |
| vs åŸé…ç½®çš„æå‡ | TODO |

---

# 1. ğŸ¯ ç›®æ ‡

## 1.1 å®éªŒç›®çš„

> **éªŒè¯ LightGBM å‚æ•°ç©ºé—´æ˜¯å¦æ¢ç´¢å®Œå…¨ï¼Œæ˜¯å¦è¿˜èƒ½æŠ¬é«˜ RÂ² ä¸Šé™**

**èƒŒæ™¯è§‚å¯Ÿ**ï¼š
- åŸé…ç½®ï¼šlr=0.05, num_leaves=63, early stopping @ 50 rounds
- 1M æ—¶å®é™…åªç”¨äº† ~1293 æ£µæ ‘ï¼ˆvs max 5000ï¼‰
- è¿™è¯´æ˜"ä¸æ˜¯æ ‘ä¸å¤Ÿ"ï¼Œè€Œæ˜¯"ç»§ç»­åŠ æ ‘åœ¨éªŒè¯é›†ä¸Šä¸å†å¸¦æ¥æ³›åŒ–å¢ç›Š"
- ä½†è¿™å¯èƒ½æ˜¯å‚æ•°é…ç½®é—®é¢˜ï¼Œè€Œéæ¨¡å‹æé™

**æ ¸å¿ƒé—®é¢˜**ï¼š
1. æ›´å¤§çš„æ ‘å¤æ‚åº¦ (num_leavesâ†‘) èƒ½å¦æå‡ï¼Ÿ
2. æ›´å°çš„å­¦ä¹ ç‡ (lrâ†“) + æ›´å¤šæ ‘èƒ½å¦æ›´ç²¾ç»†æ‹Ÿåˆï¼Ÿ
3. early stopping æ˜¯å¦"è¿‡æ—©åœ"äº†ï¼Ÿ

## 1.2 é¢„æœŸ vs å®é™…ç»“æœ

| åœºæ™¯ | é¢„æœŸç»“æœ | å®é™…ç»“æœ | åˆ¤æ–­ |
|------|---------|---------|------|
| num_leaves=127/255 | RÂ² è½»å¾®æå‡ 0-2% | TODO | TODO |
| lr=0.02/0.01 | RÂ² è½»å¾®æå‡ 0-2% | TODO | TODO |
| å›ºå®šè½®æ•° vs early stopping | å·®å¼‚ < 0.01 | TODO | TODO |

---

# 2. ğŸ§ª å®éªŒè®¾è®¡

## 2.1 æ•°æ®

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| **æ•°æ®æ¥æº** | BOSZ æ¨¡æ‹Ÿå…‰è°± (mag205_225_lowT_1M) |
| **è®­ç»ƒæ ·æœ¬æ•°** | 1,000,000 |
| **éªŒè¯æ ·æœ¬æ•°** | ä»è®­ç»ƒé›†åˆ’åˆ† 10% æˆ–ä½¿ç”¨æ›´å¤§éªŒè¯é›† |
| **æµ‹è¯•æ ·æœ¬æ•°** | 500-1000 |
| **å™ªå£°æ°´å¹³** | Ïƒ = 1.0 |
| **ç›®æ ‡å˜é‡** | log_g |

## 2.2 å®éªŒè®¾è®¡ï¼š3 ç»„å°ç½‘æ ¼

### Sweep 1: æ ‘å¤æ‚åº¦

| å‚æ•° | å€¼ |
|------|-----|
| **num_leaves** | 63 (baseline), 127, 255 |
| **max_depth** | -1 (é»˜è®¤), 10, 12 |
| **å…¶ä»–å‚æ•°** | ä¿æŒ baseline |

### Sweep 2: å­¦ä¹ ç‡ + æ ‘æ•°é‡

| å‚æ•° | å€¼ |
|------|-----|
| **learning_rate** | 0.05 (baseline), 0.02, 0.01 |
| **n_estimators** | 5000, 10000, 20000 |
| **early_stopping_rounds** | 50, 100 |

### Sweep 3: æ­£åˆ™åŒ– / é˜²è¿‡æ‹Ÿåˆ

| å‚æ•° | å€¼ |
|------|-----|
| **min_data_in_leaf** | 20 (é»˜è®¤), 100, 500 |
| **subsample** | 0.8 (baseline), 0.6 |
| **reg_alpha** | 0, 0.1, 1.0 |
| **reg_lambda** | 0, 0.1, 1.0 |

### Sanity Check: å›ºå®šè½®æ•°

| é…ç½® | ç›®çš„ |
|------|------|
| å›ºå®š n_estimators=2000, æ—  early stopping | éªŒè¯ early stopping æ˜¯å¦"è¿‡æ—©åœ" |

## 2.3 Baseline é…ç½®ï¼ˆæ¥è‡ª MVP-1.1ï¼‰

```python
baseline_params = {
    'objective': 'regression',
    'metric': 'rmse',
    'learning_rate': 0.05,
    'num_leaves': 63,
    'max_depth': -1,
    'min_data_in_leaf': 20,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'n_estimators': 5000,
    'early_stopping_rounds': 50,
    'verbose': -1
}
# Baseline Result: RÂ² = 0.5709 @ 1M, trees = 1293
```

## 2.4 è¯„ä»·æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ | ç”¨é€” |
|------|------|------|
| RÂ² | å†³å®šç³»æ•° | ä¸»æŒ‡æ ‡ |
| å®é™…ä½¿ç”¨æ ‘æ•° | early stopping åçš„æ ‘æ•°é‡ | æ¨¡å‹å¤æ‚åº¦ |
| è®­ç»ƒæ—¶é—´ | ç§’ | æ•ˆç‡å‚è€ƒ |
| éªŒè¯æ›²çº¿ | train/valid loss éš epoch å˜åŒ– | è¿‡æ‹Ÿåˆè¯Šæ–­ |

---

# 3. ğŸ“Š å®éªŒå›¾è¡¨

### å›¾ 1ï¼šnum_leaves vs RÂ²

*TODO: å®éªŒå®Œæˆåæ·»åŠ å›¾è¡¨*

**å…³é”®è§‚å¯Ÿ**ï¼š
- TODO

---

### å›¾ 2ï¼šlearning_rate vs RÂ² (with different n_estimators)

*TODO: å®éªŒå®Œæˆåæ·»åŠ å›¾è¡¨*

**å…³é”®è§‚å¯Ÿ**ï¼š
- TODO

---

### å›¾ 3ï¼šTraining Curves (Best Config)

*TODO: å®éªŒå®Œæˆåæ·»åŠ å›¾è¡¨*

**å…³é”®è§‚å¯Ÿ**ï¼š
- TODO

---

### å›¾ 4ï¼šParameter Sensitivity Heatmap

*TODO: å®éªŒå®Œæˆåæ·»åŠ å›¾è¡¨*

**å…³é”®è§‚å¯Ÿ**ï¼š
- TODO

---

# 4. ğŸ’¡ å…³é”®æ´è§

## 4.1 å®è§‚å±‚æ´è§

*TODO: å®éªŒå®Œæˆåå¡«å†™*

## 4.2 æ¨¡å‹å±‚æ´è§

**é¢„æœŸå¯èƒ½çš„å‘ç°**ï¼š

1. **å¦‚æœ num_leavesâ†‘ æœ‰æ•ˆ**ï¼šè¯´æ˜åŸé…ç½®æ¬ æ‹Ÿåˆï¼Œæ ‘å®¹é‡ä¸å¤Ÿ
2. **å¦‚æœ lrâ†“ æœ‰æ•ˆ**ï¼šè¯´æ˜éœ€è¦æ›´ç»†ç²’åº¦çš„æ¢¯åº¦æ›´æ–°
3. **å¦‚æœéƒ½æ— æ•ˆ**ï¼šè¯´æ˜ LightGBM ç¡®å®è¾¾åˆ°äº†æé™

## 4.3 ç‰©ç†è§£é‡Š

- é«˜å™ªå£°ä¸‹ï¼Œæ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆå™ªå£°
- ä½†å¦‚æœæ­£åˆ™åŒ–å¤ªå¼ºï¼Œåˆä¼šæ¬ æ‹ŸåˆçœŸå®ä¿¡å·
- æœ€ä¼˜é…ç½®éœ€è¦åœ¨ä¸¤è€…ä¹‹é—´æ‰¾å¹³è¡¡

---

# 5. ğŸ“ ç»“è®º

## 5.1 æ ¸å¿ƒå‘ç°

> **TODO: å®éªŒå®Œæˆåå¡«å†™**

## 5.2 å…³é”®ç»“è®º

| # | ç»“è®º | è¯æ® |
|---|------|------|
| 1 | TODO | TODO |

## 5.3 è®¾è®¡å¯ç¤º

*TODO: å®éªŒå®Œæˆåå¡«å†™*

## 5.4 ä¸‹ä¸€æ­¥å·¥ä½œ

| æ–¹å‘ | å…·ä½“ä»»åŠ¡ | ä¼˜å…ˆçº§ | å¯¹åº” MVP |
|------|----------|--------|---------|
| å¦‚æœæ‰¾åˆ°æ›´ä¼˜é…ç½® | æ›´æ–° LightGBM baseline | ğŸ”´ P0 | - |
| å¦‚æœæ— æå‡ | ç¡®è®¤ LightGBM è¾¾æé™ | - | è½¬å‘ MVP-2.x |

---

# 6. ğŸ“ é™„å½•

## 6.1 æ•°å€¼ç»“æœè¡¨

### Sweep 1: num_leaves

| num_leaves | max_depth | RÂ² | MAE | Trees | Train Time (s) |
|------------|-----------|-----|-----|-------|----------------|
| 63 (baseline) | -1 | 0.5709 | 0.5845 | 1293 | 1643 |
| 127 | -1 | - | - | - | - |
| 255 | -1 | - | - | - | - |
| 127 | 10 | - | - | - | - |
| 127 | 12 | - | - | - | - |

### Sweep 2: learning_rate

| lr | n_estimators | RÂ² | MAE | Trees | Train Time (s) |
|----|--------------|-----|-----|-------|----------------|
| 0.05 (baseline) | 5000 | 0.5709 | 0.5845 | 1293 | 1643 |
| 0.02 | 5000 | - | - | - | - |
| 0.02 | 10000 | - | - | - | - |
| 0.01 | 10000 | - | - | - | - |
| 0.01 | 20000 | - | - | - | - |

### Sweep 3: æ­£åˆ™åŒ–

| min_data_in_leaf | subsample | RÂ² | MAE | Trees |
|------------------|-----------|-----|-----|-------|
| 20 (baseline) | 0.8 | 0.5709 | 0.5845 | 1293 |
| 100 | 0.8 | - | - | - |
| 500 | 0.8 | - | - | - |
| 20 | 0.6 | - | - | - |

### Sanity Check: å›ºå®šè½®æ•°

| Config | RÂ² | vs Early Stopping |
|--------|-----|-------------------|
| n=2000, no early stop | - | - |
| n=1293, early stop (baseline) | 0.5709 | baseline |

---

## 6.2 å®éªŒæµç¨‹è®°å½•

### 6.2.1 ç¯å¢ƒä¸é…ç½®

| é¡¹ç›® | å€¼ |
|------|-----|
| **ä»“åº“** | `~/VIT` |
| **Python** | 3.13 |
| **å…³é”®ä¾èµ–** | lightgbm, scikit-learn |

### 6.2.2 æ‰§è¡Œå‘½ä»¤

```bash
# TODO: å®éªŒæ‰§è¡Œæ—¶å¡«å†™
cd ~/VIT && source init.sh
python scripts/scaling_lgbm_param_extended.py \
    --sweep-type all \
    --output ./results/scaling_lgbm_param \
    --img-dir /home/swei20/Physics_Informed_AI/logg/scaling/img
```

### 6.2.3 è¿è¡Œæ—¥å¿—æ‘˜è¦

```
# TODO: å®éªŒæ‰§è¡Œæ—¶å¡«å†™
```

---

## 6.3 ç›¸å…³æ–‡ä»¶

| ç±»å‹ | è·¯å¾„ |
|------|------|
| Hub | `logg/scaling/scaling_hub_20251222.md` |
| Roadmap | `logg/scaling/scaling_roadmap_20251222.md` |
| æœ¬æŠ¥å‘Š | `logg/scaling/exp/exp_scaling_lgbm_param_extended_20251222.md` |
| Baseline æŠ¥å‘Š | `logg/scaling/exp/exp_scaling_ml_ceiling_20251222.md` |

---

## ğŸ”— Cross-Repo Metadata

| Field | Value |
|-------|-------|
| **experiment_id** | SCALING-20251222-lgbm-param-01 |
| **priority** | ğŸ”´ P0 |
| **depends_on** | MVP-1.3 (å¯é€‰ï¼ŒéªŒè¯ plateau åå†åšæ›´æœ‰æ„ä¹‰) |
| **blocks** | MVP-1.6, 1.7 (éœ€è¦æœ€ä¼˜é…ç½®ä½œä¸º baseline) |


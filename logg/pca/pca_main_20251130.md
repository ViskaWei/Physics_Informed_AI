# PCA · log_g 实验主笔记（截至 2025-11-30）

- 本目录：`logg/pca/`
- 最近更新时间：2025-11-30
- 写作风格参考：`/home/swei20/VIT/docs`
- 说明：此文件是该子目录所有实验的主索引、核心结论与未来计划。

---

# 目录

0. [问题重述](#0-问题重述)
1. [研究目标](#1-研究目标)
2. [实验地图（含超链接）](#2-实验地图含超链接)
3. [核心发现（中文·专业·压缩）](#3-核心发现中文专业压缩)
4. [关键图表](#4-关键图表)
5. [下一步实验计划](#5-下一步实验计划)
6. [附录：所有子实验索引](#6-附录所有子实验索引)

---

# 0. 问题重述

## 0.1 核心研究问题

> **$\log g$ 信息在 flux 空间中占据多少维度？是集中在少数高方差方向，还是分散在大量低方差方向？**

这个问题直接决定了：
- **NN bottleneck 设计**：如果 $\log g$ 是低维的，可以用很窄的 bottleneck
- **降维策略选择**：是否可以简单用 PCA 预处理
- **正则化方式**：是否需要 variance-aware 正则化

## 0.2 统计学意义

如果前 $k$ 个 PCA 分量的 $R^2$ 已经很高：
$$R^2(k) \approx 1 - \frac{\mathbb{E}[(Y - \mathbb{E}[Y|PC_{1:k}])^2]}{\operatorname{Var}(Y)}$$

则说明 $\log g$ 信息主要在**高方差方向**上。

如果需要很多 PCA 分量才能达到高 $R^2$，则说明信息**分散在低方差方向**。

## 0.3 对 NN 设计的直接影响

| 如果... | 则... |
|---------|-------|
| $k \leq 10$ 达到 $R^2 \geq 0.99$ | Bottleneck 可以很窄（8-16 维），PCA 预处理有效 |
| $k \geq 100$ 才达到 $R^2 \geq 0.99$ | Bottleneck 不能太窄，需要 variance-aware 正则化 |

---

# 1. 研究目标

本目录聚焦于 **PCA 降维对 $\log g$ 预测的影响**，核心问题是：

- $\log g$ 在光谱空间中的**有效信息维度**是多少？
- 是否可以用少量 PCA 分量（如 5-10 维）达到高精度？
- $\log g$ 信息集中在高方差方向（前几个 PC）还是分布在低方差方向？
- 正则化强度 $\alpha$ 如何与 PCA 维度 $k$ 交互？

与 $\log g$ 总目标的关系：为 NN 的 **bottleneck 层设计**和 **variance-aware 正则化**提供理论依据。

---

# 2. 实验地图（含超链接）

| 实验ID | 文件/目录 | 类型 | 关键配置 | 主要指标 | 链接 |
|-------|-----------|------|----------|----------|------|
| E01 | exp_pca_linear_regression_20251128.md | PCA 维度扫描 | k=1-4096, α 扫描 | k≥100 达 $R^2≥0.99$ | [详情](exp_pca_linear_regression_20251128.md) |
| img/ | img/ | 图表目录 | 4 张核心图表 | - | [目录](img/) |

> 表格按重要性排序。

---

# 3. 核心发现（中文·专业·压缩）

## 3.1 宏观结论

| 结论 | 数值证据 | 设计启示 |
|------|---------|---------|
| **线性可逼近** | k~100-1000 + 弱 Ridge 达 $R^2 \approx 0.999$ | 线性 shortcut 是必须的 |
| **"低维假设"推翻** | k=10 仅 $R^2=0.67$，需 k≥100 | Bottleneck 不能太窄 |
| **信息分布宽泛** | 依赖几百个 PC 叠加 | 不能简单用 PCA 预处理 |
| **正则化 = 维度选择** | 强 L2 会"剪掉"低方差方向 | Weight decay 需谨慎 |

## 3.2 PCA 维度 vs $R^2$ 对照表

| n_components | 最优正则化 | $R^2$ | 压缩率 | 备注 |
|--------------|------------|-------|--------|------|
| 5 | Ridge α=0.001 | 0.231 | 99.9% | ❌ 信息丢失严重 |
| 10 | Ridge α=1.0 | 0.667 | 99.8% | ❌ 不足 |
| 20 | Ridge α=0.001 | 0.866 | 99.5% | ⚠️ 勉强可用 |
| 50 | Ridge α=0.001 | 0.975 | 98.8% | ✅ 较好 |
| **100** | Ridge α=0.001 | **0.994** | 97.6% | ✅ **推荐** |
| 500 | Ridge α=0.0001 | **0.9995** | 87.8% | ✅ 最优 |

## 3.3 关键发现：信息在低方差方向

- **现象**：前 5 个 PC 方差占比 >90%，但 $R^2$ 仅 0.23
- **含义**：$\log g$ 信息主要在 PC 20-200 的**低方差方向**
- **启示**：
  - 不能用方差解释度作为维度选择标准
  - 需要 Variance-aware 正则化/归一化

## 3.4 关键数字速查

| 指标 | 值 |
|------|-----|
| 达到 $R^2 ≥ 0.99$ 所需 PC 数 | **100** |
| 达到 $R^2 ≥ 0.95$ 所需 PC 数 | **50** |
| 前 5 PC 的 $R^2$ | 0.231 |
| 前 10 PC 的 $R^2$ | 0.667 |
| 全维度 (4096) $R^2$ | ~0.999 (弱正则) |

---

# 4. 关键图表

> 所有图表位于 `img/` 子目录：

| 图表 | 描述 | 文件 |
|------|------|------|
| PCA 回归对比 | 不同 k 值的 $R^2$ 曲线 | [pca_regression_comparison.png](img/pca_regression_comparison.png) |
| 方差 vs $R^2$ | 累积方差与 $R^2$ 的关系 | [pca_var_vs_r2.png](img/pca_var_vs_r2.png) |
| 贡献谱 (k=200) | $w_j^2 \lambda_j$ 分布 | [pca_contribution_spectrum_k200.png](img/pca_contribution_spectrum_k200.png) |
| 贡献谱 (k=500) | $w_j^2 \lambda_j$ 分布 | [pca_contribution_spectrum_k500.png](img/pca_contribution_spectrum_k500.png) |

---

# 5. 下一步实验计划

| 优先级 | 方向 | 具体任务 | 预期收益 |
|--------|------|----------|----------|
| **P1** | 噪声下的 PCA | 不同 noise level 下的 PCA 维度 vs $R^2$ | 评估 PCA 的抗噪能力 |
| **P1** | Whitening 对比 | PCA whitening vs non-whitening | 验证 variance-aware 正则化 |
| **P2** | 与 TopK 对比 | PCA 降维 vs TopK 特征选择 | 哪种降维更适合 $\log g$ |

---

# 6. 附录：所有子实验索引

## 6.1 完整实验列表

| 文件 | 日期 | 主题 | 状态 |
|------|------|------|------|
| [exp_pca_linear_regression_20251128.md](exp_pca_linear_regression_20251128.md) | 2025-11-28 | PCA 维度扫描 | ✅ 完成 |

## 6.2 相关外部文件

| 类型 | 路径 |
|------|------|
| VIT 总结 | `/home/swei20/VIT/docs/summaries/pca_master_report.md` |

## 6.3 与其他目录的关联

| 目录 | 关联主题 | 链接 |
|------|----------|------|
| `ridge/` | Ridge 正则化对比 | [ridge_main](../ridge/ridge_main_20251130.md) |
| `gta/` | Global Tower 输入维度设计 | [gta_main](../gta/gta_main_20251130.md) |
| `NN/` | NN bottleneck 设计 | [NN_main](../NN/NN_main_20251130.md) |
| `noise/` | TopK 特征选择对比 | [noise_main](../noise/noise_main_20251130.md) |

## 6.4 对 NN 设计的启示

| 设计原则 | 具体建议 | 来源 |
|---------|---------|------|
| **Linear shortcut** | 模型写成 $\hat{y} = w^\top x + g_\theta(x)$ | 线性本质 |
| **Variance-aware 正则** | 输入前做 PCA + whitening | 低方差方向重要 |
| **容量不必大** | 线性模型已接近上限 | $R^2=0.999$ |
| **Bottleneck ≥ 100** | 不能过度降维 | k≥100 才达 0.99 |

---

*最后更新: 2025-11-30*  
*核心发现: $\log g$ 是高维分散在低方差方向上的近线性函数，需要 k≥100 个 PC 才能达到 $R^2≥0.99$*


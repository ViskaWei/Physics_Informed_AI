# ğŸ“˜ MLP & CNN Baseline å®éªŒæŠ¥å‘Š
> **Name:** TODO | **ID:** `VIT-20251130-mlp-01`  
> **Topic:** `mlp` | **MVP:** MVP-1.1 | **Project:** `VIT`  
> **Author:** Viska Wei | **Date:** 2025-11-30 | **Status:** ğŸ”„
```
ğŸ’¡ å®éªŒç›®çš„  
å†³å®šï¼šå½±å“çš„å†³ç­–
```

---


## ğŸ”— Upstream Links
| Type | Link |
|------|------|
| ğŸ§  Hub | `logg/mlp/mlp_hub.md` |
| ğŸ—ºï¸ Roadmap | `logg/mlp/mlp_roadmap.md` |

---

---

# âš¡ æ ¸å¿ƒç»“è®ºé€Ÿè§ˆï¼ˆä¾› main æå–ï¼‰

### ä¸€å¥è¯æ€»ç»“

> **MLP åœ¨ noise=1.0 æ—¶è¶…è¿‡ Ridge 6.3%ï¼ˆ$R^2=0.487$ vs 0.458ï¼‰ï¼Œä½† CNN å¤±è´¥ï¼ˆ$R^2=0.13$ï¼‰ï¼š$\log g$ é¢„æµ‹éœ€è¦å…¨å±€ä¿¡æ¯ï¼Œå±€éƒ¨æ„Ÿå—é‡æ¶æ„ä¸é€‚ç”¨ã€‚**

### å¯¹å‡è®¾çš„éªŒè¯

| éªŒè¯é—®é¢˜ | ç»“æœ | ç»“è®º |
|---------|------|------|
| MLP èƒ½å¦è¶…è¿‡ Ridgeï¼Ÿ | âœ… æ˜¯ï¼Œ+6.3% | éçº¿æ€§æœ‰è¾¹é™…æ”¶ç›Š |
| CNN èƒ½å¦åˆ©ç”¨å±€éƒ¨ç»“æ„ï¼Ÿ | âŒ å¦ï¼Œ$R^2=0.13$ | æ„Ÿå—é‡ä¸è¶³ï¼Œéœ€å…¨å±€ä¿¡æ¯ |
| æœ€ä¼˜æ¿€æ´»å‡½æ•°ï¼Ÿ | âœ… GELU > Tanh > ReLU | ä¸ Transformer ä¸€è‡´ |
| é«˜ learning rate èƒ½ workï¼Ÿ | âœ… æ˜¯ï¼Œlr=0.001 æœ€ä¼˜ | ä¸éœ€è¦å¾ˆä¿å®ˆçš„ lr |

### è®¾è®¡å¯ç¤ºï¼ˆ1-2 æ¡ï¼‰

| å¯ç¤º | å…·ä½“å»ºè®® |
|------|---------|
| **å…¨å±€æ„Ÿå—é‡å¿…éœ€** | $\log g$ é¢„æµ‹éœ€è¦ attention/å…¨è¿æ¥ï¼Œä¸èƒ½ç”¨çº¯å·ç§¯ |
| **MLP æ˜¯åˆç† baseline** | ç”¨ MLP $R^2=0.487$ ä½œä¸º NN æœ€ä½åŸºçº¿ |

### å…³é”®æ•°å­—

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| MLP best $R^2$ (noise=1.0) | **0.487** |
| CNN best $R^2$ (noise=1.0) | **0.13** |
| Ridge baseline $R^2$ | **0.458** |
| æœ€ä¼˜ lr | **0.001** |
| æœ€ä¼˜æ¿€æ´» | **GELU** |

---

# ğŸ“‘ ç›®å½•

- [1. ğŸ¯ ç›®æ ‡](#1--ç›®æ ‡)
- [2. ğŸ§ª å®éªŒè®¾è®¡](#2--å®éªŒè®¾è®¡experiment-design)
- [3. ğŸ“Š å®éªŒå›¾è¡¨](#3--å®éªŒå›¾è¡¨)
- [4. ğŸ’¡ å…³é”®æ´è§](#4--å…³é”®æ´è§key-insights)
- [5. ğŸ“ ç»“è®º](#5--ç»“è®ºconclusion)
- [6. ğŸ“ é™„å½•](#6--é™„å½•)

---

# 1. ğŸ¯ ç›®æ ‡

## 1.1 èƒŒæ™¯ä¸åŠ¨æœº

å‰æœŸçº¿æ€§å›å½’å®éªŒå·²ç»å»ºç«‹äº†é‡è¦çš„åŸºçº¿è®¤è¯†ï¼š
- **Ridge Regression** åœ¨ noise=1.0 æ—¶è¾¾åˆ° $R^2 = 0.458$
- **LightGBM** åœ¨ noise=1.0 æ—¶è¾¾åˆ° $R^2 = 0.536$
- **PCA å®éªŒ** è¡¨æ˜æœ‰æ•ˆä¿¡æ¯ç»´åº¦çº¦ 100â€“200
- **Top-K å®éªŒ** è¡¨æ˜ä¿¡æ¯é«˜åº¦ç¨€ç–ï¼Œçº¦ 24% åƒç´  (Kâ‰ˆ1000) å³å¯

æœ¬å®éªŒæ—¨åœ¨ï¼š
> **ç³»ç»Ÿæ€§åœ°æ¢ç´¢ MLP å’Œ CNN åœ¨å…¨è°±è¾“å…¥ä¸‹çš„è¡¨ç°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ã€æ¿€æ´»å‡½æ•°ã€æ¶æ„æ·±åº¦ç­‰å…³é”®è¶…å‚æ•°çš„å½±å“ï¼Œä¸ºåç»­ Physics-Informed æ¶æ„æä¾›åŸºçº¿ã€‚**

å…·ä½“ç›®æ ‡ï¼š
1. å»ºç«‹ MLP baselineï¼šéªŒè¯æ˜¯å¦èƒ½è¶…è¿‡ Ridgeï¼Œæ¥è¿‘ LightGBM
2. æ¢ç´¢ CNN å¯è¡Œæ€§ï¼šæµ‹è¯• 1D CNN èƒ½å¦åˆ©ç”¨å±€éƒ¨è°±çº¿ç»“æ„
3. è¶…å‚æ•°æ¢ç´¢ï¼šå­¦ä¹ ç‡ã€æ¿€æ´»å‡½æ•°ã€åˆå§‹åŒ–ã€æ­£åˆ™åŒ–çš„ç³»ç»Ÿæœç´¢
4. è¯†åˆ«æ¶æ„ç“¶é¢ˆï¼šåˆ†æå¤±è´¥åŸå› ï¼ŒæŒ‡å¯¼åç»­æ”¹è¿›

## 1.2 æ ¸å¿ƒå‡è®¾

> **åœ¨æ ‡å‡†å™ªå£°ï¼ˆnoise=1.0ï¼‰æ¡ä»¶ä¸‹ï¼ŒMLP åº”èƒ½è¾¾åˆ°æˆ–è¶…è¿‡ Ridge baseline ($R^2 = 0.458$)ï¼›CNN é€šè¿‡æ•è·å±€éƒ¨è°±çº¿ç»“æ„ï¼Œå¯èƒ½è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚**

å¦‚æœå‡è®¾æˆç«‹ï¼Œæ„å‘³ç€ï¼š
- ç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ åˆ°æ¯”çº¿æ€§æ¨¡å‹æ›´é²æ£’çš„è¡¨ç¤º
- CNN çš„å½’çº³åç½®å¯¹å…‰è°±æ•°æ®æœ‰æ•ˆ
- å¯ä»¥ä½œä¸ºåç»­æ›´å¤æ‚æ¶æ„çš„åˆç†èµ·ç‚¹

å¦‚æœå‡è®¾ä¸æˆç«‹ï¼Œåˆ™éœ€è¦ï¼š
- åˆ†æå¤±è´¥åŸå› ï¼ˆå…¨å±€ vs å±€éƒ¨ä¿¡æ¯ã€æ„Ÿå—é‡ä¸è¶³ç­‰ï¼‰
- è€ƒè™‘æ›¿ä»£æ¶æ„ï¼ˆæ³¨æ„åŠ›æœºåˆ¶ã€Top-K é¢„é€‰ç­‰ï¼‰
- é‡æ–°å®¡è§†è¾“å…¥è¡¨ç¤ºï¼ˆå…¨è°± vs ç‰¹å¾é€‰æ‹©ï¼‰

## 1.3 éªŒè¯é—®é¢˜

| # | é—®é¢˜ | éªŒè¯ç›®æ ‡ | ç»“æœ |
|---|------|---------|------|
| Q1 | MLP èƒ½å¦è¶…è¿‡ Ridge ($R^2 = 0.458$)ï¼Ÿ | éªŒè¯ MLP çš„éçº¿æ€§å»ºæ¨¡èƒ½åŠ› | âœ… **æ˜¯**ï¼Œæœ€ä½³ $R^2 = 0.487$ (+6.3%) |
| Q2 | MLP èƒ½å¦æ¥è¿‘ LightGBM ($R^2 = 0.536$)ï¼Ÿ | å¯¹æ ‡æ ‘æ¨¡å‹æ€§èƒ½ | âŒ **å¦**ï¼Œå·®è· 9.1% |
| Q3 | CNN èƒ½å¦æœ‰æ•ˆå­¦ä¹ ï¼Ÿ | éªŒè¯å·ç§¯å¯¹å…‰è°±çš„é€‚ç”¨æ€§ | âŒ **å¦**ï¼Œæœ€ä½³ $R^2 = 0.016$ (â‰ˆéšæœº) |
| Q4 | å“ªä¸ªå­¦ä¹ ç‡æœ€æœ‰æ•ˆï¼Ÿ | ç¡®å®šè®­ç»ƒç¨³å®šåŒºé—´ | âœ… lr=0.001 (MLP), lr=0.003 (CNN) |
| Q5 | å“ªç§æ¿€æ´»å‡½æ•°æœ€ä½³ï¼Ÿ | é€‰æ‹©æ¿€æ´»å‡½æ•° | âœ… GELU (å¤§æ¨¡å‹), ReLU (å°æ¨¡å‹) |

## 1.4 ç»“è®ºæ‘˜è¦

### 1.4.1 å®éªŒç»“è®º

| ç»“è®º | è¯´æ˜ |
|------|------|
| **MLP > Ridge** | æœ€ä½³ MLP è¾¾åˆ° $R^2 = 0.487$ï¼Œè¶…è¿‡ Ridge 6.3% |
| **MLP < LightGBM** | ä¸ LightGBM ($R^2 = 0.536$) ä»æœ‰ 9.1% å·®è· |
| **CNN å…¨é¢å¤±è´¥** | æ‰€æœ‰ CNN å®éªŒ $R^2 \approx 0$ï¼Œæ¥è¿‘éšæœºçŒœæµ‹ |
| **å­¦ä¹ ç‡ææ•æ„Ÿ** | MLP ä»… lr=0.001 æœ‰æ•ˆï¼ŒCNN ä»… lr=0.003 å‹‰å¼ºå¯ç”¨ |

### 1.4.2 è®¾è®¡å¯ç¤º

| è®¾è®¡åŸåˆ™ | å…·ä½“å»ºè®® |
|---------|---------|
| **MLP å¯ç”¨** | ä½œä¸º NN baseline æ˜¯åˆç†çš„ï¼Œå¯ç»§ç»­ä¼˜åŒ– |
| **CNN éœ€é‡æ–°è®¾è®¡** | å…¨è°±è¾“å…¥å¯¹æµ…å±‚ CNN æ— æ•ˆï¼Œéœ€ Top-K + å±€éƒ¨çª—å£ |
| **æ­£åˆ™åŒ–å…³é”®** | dropout=0.3 æ˜¯å¿…è¦çš„ï¼Œé˜²æ­¢ä¸¥é‡è¿‡æ‹Ÿåˆ |

> **ä¸€å¥è¯æ€»ç»“**ï¼šMLP åœ¨ noise=1.0 ä¸‹å¯è¶…è¶Š Ridge (+6.3%)ï¼Œä½† CNN å…¨é¢å¤±è´¥ï¼Œè¯´æ˜å…¨è°±çš„å…¨å±€ä¿¡æ¯æ¯”å±€éƒ¨çº¹ç†æ›´é‡è¦ï¼Œåç»­åº”ä¼˜å…ˆä¼˜åŒ– MLP æˆ–å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ã€‚

---

# 2. ğŸ§ª å®éªŒè®¾è®¡ï¼ˆExperiment Designï¼‰

## 2.1 æ•°æ®ï¼ˆDataï¼‰

| é…ç½®é¡¹ | å€¼ |
|--------|-----|
| è®­ç»ƒæ ·æœ¬æ•° | 32,000 |
| éªŒè¯æ ·æœ¬æ•° | 10,000 |
| æµ‹è¯•æ ·æœ¬æ•° | 10,000 |
| ç‰¹å¾ç»´åº¦ | 4,096 (flux) |
| æ ‡ç­¾å‚æ•° | $\log g$ |
| å™ªå£°æ°´å¹³ | 1.0 (æ ‡å‡†å™ªå£°) |

**å™ªå£°æ¨¡å‹ï¼š**
$$
\text{noisy\_flux} = \text{flux} + \mathcal{N}(0, 1) \times \text{error} \times \text{noise\_level}
$$

## 2.2 ä½¿ç”¨çš„ç‰¹å¾ç±»å‹

| ç‰¹å¾ç±»å‹ | ç»´åº¦ | è¯´æ˜ |
|---------|------|------|
| å…¨è°± flux | 4096 | æ ‡å‡†åŒ–åçš„å…‰è°±æµé‡ |

## 2.3 æ¨¡å‹ä¸ç®—æ³•ï¼ˆModel & Algorithmï¼‰

### 2.3.1 MLP æ¶æ„

**å¤§æ¨¡å‹** (hidden=[256, 64], 1,065,345 å‚æ•°)ï¼š
$$
\text{Input} (4096) \xrightarrow{\text{Linear}} 256 \xrightarrow{\text{Act}} 64 \xrightarrow{\text{Linear}} 1
$$

**å°æ¨¡å‹** (hidden=[128, 32], 528,577 å‚æ•°)ï¼š
$$
\text{Input} (4096) \xrightarrow{\text{Linear}} 128 \xrightarrow{\text{Act}} 32 \xrightarrow{\text{Linear}} 1
$$

### 2.3.2 CNN æ¶æ„

**åŸºç¡€æ¶æ„** (2å±‚, channels=[32,64], kernel=7)ï¼š
```
Input (4096) â†’ Conv1d(32, k=7) â†’ ReLU â†’ MaxPool(2)
            â†’ Conv1d(64, k=7) â†’ ReLU â†’ MaxPool(2)
            â†’ AdaptiveAvgPool â†’ FC â†’ Output
```

**æµ‹è¯•å˜ä½“**ï¼š
- Kernel size: 7, 15, 21
- Channels: [32], [32,64], [64,128], [32,64,128]
- BatchNorm: True/False

## 2.4 è¶…å‚æ•°ï¼ˆHyperparametersï¼‰

### è®­ç»ƒé…ç½®ï¼ˆå›ºå®šï¼‰

| å‚æ•° | å€¼ |
|------|-----|
| Optimizer | AdamW |
| Batch size | 2048 |
| Max epochs | 100 |
| Early stopping patience | 50 |
| Gradient clip | 1.0 |
| Mixed precision | True |
| Seed | 42 |

### æœç´¢ç©ºé—´

| æ¨¡å‹ | å‚æ•° | æœç´¢èŒƒå›´ |
|------|------|----------|
| MLP | Learning rate | $\{0.1, 0.01, 0.001, 0.0005\}$ |
| MLP | Dropout | $\{0.1, 0.3\}$ |
| MLP | Weight decay | $\{0, 10^{-4}\}$ |
| MLP | æ¿€æ´»å‡½æ•° | $\{\text{ReLU}, \text{GELU}, \text{SiLU}\}$ |
| MLP | åˆå§‹åŒ– | $\{\text{Random}, \text{Xavier}\}$ |
| CNN | Learning rate | $\{0.1, 0.03, 0.01, 0.003, 0.001, 3\times10^{-4}\}$ |
| CNN | Weight decay | $\{0, 10^{-5}, 10^{-4}, 5\times10^{-4}, 10^{-3}\}$ |
| CNN | Kernel size | $\{7, 15, 21\}$ |

## 2.5 åŸºçº¿å¯¹æ¯”

| æ¨¡å‹ | Test $R^2$ | Test MAE | Test RMSE | è®­ç»ƒæ—¶é—´ |
|------|-----------|----------|-----------|----------|
| **LightGBM** | **0.536** | ~0.16 | ~0.20 | ~80s |
| **Ridge ($\alpha=200$)** | **0.458** | 0.173 | 0.215 | ~1s |

---

# 3. ğŸ“Š å®éªŒå›¾è¡¨

> å®éªŒå›¾è¡¨å¾…ç”Ÿæˆ

### å›¾ 1ï¼šMLP å­¦ä¹ ç‡æ¢ç´¢ç»“æœï¼ˆå»ºè®®ç»˜åˆ¶ï¼‰

**å»ºè®®å†…å®¹ï¼š**
- X è½´ï¼šLearning Rate (log scale)
- Y è½´ï¼šTest $R^2$
- æ ‡æ³¨ï¼šRidge baseline æ°´å¹³çº¿

**é¢„æœŸè§‚å¯Ÿï¼š**
- ä»… lr=0.001 æœ‰æ•ˆï¼Œå…¶ä»–å­¦ä¹ ç‡è®­ç»ƒå¤±è´¥

### å›¾ 2ï¼šMLP æ¿€æ´»å‡½æ•°å¯¹æ¯”ï¼ˆå»ºè®®ç»˜åˆ¶ï¼‰

**å»ºè®®å†…å®¹ï¼š**
- åˆ†ç»„æŸ±çŠ¶å›¾ï¼šå¤§æ¨¡å‹ vs å°æ¨¡å‹
- æ¯ç»„åŒ…å« ReLU, GELU, SiLU
- Y è½´ï¼šTest $R^2$

**é¢„æœŸè§‚å¯Ÿï¼š**
- å¤§æ¨¡å‹ï¼šGELU > ReLU > SiLU
- å°æ¨¡å‹ï¼šReLU > SiLU > GELU

### å›¾ 3ï¼šCNN æ¶æ„æ¢ç´¢çƒ­åŠ›å›¾ï¼ˆå»ºè®®ç»˜åˆ¶ï¼‰

**å»ºè®®å†…å®¹ï¼š**
- X è½´ï¼šKernel Size
- Y è½´ï¼šé€šé“é…ç½®
- é¢œè‰²ï¼šTest $R^2$

**é¢„æœŸè§‚å¯Ÿï¼š**
- æ‰€æœ‰é…ç½®é¢œè‰²æ¥è¿‘ï¼ˆå‡ â‰ˆ 0ï¼‰

---

# 4. ğŸ’¡ å…³é”®æ´è§ï¼ˆKey Insightsï¼‰

## 4.1 å®è§‚å±‚æ´è§ï¼ˆç”¨äºæŒ‡å¯¼ Neural Network æ¶æ„è®¾è®¡ï¼‰

### Insight 1: MLP å¯è¶…è¶Š Ridge Baseline
- **ç°è±¡**ï¼šæœ€ä½³ MLP ($R^2 = 0.487$) è¶…è¿‡ Ridge ($R^2 = 0.458$) çº¦ 6.3%
- **å«ä¹‰**ï¼šå­˜åœ¨éçº¿æ€§ä¿¡æ¯å¯ä¾›ç¥ç»ç½‘ç»œåˆ©ç”¨
- **è®¾è®¡å¯ç¤º**ï¼šMLP æ˜¯åˆç†çš„ baseline é€‰æ‹©ï¼Œå€¼å¾—ç»§ç»­ä¼˜åŒ–

### Insight 2: CNN åœ¨å…¨è°±è¾“å…¥ä¸Šå…¨é¢å¤±è´¥
- **ç°è±¡**ï¼šæ‰€æœ‰ CNN å®éªŒ $R^2 \approx 0.016$ï¼Œæ¥è¿‘éšæœºçŒœæµ‹
- **å«ä¹‰**ï¼š
  - 4096 ç»´è¾“å…¥å¯¹æµ…å±‚ CNN è¿‡é•¿
  - $\log g$ ä¿¡æ¯ä¾èµ–å…¨å±€æ¨¡å¼ï¼Œéå±€éƒ¨çº¹ç†
  - 2-3 å±‚ CNN æ„Ÿå—é‡ (~50 åƒç´ ) è¿œå°äºè¾“å…¥é•¿åº¦
- **è®¾è®¡å¯ç¤º**ï¼š
  - éœ€è¦å…ˆç”¨ Top-K é€‰æ‹©é‡è¦åŒºåŸŸ
  - æˆ–ä½¿ç”¨æ›´æ·±ç½‘ç»œ + æ®‹å·®è¿æ¥
  - æˆ–å¼•å…¥è‡ªæ³¨æ„åŠ›æ•è·é•¿ç¨‹ä¾èµ–

### Insight 3: å­¦ä¹ ç‡æå…¶æ•æ„Ÿ
- **ç°è±¡**ï¼š
  - MLP: ä»… lr=0.001 æœ‰æ•ˆï¼Œlr=0.01/0.1 å®Œå…¨å¤±è´¥
  - CNN: ä»… lr=0.003 å‹‰å¼ºå¯ç”¨ï¼Œå…¶ä»–å­¦ä¹ ç‡å‡ ä¹æ— æ•ˆ
- **å«ä¹‰**ï¼šè®­ç»ƒä¸ç¨³å®šï¼Œéœ€è¦ç²¾ç»†è°ƒå‚
- **è®¾è®¡å¯ç¤º**ï¼šä½¿ç”¨ learning rate warmup æˆ– scheduler

## 4.2 æ¨¡å‹å±‚æ´è§ï¼ˆç”¨äºä¼˜åŒ–æ¨¡å‹ï¼‰

### Insight 4: æ¿€æ´»å‡½æ•°é€‰æ‹©ä¸æ¨¡å‹å®¹é‡ç›¸å…³
- **ç°è±¡**ï¼š
  - å¤§æ¨¡å‹ (1M å‚æ•°): GELU ($R^2 = 0.483$) > ReLU ($R^2 = 0.474$) > SiLU ($R^2 = 0.449$)
  - å°æ¨¡å‹ (0.5M å‚æ•°): ReLU ($R^2 = 0.460$) > SiLU ($R^2 = 0.437$) > GELU ($R^2 = 0.412$)
- **å«ä¹‰**ï¼šGELU çš„å¹³æ»‘ç‰¹æ€§åœ¨å¤§æ¨¡å‹ä¸­æ›´æœ‰åˆ©ï¼Œå°æ¨¡å‹åè€Œéœ€è¦ ReLU çš„ç¡¬é˜ˆå€¼
- **è®¾è®¡å¯ç¤º**ï¼šæ ¹æ®æ¨¡å‹å®¹é‡é€‰æ‹©æ¿€æ´»å‡½æ•°

### Insight 5: Xavier åˆå§‹åŒ– + é€‚å½“æ­£åˆ™åŒ–æœ‰æ•ˆ
- **ç°è±¡**ï¼šXavier åˆå§‹åŒ– + dropout=0.1 + wd=1e-4 è¡¨ç°ç¨³å®š
- **å«ä¹‰**ï¼šè‰¯å¥½çš„åˆå§‹åŒ–å’Œæ­£åˆ™åŒ–ç»„åˆå¯ä»¥ç¨³å®šè®­ç»ƒ
- **è®¾è®¡å¯ç¤º**ï¼šå›ºå®šä½¿ç”¨ Xavier åˆå§‹åŒ–ä½œä¸ºé»˜è®¤é€‰é¡¹

### Insight 6: å¤§æ¨¡å‹ç•¥ä¼˜äºå°æ¨¡å‹
- **ç°è±¡**ï¼š1M å‚æ•°æ¨¡å‹ ($R^2 = 0.483$) > 0.5M å‚æ•°æ¨¡å‹ ($R^2 = 0.460$)
- **å«ä¹‰**ï¼šå½“å‰ä»»åŠ¡éœ€è¦è¶³å¤Ÿçš„æ¨¡å‹å®¹é‡
- **è®¾è®¡å¯ç¤º**ï¼šä¸åº”è¿‡åº¦å‹ç¼©æ¨¡å‹ï¼Œhidden=[256, 64] æ˜¯åˆç†èµ·ç‚¹

## 4.3 å®éªŒå±‚ç»†èŠ‚æ´è§

### Insight 7: MLP å­˜åœ¨è½»å¾®è¿‡æ‹Ÿåˆä½†å¯æ§
- **ç°è±¡**ï¼šTrain $R^2$ = 0.459, Test $R^2$ = 0.487ï¼ˆæµ‹è¯•ç•¥é«˜äºè®­ç»ƒï¼‰
- **å«ä¹‰**ï¼šå™ªå£°å¯¼è‡´è®­ç»ƒä¸ç¨³å®šï¼Œä½†æ³›åŒ–è‰¯å¥½
- **è®¾è®¡å¯ç¤º**ï¼šå½“å‰æ­£åˆ™åŒ–ç­–ç•¥ï¼ˆdropout=0.3ï¼‰æ˜¯æœ‰æ•ˆçš„

### Insight 8: 3 å±‚ CNN è®­ç»ƒå´©æºƒ
- **ç°è±¡**ï¼š3 å±‚ CNN (channels=[32,64,128]) å‡ºç° NaN
- **å«ä¹‰**ï¼šæ·±å±‚ CNN åœ¨è¯¥ä»»åŠ¡ä¸Šæ¢¯åº¦ä¸ç¨³å®š
- **è®¾è®¡å¯ç¤º**ï¼šéœ€è¦æ®‹å·®è¿æ¥æˆ–æ¢¯åº¦è£å‰ª

---

# 5. ğŸ“ ç»“è®ºï¼ˆConclusionï¼‰

## 5.1 æ ¸å¿ƒå‘ç°

> **MLP å¯è¶…è¶Š Ridge baseline (+6.3%)ï¼Œä½†ä»ä¸åŠ LightGBM (-9.1%)ï¼›CNN åœ¨å…¨è°±è¾“å…¥ä¸Šå…¨é¢å¤±è´¥ï¼Œè¯´æ˜ $\log g$ ä¿¡æ¯ä¾èµ–å…¨å±€ç‰¹å¾è€Œéå±€éƒ¨çº¹ç†ã€‚**

- âŒ åŸå‡è®¾ï¼šCNN é€šè¿‡æ•è·å±€éƒ¨è°±çº¿ç»“æ„å¯ä»¥æå‡æ€§èƒ½
- âœ… å®éªŒç»“æœï¼šCNN å®Œå…¨å¤±è´¥ ($R^2 \approx 0$)ï¼ŒMLP åè€Œæ›´å¥½

## 5.2 å…³é”®ç»“è®ºï¼ˆ2-4 æ¡ï¼‰

| # | ç»“è®º | è¯æ® |
|---|------|------|
| 1 | **MLP å¯è¶…è¶Š Ridge** | $R^2 = 0.487$ vs 0.458 (+6.3%) |
| 2 | **CNN åœ¨å…¨è°±ä¸Šæ— æ•ˆ** | æœ€ä½³ $R^2 = 0.016$ï¼Œæ¥è¿‘éšæœº |
| 3 | **å­¦ä¹ ç‡ææ•æ„Ÿ** | MLP ä»… lr=0.001 æœ‰æ•ˆï¼Œå…¶ä»–å®Œå…¨å¤±è´¥ |
| 4 | **GELU å¯¹å¤§æ¨¡å‹æœ€ä¼˜** | å¤§æ¨¡å‹ GELU ($R^2 = 0.483$) > ReLU ($R^2 = 0.474$) |

## 5.3 è®¾è®¡å¯ç¤º

### æ¶æ„åŸåˆ™

| åŸåˆ™ | å»ºè®® | åŸå›  |
|------|------|------|
| **ä¼˜å…ˆ MLP** | ä½¿ç”¨ MLP è€Œé CNN ä½œä¸º baseline | CNN å…¨é¢å¤±è´¥ |
| **è¶³å¤Ÿå®¹é‡** | hidden=[256, 64]ï¼Œçº¦ 1M å‚æ•° | å¤§æ¨¡å‹ç•¥ä¼˜äºå°æ¨¡å‹ |
| **æ¿€æ´»å‡½æ•°** | GELU (å¤§æ¨¡å‹) / ReLU (å°æ¨¡å‹) | ä¸æ¨¡å‹å®¹é‡åŒ¹é… |

### æ­£åˆ™åŒ–ç­–ç•¥

| ç­–ç•¥ | å»ºè®®é…ç½® | è¯´æ˜ |
|------|----------|------|
| Dropout | 0.1-0.3 | é˜²æ­¢è¿‡æ‹Ÿåˆ |
| Weight decay | $10^{-4}$ | é…åˆ Xavier åˆå§‹åŒ– |
| åˆå§‹åŒ– | Xavier | ç¨³å®šè®­ç»ƒ |

### âš ï¸ å¸¸è§é™·é˜±

| å¸¸è§åšæ³• | å®éªŒè¯æ® |
|----------|----------|
| "ä½¿ç”¨ CNN æ•è·å±€éƒ¨è°±çº¿ç‰¹å¾" | å…¨é¢å¤±è´¥ï¼Œ$R^2 \approx 0$ |
| "ä½¿ç”¨è¾ƒé«˜å­¦ä¹ ç‡ (0.01, 0.1)" | è®­ç»ƒå®Œå…¨å¤±è´¥ |
| "3 å±‚æˆ–æ›´æ·± CNN" | è®­ç»ƒå´©æºƒ (NaN) |

## 5.4 ç‰©ç†è§£é‡Š

### CNN å¤±è´¥åŸå› åˆ†æ

| åŸå›  | è¯´æ˜ | è¯æ® |
|------|------|------|
| **å…¨è°±è¾“å…¥å¤ªé•¿** | 4096 ç»´å¯¹æµ…å±‚ CNN éš¾ä»¥æ•è·å…¨å±€ä¾èµ– | æ‰€æœ‰æ¶æ„å‡å¤±è´¥ |
| **ç¼ºä¹å±€éƒ¨ä¸å˜æ€§** | $\log g$ ä¿¡æ¯åœ¨ç‰¹å®šè°±çº¿ä½ç½®ï¼Œéçº¹ç†ç‰¹å¾ | å¢å¤§ kernel æ— æ•ˆ |
| **æ„Ÿå—é‡ä¸è¶³** | 2-3 å±‚ CNN æ„Ÿå—é‡ ~50 åƒç´  vs 4096 è¾“å…¥ | æ›´æ·±ç½‘ç»œå´©æºƒ |

### MLP æˆåŠŸåŸå› åˆ†æ

| åŸå›  | è¯´æ˜ |
|------|------|
| **å…¨è¿æ¥æ•è·å…¨å±€** | å¯ç›´æ¥å­¦ä¹ ä»»æ„ä½ç½®è°±çº¿ç»„åˆ |
| **è¶³å¤Ÿå‚æ•°é‡** | 1M å‚æ•°è¶³ä»¥å»ºæ¨¡ 4096â†’1 æ˜ å°„ |
| **é€‚å½“æ­£åˆ™åŒ–** | dropout=0.3 é˜²æ­¢è¿‡æ‹Ÿåˆ |

## 5.5 å…³é”®æ•°å­—é€ŸæŸ¥

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| **æœ€ä½³ MLP** | $R^2 = 0.487$ (lr=0.001, dropout=0.3) |
| **æœ€ä½³ MLP (GELU)** | $R^2 = 0.483$ (Xavier, wd=1e-4) |
| **æœ€ä½³ CNN** | $R^2 = 0.016$ (lr=0.003, wd=5e-4) |
| **Ridge baseline** | $R^2 = 0.458$ |
| **LightGBM baseline** | $R^2 = 0.536$ |
| **MLP vs Ridge** | **+6.3%** |
| **MLP vs LightGBM** | **-9.1%** |

## 5.6 ä¸‹ä¸€æ­¥å·¥ä½œ

| æ–¹å‘ | å…·ä½“ä»»åŠ¡ | ä¼˜å…ˆçº§ |
|------|----------|--------|
| **MLP è¶…å‚æ•°ä¼˜åŒ–** | æ›´ç»†è‡´çš„ lr/wd ç½‘æ ¼æœç´¢ | P0 |
| **Ridge åˆå§‹åŒ–** | ç”¨ Ridge æƒé‡åˆå§‹åŒ– MLP ç¬¬ä¸€å±‚ | P1 |
| **Top-K + CNN** | å…ˆé€‰ Top-K é‡è¦ç‰¹å¾ï¼Œå†ç”¨ CNN å¤„ç†å±€éƒ¨çª—å£ | P1 |
| **æ³¨æ„åŠ›æœºåˆ¶** | æ·»åŠ è‡ªæ³¨æ„åŠ›å±‚æ•è·é•¿ç¨‹ä¾èµ– | P2 |
| **é›†æˆæ–¹æ³•** | MLP + Ridge é›†æˆ | P2 |
| **ä½å™ªå£°éªŒè¯** | åœ¨ noise=0 ä¸‹éªŒè¯ CNN èƒ½å¦å­¦ä¹  | P2 |

---

# 6. ğŸ“ é™„å½•

## 6.1 æ•°å€¼ç»“æœè¡¨ï¼ˆResultsï¼‰

### 6.1.1 MLP Stage 1: å­¦ä¹ ç‡æ¢ç´¢ (dropout=0.3, wd=0)

| å®éªŒID | LR | Train $R^2$ | Val $R^2$ | **Test $R^2$** | Test MAE | Epochs | å‚æ•°é‡ |
|--------|-----|----------|--------|-------------|----------|--------|--------|
| Step1_lr1en03_wd0 | **0.001** | 0.459 | 0.417 | **0.487** ğŸ† | 0.660 | 98 | 1,065,345 |
| Step1_lr1en02_wd0 | 0.01 | -0.00003 | -0.001 | -0.0005 | 1.002 | 38 | 1,065,345 |
| Step1_lr1en01_wd0 | 0.1 | -0.00003 | -0.001 | -0.0005 | 1.002 | 7 | 1,065,345 |

### 6.1.2 MLP Stage 2: æ¿€æ´»å‡½æ•°ä¸æ¶æ„æ¢ç´¢ (lr=0.0005, wd=1e-4, Xavier)

**å¤§æ¨¡å‹** (hidden=[256, 64], 1,065,345 å‚æ•°)ï¼š

| å®éªŒID | æ¿€æ´»å‡½æ•° | Train $R^2$ | Val $R^2$ | **Test $R^2$** | Test MAE | Test RMSE |
|--------|----------|----------|--------|-------------|----------|-----------|
| Step2_2L_256_gelu_xavier | **GELU** | 0.443 | 0.401 | **0.483** ğŸ† | 0.672 | 0.840 |
| Step2_2L_256_relu_xavier | ReLU | 0.455 | 0.415 | 0.474 | 0.672 | 0.847 |
| Step2_2L_256_silu_xavier | SiLU | 0.406 | 0.373 | 0.449 | 0.701 | 0.867 |

**å°æ¨¡å‹** (hidden=[128, 32], 528,577 å‚æ•°)ï¼š

| å®éªŒID | æ¿€æ´»å‡½æ•° | Train $R^2$ | Val $R^2$ | **Test $R^2$** | Test MAE | Test RMSE |
|--------|----------|----------|--------|-------------|----------|-----------|
| Step2_2L_128_relu_xavier | **ReLU** | 0.437 | 0.388 | **0.460** ğŸ† | 0.684 | 0.859 |
| Step2_2L_128_silu_xavier | SiLU | 0.395 | 0.360 | 0.437 | 0.713 | 0.877 |
| Step2_2L_128_gelu_xavier | GELU | 0.362 | 0.330 | 0.412 | 0.739 | 0.896 |

### 6.1.3 CNN Stage 1: å­¦ä¹ ç‡ä¸æ­£åˆ™åŒ–æ¢ç´¢

| å®éªŒID | LR | WD | Train $R^2$ | Val $R^2$ | **Test $R^2$** | Epochs |
|--------|-----|------|----------|--------|-------------|--------|
| CNN_S1_lr3en03_wd5en04 | **3e-3** | 5e-4 | 0.0137 | 0.0113 | **0.0158** ğŸ† | 97 |
| CNN_S1_lr3en03_wd1en04 | 3e-3 | 1e-4 | 0.0115 | 0.0111 | 0.0158 | 96 |
| CNN_S1_lr3en03_wd1en05 | 3e-3 | 1e-5 | 0.0109 | 0.0108 | 0.0148 | 100 |
| CNN_S1a_lr1en02 | 1e-2 | 0 | 0.0092 | 0.0061 | 0.0107 | 94 |
| CNN_S1_lr1en03_wd1en05 | 1e-3 | 1e-5 | 0.0029 | 0.0030 | 0.0010 | 92 |
| CNN_S1a_lr1en01 | 0.1 | 0 | -0.00003 | -0.001 | -0.0005 | 34 |

### 6.1.4 CNN Stage 2: æ¶æ„æ¢ç´¢ (lr=0.5, wd=1e-3)

| å®éªŒID | æ¶æ„ | Kernel | BN | **Test $R^2$** | å‚æ•°é‡ |
|--------|------|--------|-----|-------------|--------|
| CNN_S2_2L_c32_64_k15_bn | 2L [32,64] | 15 | âœ“ | -0.0003 | 39,937 |
| CNN_S2_1L_c32_k7_nobn | 1L [32] | 7 | âœ— | -0.0005 | 4,609 |
| CNN_S2_2L_c64_128_k15_nobn | 2L [64,128] | 15 | âœ— | -0.0005 | 140,673 |
| CNN_S2_3L_c32_64_128_k15 | 3L [32,64,128] | 15 | âœ— | **NaN** | 170,945 |

## 6.2 å»ºè®®ç»˜å›¾ï¼ˆPlot Suggestionsï¼‰

### 6.2.1 MLP å­¦ä¹ ç‡æ•æ„Ÿæ€§
- **ç›®çš„**ï¼šå±•ç¤ºå­¦ä¹ ç‡å¯¹ MLP è®­ç»ƒçš„å…³é”®å½±å“
- **X è½´**ï¼šLearning Rate (log scale)
- **Y è½´**ï¼šTest $R^2$
- **å›¾ä¸Šæ ‡æ³¨**ï¼šä»… lr=0.001 æœ‰æ•ˆ

### 6.2.2 æ¿€æ´»å‡½æ•° Ã— æ¨¡å‹å®¹é‡äº¤äº’æ•ˆåº”
- **ç›®çš„**ï¼šå±•ç¤ºæ¿€æ´»å‡½æ•°é€‰æ‹©ä¸æ¨¡å‹å¤§å°çš„å…³ç³»
- **ç±»å‹**ï¼šåˆ†ç»„æŸ±çŠ¶å›¾
- **X è½´**ï¼šæ¿€æ´»å‡½æ•° (ReLU, GELU, SiLU)
- **åˆ†ç»„**ï¼šå¤§æ¨¡å‹ vs å°æ¨¡å‹
- **Y è½´**ï¼šTest $R^2$

### 6.2.3 MLP vs CNN vs Baseline å¯¹æ¯”
- **ç›®çš„**ï¼šç›´è§‚å¯¹æ¯”å„æ–¹æ³•æ€§èƒ½
- **ç±»å‹**ï¼šæ°´å¹³æ¡å½¢å›¾
- **æ¨¡å‹**ï¼šLightGBM, MLP, Ridge, CNN
- **X è½´**ï¼šTest $R^2$

## 6.3 æœ€ä½³é…ç½®æ€»ç»“

### MLP æœ€ä½³é…ç½®

```yaml
mlp:
  hidden_sizes: [256, 64]
  activation: gelu
  dropout: 0.1
  lr: 0.0005
  weight_decay: 0.0001
  init: xavier
  params: 1,065,345
  test_r2: 0.483
```

### CNN é…ç½®ï¼ˆå¤±è´¥ï¼‰

```yaml
cnn:
  conv_channels: [32, 64]
  kernel_size: 7
  use_batch_norm: false
  lr: 0.003
  weight_decay: 0.0005
  params: 23,105
  test_r2: 0.016  # â‰ˆ random
```

## 6.4 ç›¸å…³æ–‡ä»¶

| ç±»å‹ | è·¯å¾„ |
|------|------|
| åŸå§‹ç»“æœæ±‡æ€» | `/home/swei20/Physics_Informed_AI/raw/NN_RESULTS_SUMMARY.md` |
| ç»“æœ CSV | `/home/swei20/VIT/results/nn_baselines/nn_vs_ml_results.csv` |
| è®­ç»ƒæ›²çº¿å›¾ | `/home/swei20/VIT/results/nn_baselines/debug/` |
| å®éªŒè„šæœ¬ | `/home/swei20/VIT/scripts/run_nn_baselines.py` |
| æ¨¡å‹å®šä¹‰ | `/home/swei20/VIT/src/nn/models/` |
| NN æ¶æ„è®¾è®¡æ–‡æ¡£ | `/home/swei20/Physics_Informed_AI/logg/NN/exp_nn_architecture_design_20251129.md` |

---

*æŠ¥å‘Šåˆ›å»ºæ—¶é—´: 2025-11-30*  
*æ€»å®éªŒæ•°: 27 ä¸ª (9 MLP + 18 CNN)*  
*å™ªå£°æ°´å¹³: 1.0 (æ ‡å‡†å™ªå£°)*  
*æ ¸å¿ƒå‘ç°: MLP > Ridge (+6.3%), CNN å…¨é¢å¤±è´¥*

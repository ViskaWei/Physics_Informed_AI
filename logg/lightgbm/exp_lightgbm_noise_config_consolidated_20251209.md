# ğŸ“˜ LightGBM Best Config by Noise Level â€” Consolidated Experiment Summary
> **Name:** TODO | **ID:** `VIT-20251209-lightgbm-01`  
> **Topic:** `lightgbm` | **MVP:** MVP-X.X | **Project:** `VIT`  
> **Author:** Viska Wei | **Date:** 2025-12-09 | **Status:** ğŸ”„
```
ğŸ’¡ å®éªŒç›®çš„  
å†³å®šï¼šå½±å“çš„å†³ç­–
```

---


## ğŸ”— Upstream Links
| Type | Link |
|------|------|
| ğŸ§  Hub | `logg/lightgbm/lightgbm_hub.md` |
| ğŸ—ºï¸ Roadmap | `logg/lightgbm/lightgbm_roadmap.md` |

---

# ğŸ“‘ Table of Contents

- [1. ğŸ¯ Purpose of This Consolidation](#1--purpose-of-this-consolidation)
- [2. ğŸ“ Included Experiments](#2--included-experiments)
- [3. ğŸ“Š Core Findings (Key Insights)](#3--core-findings-key-insights)
- [4. ğŸ” Detailed Comparison](#4--detailed-comparison)
- [5. ğŸ§ª Failed / Unhelpful Experiments](#5--failed--unhelpful-experiments)
- [6. ğŸ§­ Recommended Best Setting (Current SOTA)](#6--recommended-best-setting-current-sota)
- [7. ğŸ“ˆ Visual Summary](#7--visual-summary)
- [8. ğŸ“ Appendix](#8--appendix)

---

# 1. ğŸ¯ Purpose of This Consolidation

**åˆå¹¶ç†ç”±**ï¼š
- [x] å¤šæ¬¡å­å®éªŒçš„ç»“è®ºç¢ç‰‡åŒ–ï¼Œå¸Œæœ›ç»Ÿä¸€å¾—åˆ°å¯å¤ç°çš„ summary
- [x] éœ€è¦è·¨ noise level çš„ç»¼åˆå¯¹æ¯”
- [x] ä¸º NN baseline æ¯”è¾ƒæä¾› LightGBM çš„ SOTA å‚è€ƒ

**æ ¸å¿ƒé—®é¢˜**ï¼š
> ä¸åŒ noise level (Ïƒ = 0.0 ~ 2.0) ä¸‹ï¼ŒLightGBM çš„æœ€ä½³é…ç½®æ˜¯ä»€ä¹ˆï¼ŸRÂ² èƒ½è¾¾åˆ°å¤šå°‘ï¼Ÿ

**é¢„æœŸäº§å‡º**ï¼š
1. å„ noise level ä¸‹çš„ best config æ±‡æ€»è¡¨
2. lr / n_estimators / data_size çš„æœ€ä¼˜é€‰æ‹©è§„å¾‹
3. æ¨èçš„ SOTA é…ç½®ï¼ˆå¯ç›´æ¥å¤ç”¨ï¼‰

---

# 2. ğŸ“ Included Experiments

| # | File | Date | Focus | Key Result |
|---|------|------|-------|------------|
| 1 | `exp_lightgbm_noise_sweep_lr_20251204.md` | 2025-12-04 | 32k, lr sweep across noise | lr=0.1 æ’å®šæœ€ä¼˜ @ nâ‰¤100 |
| 2 | `exp_lightgbm_100k_noise_sweep_20251205.md` | 2025-12-05 | 100k, n=500, noise sweep | 100k è¶…è¶Š 32k baseline |
| 3 | `exp_lightgbm_100k_tree_limit_20251207.md` | 2025-12-07 | 100k, n=5000, tree ä¸Šé™ | n=2500 æ¨èï¼Œ100k å…¨é¢åè¶… |

### å®éªŒå…³ç³»å›¾

```
exp_noise_sweep_lr (32k baseline, nâ‰¤100)
    â”‚
    â”œâ”€â”€ exp_100k_noise_sweep (100k, n=500)
    â”‚       â†’ å‘ç° 100k è¢« n=500 é™åˆ¶
    â”‚
    â””â”€â”€ exp_100k_tree_limit (100k, n=5000)
            â†’ è§£å†³é™åˆ¶ï¼Œç¡®å®š n=2500 æ¨èå€¼
```

---

# 3. ğŸ“Š Core Findings (Key Insights)

### 3.1 â­ ä¸€å¥è¯æ€»ç»“

> **100k æ•°æ® + n_estimators=2500 + lr=0.05 æ˜¯å„ noise level çš„æœ€ä¼˜é…ç½®ï¼›å¢ç›Šéšå™ªå£°å¢å¤§ï¼Œä½å™ªå£° +1%ï¼Œé«˜å™ªå£° +10%+**

### 3.2 å…³é”®å‘ç°

- **æœ€ä½³ lr è§„å¾‹**ï¼š
  - å°æ¨¡å‹ (nâ‰¤100)ï¼šlr=0.1 æ’å®šæœ€ä¼˜
  - å¤§æ¨¡å‹ (n=500+)ï¼šlr=0.05 åœ¨ä½å™ªå£°æ›´ä¼˜ï¼Œlr=0.1 åœ¨é«˜å™ªå£°æ›´ç¨³å¥
  
- **n_estimators ä¸Šé™**ï¼š
  - 100k æ•°æ®çš„ tree ä¸Šé™çº¦ **2179**ï¼ˆä¸­ä½æ•°ï¼‰
  - æ¨è n_estimators = **2500**
  - 32k æ•°æ®æ¨è n_estimators = **1000**

- **æ•°æ®é‡å¢ç›Š**ï¼š
  - 100k vs 32k å¢ç›Šéšå™ªå£°é€’å¢
  - Ïƒ=0.1: +1.04%  â†’  Ïƒ=1.0: +2.21%
  - **é«˜å™ªå£°åœºæ™¯ä»æ›´å¤šæ•°æ®ä¸­è·ç›Šæœ€å¤§**

- **æ—©åœ (Early Stopping) è¡Œä¸º**ï¼š
  - lr=0.05 å‡ ä¹ç”¨æ»¡æ ‘æ•°
  - lr=0.1 æ”¶æ•›æ›´å¿«ï¼Œçº¦ç”¨ä¸€åŠæ ‘æ•°
  - lr=0.3 è¿‡æ—©åœæ­¢ï¼Œæ•ˆæœæœ€å·®

### 3.3 è¶‹åŠ¿æ€»ç»“è¡¨

| ç»´åº¦ | ä½å™ªå£° (Ïƒâ‰¤0.2) | ä¸­å™ªå£° (Ïƒ=0.5) | é«˜å™ªå£° (Ïƒâ‰¥1.0) |
|------|---------------|---------------|----------------|
| **Best lr** | 0.05 | 0.05 | 0.05~0.1 |
| **Best n_estimators** | 2000-3600 | 3000-4000 | 1500-2200 |
| **Best num_leaves** | 31 | 31 | 31 |
| **RÂ² (100k)** | 0.93-0.97 | 0.76 | 0.55-0.56 |
| **RÂ² (32k)** | 0.88-0.95 | 0.67-0.74 | 0.45-0.54 |
| **100k vs 32k Î”** | +1-3% | +2-3% | +2-4% |

---

# 4. ğŸ” Detailed Comparison

## 4.1 â­ è·¨ Noise Level æœ€ä½³é…ç½® (SOTA)

| Noise Ïƒ | Best RÂ² | Best lr | n_estimators | num_leaves | Data Size | Source Exp |
|---------|---------|---------|--------------|------------|-----------|------------|
| 0.0 | **0.9991** | 0.05 | 5000 | 31 | 100k | exp_tree_limit |
| 0.1 | **0.9720** | 0.05 | 2218 | 31 | 100k | exp_tree_limit |
| 0.2 | **0.9318** | 0.05 | 3608 | 31 | 100k | exp_tree_limit |
| 0.4 | **0.8183** | 0.05 | 4995 | 31 | 100k | exp_tree_limit |
| 0.5 | **0.7573** | 0.05 | 3855 | 31 | 100k | exp_tree_limit |
| 1.0 | **0.5582** | 0.05 | 2140 | 31 | 100k | exp_tree_limit |
| 2.0 | **0.3038** | 0.05 | - | 31 | 100k | exp_100k_noise |

## 4.2 Sweep: learning_rate

### 32k æ•°æ® (nâ‰¤100)

| Noise Ïƒ | lr=0.02 | lr=0.05 | lr=0.10 | Best |
|---------|---------|---------|---------|------|
| 0.1 | 0.8654 | 0.9389 | **0.9456** | 0.10 |
| 0.2 | 0.7768 | 0.8725 | **0.8775** | 0.10 |
| 0.5 | 0.5297 | 0.6356 | **0.6697** | 0.10 |
| 1.0 | 0.3150 | 0.4099 | **0.4407** | 0.10 |

â†’ **Insight**: å°æ¨¡å‹ä¸‹ lr=0.1 æ’å®šæœ€ä¼˜

### 100k æ•°æ® (n=500)

| Noise Ïƒ | lr=0.05 | lr=0.10 | lr=0.30 | Best |
|---------|---------|---------|---------|------|
| 0.1 | **0.9641** | 0.9619 | 0.9545 | 0.05 |
| 0.2 | **0.9129** | 0.9128 | 0.8874 | 0.05 |
| 0.5 | 0.7337 | **0.7370** | 0.6810 | 0.10 |
| 1.0 | 0.5162 | **0.5310** | 0.4649 | 0.10 |
| 2.0 | **0.3038** | 0.2953 | 0.2670 | 0.05 |

â†’ **Insight**: å¤§æ¨¡å‹ä¸‹ï¼Œä½å™ªå£°/æé«˜å™ªå£°ç”¨ lr=0.05ï¼Œä¸­é«˜å™ªå£°ç”¨ lr=0.1

## 4.3 Sweep: n_estimators

### 100k æ•°æ®å®é™… best_iteration

| Noise Ïƒ | lr=0.05 best_iter | lr=0.1 best_iter | ç‰¹ç‚¹ |
|---------|-------------------|------------------|------|
| 0.0 | 5000 (ä¸Šé™) | 5000 (ä¸Šé™) | ä½å™ªå£°å¯æŒç»­å­¦ä¹  |
| 0.1 | 2218 | 1259 | |
| 0.2 | 3608 | 1826 | |
| 0.4 | 4995 (â‰ˆä¸Šé™) | 1548 | lr=0.05 æ¥è¿‘ä¸Šé™ |
| 0.5 | 3855 | 1309 | |
| 1.0 | 2140 | 1117 | é«˜å™ªå£°æ”¶æ•›æ›´å¿« |

â†’ **Insight**: 
- lr=0.05 éœ€è¦æ›´å¤šæ ‘ï¼ˆå¹³å‡ 3636ï¼‰
- lr=0.1 æ”¶æ•›æ›´å¿«ï¼ˆå¹³å‡ 2003ï¼‰
- æ¨è 100k ä½¿ç”¨ **n=2500**

### ä¸åŒ n_estimators å¯¹æ¯” (32k æ•°æ®)

| Noise Ïƒ | n=100 | n=500 | n=1000 | æœ€ä¼˜ n |
|---------|-------|-------|--------|--------|
| 0.1 | 0.9456 | 0.9574 | 0.9570 | 500 |
| 0.2 | 0.8778 | 0.9003 | **0.9130** | 1000 |
| 0.5 | 0.6740 | 0.7122 | **0.7198** | 1000 |
| 1.0 | 0.4505 | **0.4949** | 0.4822 | 500 |

â†’ **Insight**: é«˜å™ªå£°æ—¶è¿‡å¤šæ ‘åè€Œè¿‡æ‹Ÿåˆ

## 4.4 Sweep: data_size (32k vs 100k)

| Noise Ïƒ | 32k best RÂ² | 100k n=500 RÂ² | 100k n=5000 RÂ² | Î”(100k-32k) |
|---------|-------------|---------------|----------------|-------------|
| 0.0 | 0.9981 | - | **0.9991** | +0.10% |
| 0.1 | 0.9616 | 0.9641 | **0.9720** | +1.04% |
| 0.2 | 0.9045 | 0.9129 | **0.9318** | +2.73% |
| 0.4 | 0.8159 | - | **0.8183** | +0.24% |
| 0.5 | 0.7393 | 0.7370 âš ï¸ | **0.7573** | +1.80% |
| 1.0 | 0.5361 | 0.5310 âš ï¸ | **0.5582** | +2.21% |

âš ï¸ **å…³é”®å‘ç°**: 100k + n=500 åœ¨é«˜å™ªå£°ä¸‹åè€Œä¸å¦‚ 32kï¼Œå› ä¸ºè¢«æ ‘æ•°é™åˆ¶

â†’ **Insight**: 100k æ•°æ®å¿…é¡»é…åˆ nâ‰¥2500 æ‰èƒ½å‘æŒ¥ä¼˜åŠ¿

---

# 5. ğŸ§ª Failed / Unhelpful Experiments

| é…ç½® | ç»“æœ | åŸå› åˆ†æ |
|------|------|---------|
| **lr=0.3** | æ‰€æœ‰åœºæ™¯æœ€å·® | Early stopping è¿‡æ—©è§¦å‘ï¼Œåªç”¨ 100-300 æ£µæ ‘ |
| **100k + n=500** @ é«˜å™ªå£° | è¢« 32k è¶…è¶Š | æ ‘æ•°ä¸¥é‡é™åˆ¶ 100k å­¦ä¹ èƒ½åŠ› |
| **lr=0.02** @ 32k | RÂ² ä½ 5-10% | å­¦ä¹ ç‡è¿‡å°ï¼Œæ¨¡å‹ underfit |
| **n=5000** @ Ïƒ=1.0 | ç•¥ä¼˜äº n=500 ä½†è€—æ—¶é«˜ | é«˜å™ªå£°ä¸‹å¢ç›Šæœ‰é™ï¼Œä¸åˆ’ç®— |

### æ•™è®­

1. **å¤§æ¨¡å‹éœ€è¦æ›´ä¿å®ˆçš„å­¦ä¹ ç‡**
   - 100k + n=500+ é…ç½®ä¸‹ï¼Œlr=0.3 å®Œå…¨å¤±æ•ˆ
   - æ¨èä½¿ç”¨ lr=0.05

2. **æ¨¡å‹å®¹é‡è¦åŒ¹é…æ•°æ®é‡**
   - 100k æ•°æ®éœ€è¦ nâ‰¥2500
   - å¦åˆ™ä¸å¦‚ç”¨ 32k + n=1000

3. **é«˜å™ªå£°ä¸‹ ensemble éœ€è¦æ§åˆ¶**
   - Ïƒ=1.0 æ—¶ n=500 åè€Œä¼˜äº n=1000ï¼ˆ32kï¼‰
   - è¿‡å¤šæ ‘ä¼šè¿‡æ‹Ÿåˆå™ªå£°

4. **lr ä¸ n_estimators çš„äº¤äº’**
   - lr å° â†’ éœ€è¦æ›´å¤šæ ‘
   - lr å¤§ â†’ æ—©åœæ›´æ—©

---

# 6. ğŸ§­ Recommended Best Setting (Current SOTA)

## 6.1 æ¨èé…ç½®

```python
# SOTA Config for LightGBM log_g Prediction
# ==========================================

# é€šç”¨é…ç½®ï¼ˆæ‰€æœ‰ noise levelï¼‰
base_config = {
    'boosting_type': 'gbdt',
    'objective': 'regression',
    'metric': 'mae',
    'num_leaves': 31,           # ç¨³å¥é€‰æ‹©
    'max_depth': 7,             # æˆ– -1ï¼ˆæ— é™åˆ¶ï¼‰
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'early_stopping_rounds': 100,
    'device_type': 'gpu',       # å¦‚æœ‰ GPU
    'random_state': 42,
    'n_jobs': -1,
}

# æŒ‰ noise level è°ƒæ•´
def get_config_for_noise(noise_level, data_size='100k'):
    config = base_config.copy()
    
    if data_size == '100k':
        config['n_estimators'] = 2500
        if noise_level <= 0.2 or noise_level >= 2.0:
            config['learning_rate'] = 0.05
        else:
            config['learning_rate'] = 0.1
    else:  # 32k
        config['n_estimators'] = 1000
        config['learning_rate'] = 0.1
    
    return config
```

## 6.2 æŒ‰åœºæ™¯æ¨è

| åœºæ™¯ | æ¨èé…ç½® | é¢„æœŸ RÂ² | è®­ç»ƒæ—¶é—´ |
|------|---------|---------|---------|
| **ä½å™ªå£° (Ïƒâ‰¤0.2) + 100k** | lr=0.05, n=2500, leaves=31 | 0.93-0.97 | ~3-5 min |
| **ä¸­å™ªå£° (Ïƒ=0.5) + 100k** | lr=0.05, n=2500, leaves=31 | 0.75-0.76 | ~3-5 min |
| **é«˜å™ªå£° (Ïƒâ‰¥1.0) + 100k** | lr=0.1, n=1500, leaves=31 | 0.55-0.56 | ~2-3 min |
| **å¿«é€Ÿå®éªŒ (32k)** | lr=0.1, n=1000, leaves=31 | é™ä½ 2-5% | ~1 min |
| **æé«˜å™ªå£° (Ïƒ=2.0)** | lr=0.05, n=2000, leaves=31 | ~0.30 | ~3 min |

## 6.3 é…ç½®é€‰æ‹©å†³ç­–æ ‘

```
Start
â”œâ”€â”€ æ•°æ®é‡?
â”‚   â”œâ”€â”€ 100k+ â†’ n_estimators = 2500
â”‚   â””â”€â”€ 32k   â†’ n_estimators = 1000
â”‚
â”œâ”€â”€ å™ªå£°æ°´å¹³?
â”‚   â”œâ”€â”€ Ïƒ â‰¤ 0.2      â†’ lr = 0.05
â”‚   â”œâ”€â”€ 0.2 < Ïƒ < 1.0 â†’ lr = 0.05 æˆ– 0.1 (both OK)
â”‚   â”œâ”€â”€ Ïƒ â‰¥ 1.0      â†’ lr = 0.1
â”‚   â””â”€â”€ Ïƒ â‰¥ 2.0      â†’ lr = 0.05 (å›å½’ä¿å®ˆ)
â”‚
â””â”€â”€ è®­ç»ƒæ—¶é—´çº¦æŸ?
    â”œâ”€â”€ å¿«é€Ÿ â†’ n_estimators Ã· 2, early_stopping = 50
    â””â”€â”€ ç²¾åº¦ä¼˜å…ˆ â†’ ä½¿ç”¨æ¨èé…ç½®
```

## 6.4 å…³é”®æ•°å­—é€ŸæŸ¥

| æŒ‡æ ‡ | å€¼ | æ¡ä»¶ |
|------|-----|------|
| **æœ€ä½³ RÂ² (noiseless)** | 0.9991 | 100k, lr=0.05, n=5000 |
| **æœ€ä½³ RÂ² (Ïƒ=0.1)** | 0.9720 | 100k, lr=0.05, n=2218 |
| **æœ€ä½³ RÂ² (Ïƒ=0.5)** | 0.7573 | 100k, lr=0.05, n=3855 |
| **æœ€ä½³ RÂ² (Ïƒ=1.0)** | 0.5582 | 100k, lr=0.05, n=2140 |
| **æ¨è n_estimators (100k)** | 2500 | ä¸­ä½æ•° 2179 å‘ä¸Šå–æ•´ |
| **æ¨è n_estimators (32k)** | 1000 | |
| **100k vs 32k å¹³å‡å¢ç›Š** | +1.5~2.5% | |
| **è®­ç»ƒæ—¶é—´ (100k, n=2500)** | 3-5 min | GPU |

---

# 7. ğŸ“ˆ Visual Summary

## 7.1 å…³é”®å›¾è¡¨å¼•ç”¨

| å›¾è¡¨ | æ¥æº | è¦ç‚¹ |
|------|------|------|
| RÂ² vs Noise | exp_noise_sweep | RÂ² éš noise è¿‘çº¿æ€§ä¸‹é™ |
| RÂ² vs LR per Noise | exp_100k_noise | lr=0.3 åœ¨æ‰€æœ‰ noise ä¸‹æœ€å·® |
| best_iter vs Noise | exp_tree_limit | 100k éœ€è¦ 2000+ æ£µæ ‘ |
| Î” RÂ² (100k-32k) | exp_100k_noise | å¢ç›Šéšå™ªå£°å¢å¤§ |
| Heatmap (lr Ã— noise) | exp_100k_noise | ä½å™ªå£°+ä½lr æœ€ä¼˜ |

## 7.2 å›¾è¡¨ä½ç½®

```
logg/lightgbm/img/
â”œâ”€â”€ r2_vs_noise.png                 # RÂ² vs Noise Level
â”œâ”€â”€ r2_vs_lr_per_noise.png          # RÂ² vs LR (per noise)
â”œâ”€â”€ best_lr_vs_noise.png            # Best LR vs Noise
â”œâ”€â”€ heatmap_lr_noise.png            # Heatmap: lr Ã— noise â†’ RÂ²
â”œâ”€â”€ delta_r2_100k_vs_32k.png        # 100k vs 32k Delta
â”œâ”€â”€ lgb_100k_best_iter_vs_noise.png # best_iteration vs Noise
â”œâ”€â”€ lgb_100k_tree_limit_summary.png # Tree Limit Summary
â””â”€â”€ lgb_100k_r2_comparison.png      # RÂ² Comparison
```

---

# 8. ğŸ“ Appendix

## 8.1 å®Œæ•´æ•°å€¼æ±‡æ€»è¡¨

### 100k æ•°æ®å®Œæ•´ç»“æœ (n=5000, lr=0.05)

| Noise Ïƒ | RÂ² | MAE | RMSE | best_iter | Time (s) |
|---------|-----|------|------|-----------|----------|
| 0.0 | 0.9991 | 0.0060 | 0.0087 | 5000 | 65659 |
| 0.1 | 0.9720 | 0.0336 | 0.0489 | 2218 | 192 |
| 0.2 | 0.9318 | 0.0523 | 0.0762 | 3608 | 249 |
| 0.4 | 0.8183 | 0.0880 | 0.1245 | 4995 | 355 |
| 0.5 | 0.7573 | 0.1034 | 0.1438 | 3855 | 317 |
| 1.0 | 0.5582 | 0.1517 | 0.1941 | 2140 | 222 |

### 100k æ•°æ® (n=500) å®Œæ•´ç»“æœ

| Noise Ïƒ | lr | RÂ² | MAE | Time (s) |
|---------|-----|-----|------|----------|
| 0.1 | 0.05 | **0.9641** | 0.0392 | 64.7 |
| 0.1 | 0.10 | 0.9619 | 0.0383 | 57.9 |
| 0.1 | 0.30 | 0.9545 | 0.0463 | 34.7 |
| 0.2 | 0.05 | **0.9129** | 0.0625 | 63.9 |
| 0.2 | 0.10 | 0.9128 | 0.0617 | 49.9 |
| 0.2 | 0.30 | 0.8874 | 0.0710 | 50.9 |
| 0.5 | 0.05 | 0.7337 | 0.1126 | 76.1 |
| 0.5 | 0.10 | **0.7370** | 0.1106 | 65.3 |
| 0.5 | 0.30 | 0.6810 | 0.1216 | 40.1 |
| 1.0 | 0.05 | 0.5162 | 0.1605 | 60.3 |
| 1.0 | 0.10 | **0.5310** | 0.1553 | 58.5 |
| 1.0 | 0.30 | 0.4649 | 0.1681 | 32.6 |
| 2.0 | 0.05 | **0.3038** | 0.2013 | 65.0 |
| 2.0 | 0.10 | 0.2953 | 0.2011 | 48.5 |
| 2.0 | 0.30 | 0.2670 | 0.2065 | 29.2 |

### 32k æ•°æ® Best Config per Noise

| Noise Ïƒ | Best RÂ² | lr | n_est | leaves |
|---------|---------|-----|-------|--------|
| 0.1 | 0.9456 | 0.10 | 100 | 31 |
| 0.2 | 0.8778 | 0.10 | 100 | 63 |
| 0.5 | 0.6740 | 0.10 | 100 | 63 |
| 1.0 | 0.4505 | 0.10 | 100 | 63 |

## 8.2 best_iteration ç»Ÿè®¡ (100k)

| ç»Ÿè®¡é‡ | å€¼ |
|--------|-----|
| min | 1117 |
| max | 5000 |
| mean | 2819 |
| **median** | **2179** |
| std | 1564 |

## 8.3 å®éªŒæ—¶é—´çº¿

| Date | Experiment | ä¸»è¦å‘ç° |
|------|------------|---------|
| 2025-12-04 | exp_noise_sweep_lr | lr=0.1 åœ¨ nâ‰¤100 ä¸‹æ’å®šæœ€ä¼˜ |
| 2025-12-05 | exp_100k_noise_sweep | 100k + n=500 åœ¨å„å™ªå£°è¶…è¶Š 32k |
| 2025-12-07 | exp_tree_limit | 100k çš„ tree ä¸Šé™çº¦ 2179ï¼Œæ¨è n=2500 |

## 8.4 å¼€æ”¾é—®é¢˜ & ä¸‹ä¸€æ­¥

| é—®é¢˜ | ä¼˜å…ˆçº§ | å»ºè®®å®éªŒ |
|------|--------|---------|
| num_leaves=63 åœ¨ 100k ä¸‹æ•ˆæœï¼Ÿ | ğŸŸ¡ P1 | å•ç‹¬ sweep |
| æ··åˆ noise è®­ç»ƒçš„é²æ£’æ€§ï¼Ÿ | ğŸŸ¢ P2 | multi-noise training |
| LightGBM vs NN (100k) å¯¹æ¯”ï¼Ÿ | ğŸ”´ P0 | exp_nn_vs_lgb |
| Feature importance åˆ†æï¼Ÿ | ğŸŸ¡ P1 | feature_importance |

---

## ğŸ”— Related Files

| Type | Path | Description |
|------|------|-------------|
| ğŸ§  Hub | `lightgbm_hub_20251130.md` | æ™ºåº“å¯¼èˆª |
| ğŸ—ºï¸ Roadmap | `lightgbm_roadmap_20251130.md` | å®éªŒè¿½è¸ª |
| ğŸ“Š Source 1 | `exp_lightgbm_noise_sweep_lr_20251204.md` | 32k lr sweep |
| ğŸ“Š Source 2 | `exp_lightgbm_100k_noise_sweep_20251205.md` | 100k n=500 sweep |
| ğŸ“Š Source 3 | `exp_lightgbm_100k_tree_limit_20251207.md` | 100k tree ä¸Šé™ |

---

> **Generated by merge command**  
> **Last Updated**: 2025-12-09

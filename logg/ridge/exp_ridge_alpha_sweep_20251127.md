# 📊 Ridge 回归正则化强度 (α) 调优实验报告

---
> **实验名称：** Ridge Regression Alpha Sweep Experiment  
> **作者：** Viska Wei  
> **日期：** 2025-11-27  
> **数据版本：** HDF5 光谱数据（4096 像素合成光谱）  
> **模型版本：** Ridge Regression with α ∈ [0.001, 1000]

---

# 📑 目录

- [1. 🎯 目标](#1--目标)
- [2. 🧪 实验设计](#2--实验设计experiment-design)
- [3. 📊 实验图表](#3--实验图表)
- [4. 💡 关键洞见](#4--关键洞见key-insights)
- [5. 📝 结论](#5--结论conclusion)
- [6. 📎 附录](#6--附录)

---

# 1. 🎯 目标

## 1.1 背景与动机

预测 log_g 时，把无关像素"扔掉"比"保留"更有效 —— 这意味着后续 NN 架构应侧重于学习"哪些信息不重要"。

我们想验证：
- 4096 维光谱中，是否存在大量与 log_g **完全无关** 的像素/信息？
- 模型的核心任务是否是 **信息过滤（filtering）** 而非 **信息提取（extraction）**？
- 如果正则化（即"压制无关维度"）能显著提升性能，则说明 NN 设计应优先考虑 **去噪/稀疏化机制**

## 1.2 核心假设

> **神经网络的大部分 capacity 是用来"删掉无用信息"，而不是"提取有用信息"。**

本次实验通过 Ridge 回归提供以下证据：

- **证据 1**：α=0.001 时 R² 从 OLS 的 0.969 跃升至 0.999 —— 即使无噪声，也有无关信息需要压制
- **证据 2**：最优 α 随噪声单调增大 —— 噪声越大，需要"扔掉"的无关像素越多
- **证据 3**：Ridge 在所有噪声下优于 OLS —— 信息过滤始终有益

## 1.3 验证问题

| # | 问题 | 验证目标 | 结果 |
|---|------|---------|------|
| Q1 | 无噪声时是否也需要正则化？ | 验证光谱本身含无关信息 | ✅ 是，α=0.001 使 R² 从 0.969→0.999 |
| Q2 | 最优 α 如何随噪声变化？ | 揭示"需删除信息量"与噪声的关系 | ✅ 单调增大：0.001→1000 |
| Q3 | Ridge vs OLS 的性能差距有多大？ | 量化"信息过滤"的收益 | ✅ 高噪声下提升 +68.4% |
| Q4 | 高噪声下线性模型的极限在哪？ | 判断是否需要非线性来"更智能地过滤" | ✅ N=2.0 时 best R²=0.22 |

## 1.4 结论摘要

### 1.4.1 实验结论

| 结论 | 说明 |
|------|------|
| **光谱含无关信息** | 即使 noise=0，正则化也能将 R² 从 0.969 提升到 0.999 |
| **最优 α 随噪声单调增大** | 从 0.001 (N=0) 到 1000 (N=2.0)，跨越 6 个数量级 |
| **Ridge 一致优于 OLS** | 在所有噪声水平下，Δ R² 从 +0.9% 到 +68.4% |
| **光谱-log_g 映射本质线性** | noise=0 时 R²=0.999，线性模型足够 |

### 1.4.2 对 NN 设计的启示

| 设计原则 | 具体建议 |
|---------|---------|
| **信息过滤优先** | NN 设计应侧重 Attention/Sparse/Denoising 机制 |
| **Weight decay 与噪声挂钩** | 噪声越大，需要越强的正则化 |
| **Linear + Residual 结构** | 先用 Ridge 预测，再用 NN 学习残差 |

> **一句话总结**：NN 的主要任务不是"从光谱提取 log_g"，而是"学会哪些像素该忽略"。

---

# 2. 🧪 实验设计（Experiment Design）

## 2.1 数据（Data）

| 配置项 | 值 |
|--------|-----|
| 样本数 | ~52 unique (α, noise_level) 组合 |
| 特征维度 | 4,096 |
| 标签参数 | log_g |
| 噪声水平 | 0.0, 0.1, 0.2, 0.5, 1.0, 2.0 |

**噪声模型：**
$$
\text{noisy\_flux} = \text{flux} + \mathcal{N}(0, 1) \times \text{error} \times \text{noise\_level}
$$

其中：
- **flux**: 光谱流量值（每个波长点的辐射强度）
- **error**: 每个波长点的已知高斯噪声标准差 σ
- **noise_level**: 噪声缩放因子 (0.0 - 2.0)

## 2.2 模型与算法（Model & Algorithm）

### Ridge 回归（L2 正则化线性回归）
$$
\hat{y} = X w + b
$$
$$
w = (X^\top X + \alpha I)^{-1} X^\top y
$$

### OLS（Ordinary Least Squares，无正则化）
$$
w = (X^\top X)^{-1} X^\top y
$$

## 2.3 超参数搜索空间

| 参数 | 搜索范围 |
|------|----------|
| Ridge α | 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0 |
| noise_level | 0.0, 0.1, 0.2, 0.5, 1.0, 2.0 |
| 特征维度 | 4096 |

## 2.4 数据来源

| 来源 | 文件路径 | 噪声范围 | Alpha 范围 |
|------|----------|----------|------------|
| Alpha Sweep | `results/linear_alpha_search/linear_alpha_sweep.csv` | 0.0 - 2.0 | 0.001 - 1000 |
| Linear Experiments | `results/all_linear_experiments.csv` | 0.0, 0.1, 1.0 | 1 - 100 |
| Sonnet Collection | `collections/sonnet/results/LNREG_MASTER_RESULTS_TABLE.csv` | 0.0 - 2.0 | 100 |

---

# 3. 📊 实验图表

## 📊 图 1：Ridge 性能 vs log₁₀(α)（按噪声水平分组）

![Ridge Metrics vs Alpha by Noise](img/ridge_metrics_vs_alpha_by_noise.png)

**Figure 1. Ridge 回归性能随正则化强度 α 的变化（按噪声水平分组）。**

**图表结构：** 3×1 布局
- **上图**：Test R² vs log₁₀(α)（越高越好）
- **中图**：Test MAE vs log₁₀(α)（越低越好）
- **下图**：Test RMSE vs log₁₀(α)（越低越好）

**颜色方案：** Viridis colormap
- 🟡 黄色：noise=0（干净数据）
- 🟣 紫色：noise=2（高噪声）

**标记说明：**
- 折线 + 圆点：Ridge 回归结果
- ★ 星号 (x=-3.5)：OLS 基线

**关键观察**：
- 最优 α 随噪声水平单调右移
- OLS（无正则化）在所有噪声下都劣于最优 Ridge
- 高噪声下性能急剧下降，但 Ridge 仍优于 OLS

---

# 4. 💡 关键洞见（Key Insights）

## 4.1 宏观层洞见（支撑大目标假设）

### 🔑 核心发现：光谱中存在与 log_g 完全无关的信息

**关键证据：无噪声时 α=0.001 的巨大提升**

| 模型 | noise=0 时 R² | 说明 |
|------|---------------|------|
| OLS（无正则化） | 0.9694 | 保留所有 4096 维信息 |
| Ridge α=0.001 | **0.9990** | 轻微压制无关维度 |
| **Δ R²** | **+0.030 (+3.1%)** | 即使数据完全干净，也有信息需要"扔掉" |

**这说明什么？**
- 4096 维光谱中，部分像素与 log_g **完全无关**
- OLS 试图用这些无关像素拟合，反而引入噪声
- 极小的正则化（α=0.001）就能让模型"忽略"这些无关信息

### 最优 α 随噪声单调增大 → 需删除的无关信息越来越多

$$
\text{noise} \uparrow \quad \Longrightarrow \quad \alpha_{\text{opt}} \uparrow \quad \Longrightarrow \quad \text{需"扔掉"的像素越多}
$$

| 噪声水平 | 最优 α | 物理含义 |
|----------|--------|----------|
| 0.0 | 0.001 | 光谱本身含少量无关信息 |
| 0.1 | 1.0 | 噪声污染了部分像素 |
| 0.5 | 100 | 大量像素被噪声淹没 |
| 2.0 | 1000 | 几乎所有像素都需强压制 |

### 对 NN 设计的核心启示

> **NN 的主要任务不是"从光谱提取 log_g"，而是"学会哪些像素该忽略"。**

1. **架构设计应侧重"信息过滤"机制**
   - Attention 机制：学习哪些像素重要
   - Sparse 层：自动屏蔽无关维度
   - Denoising 预处理：先去噪再预测

2. **正则化 = 显式告诉模型"忽略某些信息"**
   - Weight decay、Dropout、L1 稀疏化都是在做同一件事
   - 噪声越大，需要越强的"忽略"机制

3. **Capacity 分配**
   - 大部分参数应用于"过滤无关信息"
   - 少量参数用于"从有用信息线性映射到 log_g"（因为本质是线性的）

## 4.2 模型层洞见（用于优化模型）

### 🔹 为什么 Ridge 在无噪声下反而比 OLS 更好？

- 光谱中包含 **与 log_g 完全无关的特征**
- OLS（无正则）会过度拟合这些无关维度 → R²≈0.97
- Ridge (α≈0.001) 抑制这些无关方向 → 逼近完美线性关系 R²≈1.0
- **说明 100% 的 log_g 信息都在线性子空间里，OLS 只是"走偏了"**

### 🔹 为什么最佳 α 会随着噪声上升而变大？

- 每个噪声水平都有一个最佳的 **bias–variance tradeoff** 点
- 噪声越大 → 模型越容易拟合噪声 → 需要更强正则（更大 α）
- **这说明光谱在噪声 regime 下：噪声主导的是高频维度，信号偏低频/平滑**

### 🔹 α 随噪声变化透露了数据的物理结构

| α 随 noise 的变化 | 含义 | 本实验情况 |
|-------------------|------|------------|
| **α 随 noise ↑ 上升** | 数据中有大量可被噪声污染的高频分量（像素级信息）；真正 log_g 信息在更"平滑"的方向上；需要强正则来过滤噪声 | ✅ **符合** |
| α 不变 | 信号结构稳定，对噪声不敏感（常见于低维结构或强归一化数据） | ❌ |
| α 随 noise ↑ 反而下降（少见） | 数据天然具有平滑性／强先验结构，不需要大正则 | ❌ |

**物理解读：** log_g 信息编码在光谱的 **低频/平滑结构** 中，而非像素级细节。噪声优先污染高频分量，因此需要正则化来"低通滤波"。

## 4.3 实验层细节洞见

### Ridge 一致性优于 OLS

在所有噪声水平下，最优调参的 Ridge 都优于 OLS：
- 最小改进：noise=0.1 时 +0.9%
- 最大改进：noise=2.0 时 +68.4%

**结论：** 即使是简单的 L2 正则化，在高维回归中也是必要的。

### 过度正则化的代价

| Noise | α=100 vs α_opt |
|-------|----------------|
| 0.0 | R² 从 0.999 降至 0.794 (−20%) |
| 0.1 | R² 从 0.909 降至 0.780 (−14%) |

**警示：** 固定 α 策略在跨噪声场景下不可行。

### 评估指标一致性

R², MAE, RMSE 三个指标在所有噪声水平下指向相同的最优 α，表明：
- 无需针对不同指标选择不同超参数
- 可以使用任一指标进行超参数搜索

## 4.4 物理层洞见

### 光谱-log_g 映射的线性本质

$$
\text{noise} = 0 \Rightarrow R^2 = 0.999
$$

这表明：
1. **log_g 信息分布在多个像素上**，而非稀疏谱线
2. **映射本质是线性的**，非线性模型可能只带来边际改进
3. **特征工程重点应在去噪**，而非复杂变换

### 噪声对信息的破坏

| Noise | Best R² | 信息损失 |
|-------|---------|----------|
| 0.0 | 0.999 | 0% |
| 0.1 | 0.909 | ~9% |
| 0.5 | 0.649 | ~35% |
| 1.0 | 0.451 | ~55% |
| 2.0 | 0.221 | ~78% |

**结论：** 噪声对性能的影响是剧烈的，再多的正则化也无法恢复丢失的信息。

---

# 5. 📝 结论（Conclusion）

## 5.1 核心发现

> **NN 的主要任务不是"从光谱提取 log_g"，而是"学会哪些像素该忽略"。**

假设验证：
- ✅ 最优 α 随噪声单调增大：α_opt: 0.001 → 1000 (noise: 0 → 2)
- ✅ Ridge 在所有噪声下优于 OLS：Δ R²: +0.8% ~ +68.4%
- ✅ 光谱-log_g 映射本质线性：noise=0 时 R²=0.999
- ⚠️ 高噪声下线性模型能力有限：noise=2 时 best R²=0.22

## 5.2 关键结论（4 条）

| # | 结论 | 证据 |
|---|------|------|
| 1 | **光谱含无关信息** | noise=0 时 Ridge(α=0.001) R²=0.999 > OLS R²=0.969 |
| 2 | **最优 α 随噪声单调增大** | 从 0.001 到 1000，跨越 6 个数量级 |
| 3 | **映射本质线性** | noise=0 时 R²=0.999 |
| 4 | **正则化收益随噪声增大** | Δ R² 从 +3.1% (N=0) 到 +68.4% (N=2.0) |

## 5.3 设计启示

### 架构原则

| 原则 | 建议 | 原因 |
|------|------|------|
| 信息过滤优先 | Attention/Sparse/Denoising 机制 | NN 主要任务是"忽略无关像素" |
| Linear + Residual | 先 Ridge 预测，NN 学残差 | log_g 本质线性，NN 只需学残差 |
| 自适应正则化 | Weight decay 与噪声挂钩 | 最优 α 随噪声变化 6 个数量级 |

### ⚠️ 常见陷阱

| 常见做法 | 实验证据 |
|----------|----------|
| "固定 α 适配所有噪声" | 最优 α 随噪声变化 6 个数量级 |
| "OLS 足够好" | Ridge 在所有噪声下都更优 |
| "噪声大就用更复杂的模型" | 正则化比模型复杂度更重要 |

## 5.4 物理解释

- log_g 信息编码在光谱的 **低频/平滑结构** 中
- 噪声优先污染高频分量
- 正则化 = "低通滤波"

## 5.5 关键数字速查

| 指标 | 值 |
|------|-----|
| 最佳无噪声性能 | R²=0.999 (Ridge α=0.001) |
| 最佳高噪声性能 (N=2.0) | R²=0.221 (Ridge α=1000) |
| 正则化最大收益 | +68.4% (N=2.0) |
| 最优 α 变化范围 | 0.001 → 1000 (10⁶ 倍) |

## 5.6 下一步工作

| 方向 | 具体任务 |
|------|----------|
| 非线性模型对比 | LightGBM vs Ridge (same noise levels) |
| 其他恒星参数 | 对 T_eff, [Fe/H] 重复实验 |
| α 自动选择 | 交叉验证或根据 SNR 估计 |
| NN 架构验证 | Linear + Residual 设计 |

---

# 6. 📎 附录

## 6.1 数值结果表（Results）

### 6.1.1 Ridge 回归完整结果（按噪声水平分组）

#### Noise = 0.0（无噪声）

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | **0.9990** | **0.0060** | **0.0092** |
| 0.01 | 0.9978 | 0.0093 | 0.0138 |
| 0.1 | 0.9934 | 0.0162 | 0.0237 |
| 1.0 | 0.9784 | 0.0294 | 0.0429 |
| 10.0 | 0.9301 | 0.0546 | 0.0772 |
| 100.0 | 0.7943 | 0.1014 | 0.1324 |
| 1000.0 | 0.4720 | 0.1798 | 0.2122 |
| **OLS** | 0.9694 | 0.0380 | 0.0511 |

#### Noise = 0.1

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.9012 | 0.0674 | 0.0918 |
| 0.1 | 0.9029 | 0.0669 | 0.0910 |
| 1.0 | **0.9090** | **0.0650** | **0.0881** |
| 10.0 | 0.8907 | 0.0724 | 0.0965 |
| 100.0 | 0.7802 | 0.1051 | 0.1369 |
| **OLS** | 0.9007 | 0.0673 | 0.0920 |

#### Noise = 0.5

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.6075 | 0.1397 | 0.1829 |
| 10.0 | 0.6325 | 0.1359 | 0.1770 |
| 100.0 | **0.6493** | **0.1357** | **0.1729** |
| 1000.0 | 0.4365 | 0.1860 | 0.2192 |
| **OLS** | 0.6075 | 0.1397 | 0.1829 |

#### Noise = 1.0

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.3851 | 0.1776 | 0.2290 |
| 50.0 | 0.4325 | 0.1734 | 0.2199 |
| 100.0 | **0.4507** | **0.1730** | **0.2164** |
| 1000.0 | 0.3684 | 0.1963 | 0.2320 |
| **OLS** | 0.3851 | 0.1776 | 0.2290 |

#### Noise = 2.0

| Alpha | Test R² | Test MAE | Test RMSE |
|-------|---------|----------|-----------|
| 0.001 | 0.1312 | 0.2214 | 0.2722 |
| 100.0 | 0.1709 | 0.2184 | 0.2659 |
| 1000.0 | **0.2210** | **0.2177** | **0.2577** |
| **OLS** | 0.1312 | 0.2214 | 0.2722 |

### 6.1.2 最优 α 与 OLS 对比总结

| Noise | Best α | Ridge R² | OLS R² | Δ R² | 相对改进 |
|-------|--------|----------|--------|------|----------|
| 0.0 | 0.001 | **0.9990** | 0.9694 | +0.030 | +3.1% |
| 0.1 | 1.0 | **0.9090** | 0.9007 | +0.008 | +0.9% |
| 0.2 | 10.0 | **0.8264** | 0.8108 | +0.016 | +1.9% |
| 0.5 | 100.0 | **0.6493** | 0.6075 | +0.042 | +6.9% |
| 1.0 | 100.0 | **0.4507** | 0.3851 | +0.066 | +17.0% |
| 2.0 | 1000.0 | **0.2210** | 0.1312 | +0.090 | +68.4% |

## 6.2 建议绘图（Plot Suggestions）

### 6.2.1 Linear + Residual NN 架构验证
- **目的**：验证先用 Ridge 预测，再用 NN 学习残差的架构
- **X 轴**：噪声水平
- **Y 轴**：R²
- **比较**：Ridge-only vs NN-only vs Linear+Residual

## 6.3 相关文件

| 类型 | 路径 |
|------|------|
| 图表 | `img/ridge_metrics_vs_alpha_by_noise.png` |
| 绘图脚本 | `scripts/plot_ridge_r2_vs_alpha.py` |
| Alpha Sweep 脚本 | `scripts/alpha_sweep.sh` |
| Ridge 配置 | `configs/exp/logg/linear_ridge.yaml` |
| 结果汇总 | `results/LINEAR_ALPHA_SWEEP_RESULTS.md` |

---

*Generated: 2025-11-27*

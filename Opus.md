# 🔬 快速闭环迭代的科研方法论

> **面试准备材料** | 基于 Physics_Informed_AI 项目实践  
> **作者**: Viska Wei | **生成**: Claude Opus 4.5 | **日期**: 2025-01-12

---

## 📑 目录

- [核心理念：Physics-Informed 闭环迭代](#核心理念physics-informed-闭环迭代)
- [Part 1: 物理先验 → 可优化的模型结构与约束](#part-1-物理先验--可优化的模型结构与约束)
- [Part 2: MVP 递进与假设树驱动](#part-2-mvp-递进与假设树驱动)
- [Part 3: 加数据 vs 加模型的决策框架](#part-3-加数据-vs-加模型的决策框架)
- [Part 4: 项目实例解析](#part-4-项目实例解析)
- [附录: 核心概念速查](#附录-核心概念速查)

---

## 核心理念：Physics-Informed 闭环迭代

```
┌──────────────────────────────────────────────────────────────────────────────┐
│                        快速闭环迭代方法论架构                                   │
├──────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│   📊 物理先验 & 数据特性                                                       │
│        ↓                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  1️⃣ 转化: 物理约束 → 模型结构/损失函数/正则化                          │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│        ↓                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  2️⃣ 规划: Hub(知识) ← → Roadmap(执行) + 假设树(核心问题分解)           │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│        ↓                                                                     │
│   ┌─────────────────────────────────────────────────────────────────────┐   │
│   │  3️⃣ 决策: Gate 验证 → 加数据? 加模型? 加结构?                          │   │
│   └─────────────────────────────────────────────────────────────────────┘   │
│        ↓                                                                     │
│   📊 实验结果 → 更新假设状态 → 迭代下一轮                                       │
│                                                                              │
│   核心原则: 最小可行验证(MVP) + 假设驱动 + 量化决策门(Gate)                       │
│                                                                              │
└──────────────────────────────────────────────────────────────────────────────┘
```

**一句话总结**：把物理洞见编码为模型归纳偏置，通过最小可行实验快速验证假设，用量化的决策门驱动资源分配。

---

## Part 1: 物理先验 → 可优化的模型结构与约束

### 1.1 核心思想

> **物理先验不是约束，而是归纳偏置的指南**

| 物理洞见 | 模型结构翻译 | 实际案例 |
|---------|-------------|---------|
| 映射本质是线性的 | Linear Shortcut: $\hat{y} = w^\top x + g_\theta(x)$ | Ridge R²=0.999 @ noise=0 → NN 必须包含线性通道 |
| 信息分布不均匀 | 注意力机制 / 特征选择 | [M/H] 贡献 68.7% → Gate 优先对齐金属丰度 |
| 噪声异方差 | 加权损失 / 误差感知输入 | $\mathcal{L} = \sum_i \frac{(y_i - \hat{y}_i)^2}{\sigma_i^2}$ |
| 参数纠缠 | 多任务学习 / 条件化 | Schur decay=0.69 → multi-task 可选但非必须 |
| 分段更简单 | Mixture of Experts (MoE) | Oracle MoE ΔR²=+0.16 @ noise=1 |

### 1.2 转化方法论

```
┌────────────────────────────────────────────────────────────────────────────┐
│                    物理先验 → 模型约束的转化流程                               │
├────────────────────────────────────────────────────────────────────────────┤
│                                                                            │
│   Step 1: 识别领域物理                                                       │
│   ├── 目标量的物理意义（log g = 表面重力 → 影响谱线压力展宽）                    │
│   ├── 信号来源（Ca II triplet, H-α 线翼）                                    │
│   └── 干扰因素（天空线污染, 参数耦合 Teff/[M/H]）                              │
│                                                                            │
│   Step 2: 量化信息边界                                                       │
│   ├── 理论上限: Fisher Information / CRLB → R²_max                          │
│   ├── 经验上限: noise=0 时的 best model → 信息是否足够                        │
│   └── 噪声阈值: SNR vs 性能曲线 → 临界点在哪                                   │
│                                                                            │
│   Step 3: 编码为模型结构                                                      │
│   ├── 线性假设 → Linear Shortcut / Residual 学习                             │
│   ├── 稀疏信号 → 注意力 / 稀疏连接                                            │
│   ├── 分段线性 → MoE / Conditional Normalization                            │
│   └── 异方差噪声 → Weighted Loss / 不确定性估计                               │
│                                                                            │
│   Step 4: 验证与迭代                                                         │
│   ├── 消融实验: 移除某约束 → 性能下降？                                        │
│   ├── 上限对比: 模型 vs 理论上限 → headroom 有多大                             │
│   └── 反馈调整: 假设错误 → 更新模型结构                                        │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘
```

### 1.3 实战案例：log g 预测任务

**物理背景**：从恒星光谱预测表面重力 log g

| 物理先验 | 验证实验 | 模型翻译 | 效果 |
|---------|---------|---------|------|
| log g 与光谱近似线性 | Ridge @ noise=0 得到 R²=0.999 | 添加 Linear Shortcut | NN 架构必备 |
| [M/H] 决定谱线强度 | 消融实验：[M/H] 贡献 68.7% | MoE Gate 优先对齐 [M/H] | Gate 准确率 88% |
| 高噪声削弱全局模型 | Oracle MoE vs Global: ΔR²=+0.16 @ noise=1 | 分区专家 + Soft Routing | ρ=1.00 保留率 |
| 误差信息未被利用 | Fisher 用 Σ⁻¹ 加权，ML 多数 unweighted | 加权损失 / 双通道输入 | 待验证增益点 |

### 1.4 设计原则提炼

```python
# 从物理洞见中提炼的可复用原则示例
DESIGN_PRINCIPLES = {
    "R1_Linear_Shortcut": {
        "原则": "NN 必须包含 ŷ = w⊤x + g_θ(x)",
        "证据": "Ridge R²=0.999 @ noise=0",
        "适用": "所有 NN 架构"
    },
    "M2_Soft_Routing": {
        "原则": "永远用 Soft routing，不用 Hard routing",
        "证据": "Hard ρ=0.72, Soft ρ=1.00 (损失 28% vs 0%)",
        "适用": "所有 MoE"
    },
    "L5_Raw_Input": {
        "原则": "LightGBM 必须用 raw 输入，禁止 StandardScaler",
        "证据": "ΔR²=-0.36 if standardized",
        "适用": "所有树模型"
    },
    "F3_Continue_If_Headroom": {
        "原则": "R²_max ≥ 0.75 时继续投入模型优化",
        "证据": "Fisher ceiling=0.89, LightGBM=0.57, gap=+32%",
        "适用": "资源分配决策"
    }
}
```

---

## Part 2: MVP 递进与假设树驱动

### 2.1 核心假设树 (Core Hypothesis Tree)

```
🌲 核心问题: log g 预测精度还能提升多少？瓶颈在哪里？
│
├── Q1: 信息瓶颈 - 理论上限是多少？
│   ├── Q1.1: Fisher 上限？ → ✅ R²_max=0.89 @ noise=1
│   └── Q1.2: 与现有模型差距？ → ✅ Gap=+32% vs LightGBM
│
├── Q2: 模型瓶颈 - 传统 ML 能否继续提升？
│   ├── Q2.1: Ridge 天花板？ → ✅ R²=0.46, 数据 1M 仅 +2.44%
│   ├── Q2.2: LightGBM 天花板？ → ✅ R²=0.57
│   └── Q2.3: 堆数据有效吗？ → ❌ 边际递减，需模型改进
│
├── Q3: 结构瓶颈 - 分区专家有用吗？
│   ├── Q3.1: Oracle MoE 增益？ → ✅ ΔR²=+0.16 远超阈值
│   ├── Q3.2: Gate 能落地吗？ → ✅ Soft Gate ρ=0.805
│   └── Q3.3: 哪个维度分区？ → ✅ [M/H] 贡献 68.7%
│
└── Q4: 深度学习能否超越？
    ├── Q4.1: MLP vs 传统 ML？ → ⚠️ 32k: MLP < LightGBM
    ├── Q4.2: ViT @ 1M？ → 🔆 R²=0.71, 超越 LightGBM
    └── Q4.3: CNN 效果？ → ⏳ 待验证

Legend: ✅ 已验证 | ❌ 已否定 | 🔆 进行中 | ⏳ 待验证 | 🗑️ 已关闭
```

**假设树的作用**：
1. **问题分解**：大问题 → 可验证的小假设
2. **进度追踪**：一目了然看到哪些已验证、哪些待做
3. **避免重复**：已否定的方向不再踩坑
4. **决策依据**：每个分支的答案指导下一步方向

### 2.2 Hub-Roadmap 双轨制

| 维度 | Hub (智库) | Roadmap (执行) |
|------|-----------|---------------|
| **职责** | "我们知道了什么？往哪走？" | "计划跑哪些实验？进度如何？" |
| **内容** | 假设树、洞见汇合、战略推荐、设计原则 | MVP 列表、配置、进度、数值结果 |
| **更新时机** | 实验结论改变认知时 | 每次实验状态变更时 |
| **关键章节** | 共识表、决策空白、已关闭方向 | Gate 定义、看板、数值汇总 |

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Hub ↔ Roadmap 信息流                                  │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│   Hub (战略层)                           Roadmap (执行层)                     │
│   ┌──────────────────────┐              ┌──────────────────────┐            │
│   │ §0 共识表            │ ←───同步──── │ §4.2 结论快照         │            │
│   │ §1 假设树            │              │ §2 MVP 列表          │            │
│   │ §3 战略推荐          │ ────触发───→ │ §1 Gate 定义         │            │
│   │ §5 决策空白          │              │ §3 MVP 规格          │            │
│   │ §6 设计原则          │ ←───提炼──── │ §6 数值结果          │            │
│   └──────────────────────┘              └──────────────────────┘            │
│                                                                             │
│   信息流: 假设(Hub) → Gate(Roadmap) → MVP(执行) → 结论 → 更新假设(Hub)         │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.3 MVP (Minimum Viable Product) 设计原则

```
MVP 设计三要素:

┌────────────────────────────────────────────────────────────────────────────┐
│  1️⃣ 精确假设 (Hypothesis)                                                   │
│     "LightGBM 在高噪声场景需要 lr=0.1 而非 0.05"                              │
│     ❌ 不要: "LightGBM 效果好不好"（太模糊）                                   │
├────────────────────────────────────────────────────────────────────────────┤
│  2️⃣ 最小配置 (Minimal Config)                                               │
│     只改一个变量，其他固定                                                    │
│     例: lr ∈ {0.05, 0.1}, 固定 n_estimators=2500, num_leaves=31             │
├────────────────────────────────────────────────────────────────────────────┤
│  3️⃣ 量化验收 (Acceptance Criteria)                                          │
│     "If ΔR² > 5% then 接受假设; Else 拒绝"                                  │
│     必须是可量化的，不是"看起来好"                                            │
└────────────────────────────────────────────────────────────────────────────┘
```

**MVP 示例**（来自 logg_1m_roadmap）：

| MVP | 名称 | 假设 | 验收标准 | 结果 |
|-----|------|------|---------|------|
| MVP-1.1 | Fisher 上限 | 模型误差 >> Fisher σ | 比值 > 2 → 继续优化 | ✅ gap=+32% |
| MVP-1.2 | Error 输入 | 把 σ 告诉模型能提升 | ΔMAE ≥ 5% | ⏳ |
| MVP-1.4 | 敏感窗口 | 无关波段拖累优化 | R²(窗口) ≥ R²(全谱) | ⏳ |

### 2.4 Phase 分层与依赖管理

```
Phase 0: Foundation (必须先做)
    ├── MVP-0.A: 协议定义（noise/SNR 口径）
    └── MVP-0.B: Baseline（上下限建立）
         ↓ 依赖完成
Phase 1: Quick Wins (可并行)
    ├── MVP-1.1: Fisher 上限
    ├── MVP-1.2: Error 输入
    ├── MVP-1.3: 归一化对照
    └── MVP-1.4: 敏感窗口
         ↓ Decision Gate: 哪些方向有效？
Phase 2: Breakthrough (选择性)
    ├── MVP-2.1: MSM 预训练（if MVP-1.1 显示大差距）
    └── MVP-2.3: 多尺度 Token（if MVP-1.4 窗口有效）
         ↓
Phase 3: Long-term
    └── MVP-3.x: 稳健性/泛化验证
```

---

## Part 3: 加数据 vs 加模型的决策框架

### 3.1 Decision Gate 设计

```
┌────────────────────────────────────────────────────────────────────────────┐
│                           资源分配决策树                                      │
├────────────────────────────────────────────────────────────────────────────┤
│                                                                            │
│   Q: 下一步该投入什么？                                                       │
│                                                                            │
│   Step 1: 计算理论上限                                                       │
│           Fisher R²_max = ?                                                │
│                ↓                                                           │
│           ┌─────────────────────────────────────────────────┐              │
│           │ If R²_max < 0.75 → 信息不足，需要改变任务/加先验    │              │
│           │ If R²_max ≥ 0.75 → 继续优化模型                   │              │
│           └─────────────────────────────────────────────────┘              │
│                                                                            │
│   Step 2: 计算模型效率                                                       │
│           efficiency = R²_model / R²_max                                   │
│                ↓                                                           │
│           ┌─────────────────────────────────────────────────┐              │
│           │ If efficiency < 60% → 投模型（表示/架构改进）       │              │
│           │ If efficiency ∈ [60%, 80%] → 投结构（MoE/分域）    │              │
│           │ If efficiency > 80% → 投数据或转向其他任务          │              │
│           └─────────────────────────────────────────────────┘              │
│                                                                            │
│   Step 3: Scaling 趋势分析                                                  │
│           32k → 100k → 1M 的增益曲线                                         │
│                ↓                                                           │
│           ┌─────────────────────────────────────────────────┐              │
│           │ If 增益 > 10% per 3x data → 继续投数据             │              │
│           │ If 增益 < 3% per 3x data → 边际递减，投模型        │              │
│           └─────────────────────────────────────────────────┘              │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘
```

### 3.2 实战决策案例

**案例：log g @ noise=1 的资源分配决策**

| Step | 问题 | 数据 | 结论 |
|------|------|------|------|
| 1 | 理论上限 | Fisher R²_max = 0.89 | ✅ 信息足够，继续优化 |
| 2 | 模型效率 | LightGBM=0.57, efficiency=64% | → 投模型/结构 |
| 3 | 数据增益 | 100k→1M: Ridge +2.44% | → 边际递减，不投数据 |
| 4 | 结构红利 | Oracle MoE ΔR²=+0.16 | → 投结构（MoE）|

**最终决策**: Route MoE + 深度学习，不继续堆数据

### 3.3 Gate 验证检查清单

```markdown
## 资源分配决策 Gate Checklist

### Gate-1: 信息论上限 (必做)
- [ ] 计算 Fisher/CRLB → R²_max
- [ ] 对比 R²_model vs R²_max → headroom
- [ ] 决策: headroom > 20% → 继续投模型

### Gate-2: 数据规模 (必做)
- [ ] 运行 N-sweep (32k/100k/1M)
- [ ] 计算 ΔR² per 3× data
- [ ] 决策: ΔR² < 5% → 不投数据

### Gate-3: 结构红利 (可选)
- [ ] 运行 Oracle MoE 实验
- [ ] 计算 ΔR² vs Global model
- [ ] 决策: ΔR² > 0.05 → 投结构

### Gate-4: 模型类型 (必做)
- [ ] 对比 Linear vs Tree vs NN
- [ ] 识别天花板模型
- [ ] 决策: NN > Tree? 继续深度学习
```

### 3.4 常见陷阱与规避

| 陷阱 | 症状 | 规避方法 |
|------|------|---------|
| 过早投数据 | 1M 数据提升 <3% | 先验证 scaling 趋势再决定 |
| 忽略理论上限 | 不知道还有多少提升空间 | 先做 Fisher 分析 |
| 假设未量化 | "可能有用" → 资源浪费 | MVP 必须有验收标准 |
| 不记录失败 | 重复踩坑 | Hub 维护"已关闭方向" |
| 口径不统一 | 结论互相打架 | 冻结 test/noise/metric 协议 |

---

## Part 4: 项目实例解析

### 4.1 层级结构

```
logg/                               # 项目根目录
├── master_hub.md                   # L0: 全局战略导航
│
├── scaling/                        # L1: 数据规模主题
│   ├── scaling_hub_20251222.md     # 智库: 共识/假设/战略
│   ├── scaling_roadmap_20251222.md # 执行: MVP/进度/数值
│   ├── fisher_hub_20251225.md      # 子主题: 理论上限专题
│   ├── exp/                        # 实验报告
│   │   ├── exp_scaling_fisher_ceiling_v2.md
│   │   └── exp_scaling_oracle_moe_noise1.md
│   └── img/                        # 图表
│
├── moe/                            # L1: MoE 架构主题
│   ├── moe_hub_20251203.md
│   ├── moe_roadmap_20251203.md
│   ├── moe_snr_hub.md              # 子主题: SNR-MoE
│   └── exp/
│
├── ridge/                          # L2: Ridge 专题
│   ├── ridge_hub_20251223.md
│   ├── ridge_roadmap_20251223.md
│   └── tree/                       # 假设分支
│       └── alpha/
│           ├── branch_ridge__alpha.md
│           └── leaf_ridge__alpha__A.md
│
└── vit/                            # L1: ViT 架构主题
    ├── vit_roadmap_20251227.md
    └── exp/
```

### 4.2 一个完整的迭代周期示例

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                      MoE 验证的完整迭代周期                                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  Day 1: 问题提出                                                             │
│  ├── 假设: "按物理参数分专家可以提升 log g 预测"                                │
│  ├── 记录: 添加到 moe_hub §1 假设树 Q1                                        │
│  └── 规划: 创建 MVP-1.1 (Oracle MoE 实验)                                    │
│                                                                             │
│  Day 2-3: MVP-1.1 执行                                                       │
│  ├── 配置: 9 个 (Teff×[M/H]) bins, Ridge 专家                                │
│  ├── 运行: nohup python train_moe.py > logs/moe_1.1.log 2>&1 &              │
│  └── 结果: ΔR²=+0.050 @ noise=0.2 ✅                                         │
│                                                                             │
│  Day 4: 洞见提炼                                                             │
│  ├── 消融: [M/H] 贡献 68.7%, Teff 贡献 42.9%                                 │
│  ├── 更新: moe_hub §4 洞见汇合 I2: "[M/H] 是主要贡献者"                        │
│  └── 原则: moe_hub §6 P1: "优先按 [M/H] 分专家"                               │
│                                                                             │
│  Day 5: 新假设生成                                                           │
│  ├── 问题: "高噪声(noise=1)下 MoE 仍有效吗？"                                  │
│  ├── 假设: 添加到 moe_hub §1 Q4                                              │
│  └── 规划: MVP-16O (Oracle MoE @ noise=1)                                   │
│                                                                             │
│  Day 6-7: MVP-16O 执行                                                       │
│  ├── 结果: ΔR²=+0.16 (远超阈值!)                                             │
│  ├── 洞见: moe_hub I3: "高噪声放大结构红利 3.3×"                               │
│  └── 决策: Gate 通过 → MoE 是 noise=1 主线方案                                │
│                                                                             │
│  Day 8: 下一问题                                                             │
│  ├── 决策空白: "可落地 Gate 能保住多少增益？"                                   │
│  └── 规划: MVP-PG1 (Soft Gate 验证)                                          │
│                                                                             │
│  Day 9-10: MVP-PG1 执行                                                      │
│  ├── 结果: Soft Gate ρ=1.00, Hard Gate ρ=0.72                               │
│  ├── 原则: M2: "必须用 Soft routing，放弃 Hard"                               │
│  └── 状态: Q3 已关闭 → MoE 可落地                                             │
│                                                                             │
│  最终产出:                                                                   │
│  ├── Hub: 5 条共识, 9 条洞见, 9 条设计原则, 4 个已关闭方向                       │
│  ├── 数字: Oracle MoE R²=0.62, Soft Gate ρ=1.00                              │
│  └── 决策: Route MoE+Soft Gate 验证通过 → 进入生产化                           │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 4.3 关键数字速查（权威来源）

| 模型 | 32k R² | 100k R² | 1M R² | 配置 | 来源 |
|------|--------|---------|-------|------|------|
| Ridge | 0.458 | 0.486 | 0.46 | α=200/3e4/1e5 | ridge_hub |
| LightGBM | 0.536 | 0.558 | 0.57 | lr=0.05, n=2500 | lightgbm_hub |
| MLP | 0.498 | 0.551 | - | Residual | NN_main |
| Oracle MoE | - | - | 0.62 | 9 bin | moe_hub |
| **Fisher ceiling** | - | - | **0.89** | 理论上限 | fisher_hub |
| **ViT** | - | - | **0.71** | L6-H256 | vit_roadmap |

---

## 附录: 核心概念速查

### A. 文件类型说明

| 类型 | 命名规范 | 职责 |
|------|---------|------|
| **Hub** | `[topic]_hub_YYYYMMDD.md` | 知识导航: 假设、洞见、战略、原则 |
| **Roadmap** | `[topic]_roadmap_YYYYMMDD.md` | 执行追踪: MVP、Gate、进度、数值 |
| **Exp** | `exp_[name]_YYYYMMDD.md` | 单实验报告: 目标、设计、结果、结论 |
| **Card** | `card_[name]_YYYYMMDD.md` | 知识卡片: 可复用的阶段性结论 |

### B. Hub 必备章节

```markdown
| # | 章节 | 内容 |
|---|------|------|
| §0 | TL;DR | 共识表 + 决策就绪状态 + 权威数字 |
| §1 | 假设树 | ASCII 树形图，带状态标记 |
| §2 | 口径冻结 | Dataset/Noise/Metric 唯一权威 |
| §3 | 当前答案 | 战略推荐 + 分支答案表 |
| §4 | 洞见汇合 | 多实验 → 共识 |
| §5 | 决策空白 | 我们缺什么答案？什么结果能关闭它？ |
| §6 | 设计原则 | 已确认/待验证/关键数字/已关闭方向 |
| §7 | 指针 | Roadmap/Exp/Card 链接 |
| §8 | 变更日志 | 只记录知识改变 |
```

### C. MVP 设计模板

```markdown
### MVP-X.Y: [名称]

| 项 | 配置 |
|----|------|
| **目标** | [一句话目标] |
| **假设** | [H: 假设陈述] |
| **数据** | [数据集/规模/噪声] |
| **模型** | [架构/配置] |
| **变量** | [只改这一个变量] |
| **验收** | [If 条件 then 接受 else 拒绝] |

**Steps:**
1. [具体步骤 1]
2. [具体步骤 2]
3. ...

**→ Hypothesis Impact:**
- If 接受: [下一步决策]
- If 拒绝: [转向哪个方向]
```

### D. 一句话方法论总结

> **物理洞见 → 模型归纳偏置 → 假设树分解 → MVP 最小验证 → Gate 量化决策 → 洞见提炼 → 迭代下一轮**

---

*Generated by Claude Opus 4.5 based on Physics_Informed_AI repository analysis*

# MoE Research Hub

---
> **Topic:** Mixture of Experts (MoE) for Stellar Parameter Prediction: When Is It Beneficial?  
> **Author:** Viska Wei  
> **Created:** 2025-12-03  
> **Last Updated:** 2025-12-04  
> **Status:** ğŸŸ¢ **Phase 8 Complete â€” Gating Implementation Resolved**  
> **Current Focus:** Proceeding to Phase 6 NN-MoE Integration

---

## Related Files

| Type | File | Description |
|------|------|-------------|
| Roadmap | [`moe_roadmap.md`](../logg/moe/moe_roadmap_20251203.md) | Experiment tracking |
| Sub-experiments | `exp_moe_*.md` | Individual experiment reports |
| Knowledge Cards | `card_*.md` | Condensed findings |

---

# Table of Contents

- [1. Research Question Hierarchy](#1-research-question-hierarchy)
- [2. Hypothesis Pyramid](#2-hypothesis-pyramid)
- [3. Insight Synthesis](#3-insight-synthesis)
- [4. Strategic Directions](#4-strategic-directions)
- [5. Design Principles](#5-design-principles)
- [6. Appendix](#6-appendix)

---

# 1. Research Question Hierarchy

## 1.1 Primary Research Question

> **Can Mixture of Experts (MoE) improve stellar parameter prediction performance? Under what conditions is it beneficial?**

Corollary:

> **If MoE proves effective, multi-expert architectures should be incorporated; otherwise, optimization efforts should focus on single-model approaches.**

## 1.2 Question Decomposition

```
Primary Question: Can MoE improve log g prediction?
â”‚
â”œâ”€â”€ Q1: Does physics-based expert partitioning help?
â”‚   â”œâ”€â”€ Q1.1: Does (Teff, [M/H]) binning improve performance? â†’ âœ… Î”RÂ²=+0.050 [MVP-1.1]
â”‚   â”œâ”€â”€ Q1.2: [M/H] vs Teff â€” which contributes more? â†’ âœ… [M/H] 68.7% [MVP-1.1]
â”‚   â””â”€â”€ Q1.3: Are quantile bins superior to manual boundaries? â†’ âŒ Kâ‰¥3 yields negative gain [MVP-3.0]
â”‚
â”œâ”€â”€ Q2: Does noise-level-based partitioning help?
â”‚   â”œâ”€â”€ Q2.1: What is the gain from noise-matched experts? â†’ âœ… Î”RÂ²=+0.080 [MVP-2.0]
â”‚   â””â”€â”€ Q2.2: Is discrete noise binning stable? â†’ âš ï¸ Degradation at noise=0.5 [MVP-2.0]
â”‚
â”œâ”€â”€ Q3: Is MoE deployable? (Critical Risk)
â”‚   â”œâ”€â”€ Q3.1: What fraction of oracle gain does pseudo-gating retain? â†’ âŒ Only 7.3% [MVP-3.1]
â”‚   â”œâ”€â”€ Q3.2: Can conditional linear models substitute MoE? â†’ âœ… Achieves 80% [MVP-3.2]
â”‚   â””â”€â”€ Q3.3: Is gating error the bottleneck? â†’ ğŸ”„ Under validation in MVP-7.1
â”‚
â”œâ”€â”€ Q4: Why do certain regions perform better/worse?
â”‚   â”œâ”€â”€ Q4.1: Why is high [M/H] easier? â†’ âœ… Rich metallic line features [MVP-5.0]
â”‚   â””â”€â”€ Q4.2: What does low [M/H] require? â†’ â³ Pending validation
â”‚
â””â”€â”€ Q5: ğŸŸ¢ Can physics-window features enable deployable gating? (Phase 8 âœ… Resolved)
    â”œâ”€â”€ Q5.1: Can sparse physics-window features distinguish expert domains? â†’ âœ… **82% accuracy, Ï=1.00** [MVP-PG1]
    â”œâ”€â”€ Q5.2: Is soft routing more noise-robust than hard routing? â†’ âœ… **Soft Ï=1.00 >> Hard Ï=0.72** [MVP-PG1]
    â”œâ”€â”€ Q5.3: Is Teff information essential for gating? â†’ âš ï¸ Helpful (+11%) but not required [MVP-PG1]
    â””â”€â”€ Q5.4: Is window-shape PCA necessary? â†’ âŒ Not required (Ïâ‰ˆ1.00 already achieved)
â”‚
â”œâ”€â”€ Q6: ğŸ”´ How to scale from 3 to 9 experts? (Phase 9)
â”‚   â”œâ”€â”€ Q6.1: Can physics-window gating distinguish 9 classes (TeffÃ—[M/H])? â†’ â³ [MVP-9E1]
â”‚   â”œâ”€â”€ Q6.2: Does soft routing retain â‰¥85% gain with 9 experts? â†’ â³ [MVP-9E1]
â”‚   â””â”€â”€ Q6.3: Can RÂ² improve from 0.87 to 0.90+? â†’ â³ [MVP-9E1]
â”‚
â””â”€â”€ Q7: âš ï¸ Is expert capacity the new bottleneck? (Phase 10 âœ… Complete)
    â”œâ”€â”€ Q7.1: Do NN experts outperform Ridge experts? â†’ âŒ **NN RÂ²=0.38 << Ridge RÂ²=0.87** [MVP-NN1]
    â”œâ”€â”€ Q7.2: Can NN improve difficult sub-domains (Bin4/Bin7 low [M/H])? â†’ âœ… **All three improved** [MVP-NN1]
    â””â”€â”€ Q7.3: What drives gain from fixed gate + NN expert? â†’ âœ… **Soft routing smoothing** [MVP-NN1]
â”‚
â””â”€â”€ Q8: ğŸŸ¢ How to further optimize 9-expert MoE? (Phase 11 In Progress)
    â”œâ”€â”€ Q8.1: Are classification-optimal gate weights also regression-optimal? â†’ âœ… **No â€” MLP regression gate improves RÂ² from 0.9213â†’0.9310** [MVP-Next-A]
    â”œâ”€â”€ Q8.2: How to handle out-of-range samples while maintaining high RÂ²? â†’ â³ [MVP-Next-B]
    â””â”€â”€ Q8.3: Do weakest bins (Bin3/Bin6) exhibit systematic bias? â†’ â³ [MVP-Next-C]

Legend:
âœ… Validated | âŒ Rejected | âš ï¸ Partially validated | ğŸ”„ In progress | â³ Pending
```

## 1.3 Scope Definition

| In Scope | Out of Scope |
|----------|--------------|
| MoE benefits for log g prediction | Other stellar parameters (Teff, [M/H]) |
| Linear models (Ridge) as baseline | Complex NN-MoE (only if linear validation passes) |
| Deployable gating schemes | Oracle-dependent ideal schemes |
| (Teff, [M/H], SNR) as conditioning variables | Other potential conditioning variables |

**Positioning Statement:**
> **This experimental series constitutes a feasibility study aimed at validating MoE's potential through low-cost linear experiments before committing to complex NN-MoE architectures. Conclusions should be interpreted as preliminary assessments of whether MoE warrants further investment.**

---

# 2. Hypothesis Pyramid

## 2.1 L1 Macro Hypotheses (Strategic)

| # | Macro Hypothesis | Status | If True | If False |
|---|-----------------|--------|---------|----------|
| **H1** | The $\log g$â€“spectrum mapping is "piecewise simple" in $(T_{\text{eff}}, [\text{M/H}])$ space | âœ… Validated | Adopt MoE with physics-based experts | Abandon MoE; optimize single model |
| **H2** | Deployable gating can retain majority of oracle gain | âš ï¸ Risk | Continue gating optimization | Transition to continuous conditioning |

## 2.2 L2 Meso Hypotheses (Tactical)

| # | Meso Hypothesis | Parent | Status | Key Experiment |
|---|----------------|--------|--------|----------------|
| **H1.1** | $(T_{\text{eff}}, [\text{M/H}])$ binning significantly improves performance | H1 | âœ… Î”RÂ²=+0.050 | MVP-1.1 |
| **H1.2** | [M/H] is the primary contributor to MoE gains | H1 | âœ… 68.7% contribution | MVP-1.1 ablation |
| **H1.3** | SNR/noise-level partitioning has value | H1 | âœ… Î”RÂ²=+0.080 | MVP-2.0 |
| **H2.1** | Quantile binning simplifies manual boundaries | H2 | âŒ Kâ‰¥3 yields negative gain | MVP-3.0 |
| **H2.2** | Pseudo-gating retains â‰¥70% of oracle gain | H2 | âŒ Only 7.3% | MVP-3.1 |
| **H2.3** | Conditional linear approaches MoE performance | H2 | âœ… Achieves 80% | MVP-3.2 |

## 2.3 L3 Micro Hypotheses (Testable)

| # | Testable Hypothesis | Parent | Criterion | Result | Source |
|---|---------------------|--------|-----------|--------|--------|
| **H1.1.1** | Partitioned Ridge global RÂ² exceeds global Ridge RÂ² by â‰¥0.03 | H1.1 | Î”RÂ² â‰¥ 0.03 | âœ… +0.050 | MVP-1.1 |
| **H1.1.2** | High metallicity bin RÂ² > global Ridge | H1.1 | Local RÂ² > 0.85 | âœ… 0.97-0.98 | MVP-1.0 |
| **H1.2.1** | [M/H]-only 3 experts achieve â‰¥60% of gain | H1.2 | Contribution â‰¥ 60% | âœ… 68.7% | MVP-1.1 |
| **H1.3.1** | Noise-matched experts outperform mixed | H1.3 | Î”RÂ² > 0 | âœ… +0.080 avg | MVP-2.0 |
| **H2.1.1** | Optimal K exists in [3,5] | H2.1 | K=X optimal | âŒ K=2 only positive | MVP-3.0 |
| **H2.2.1** | Pseudo â‰¥ 70% Oracle | H2.2 | Ratio â‰¥ 70% | âŒ Only 7.3% | MVP-3.1 |
| **H2.3.1** | 1st order Conditional RÂ² â‰¥ 0.90 | H2.3 | RÂ² â‰¥ 0.90 | âœ… 0.9018 | MVP-3.2 |

### Physics-Window Gate Hypotheses (Phase 8 âœ… Complete)

| # | Testable Hypothesis | Parent | Criterion | Result | Source |
|---|---------------------|--------|-----------|--------|--------|
| **H-PG1** | Sparse physics-window features suffice for expert domain classification | H2 | Accuracy >70% or **Ï â‰¥ 0.5** | âœ… **Acc=82%, Ï=1.00** | MVP-PG1 |
| **H-PG2** | Soft routing is more noise-robust than hard routing | H2 | Soft RÂ² â‰¥ Hard RÂ², lower variance | âœ… **Soft Ï=1.00 >> Hard Ï=0.72** | MVP-PG1 |
| **H-PG3** | Teff information is essential for gating | H2 | Significant Ï increase with Teff proxy | âš ï¸ Helpful (+11%) but not essential | MVP-PG1 |
| **H-PG4** | Window-shape PCA required only when scalars insufficient | H2 | Validate with depth/EW first; assess PCA increment | âŒ Not needed (Ïâ‰ˆ1.00) | MVP-PG1 |

### 9-Expert Scaling Hypotheses (Phase 9)

| # | Testable Hypothesis | Parent | Criterion | Result | Source |
|---|---------------------|--------|-----------|--------|--------|
| **H-9E1** | Physics-window features can distinguish 9 classes (TeffÃ—[M/H]) | H1 | 9-class gate accuracy >60% or **Ï â‰¥ 0.85** | â³ | MVP-9E1 |
| **H-9E2** | Soft routing retains majority of gain with 9 experts | H2 | Ï â‰¥ 0.85 (retaining 85% oracle gain) | â³ | MVP-9E1 |
| **H-9E3** | 9 experts can push deployable RÂ² from 0.87 to â‰¥0.90 | H1 | RÂ²_phys-gate(9) â‰¥ 0.90 | â³ | MVP-9E1 |

### NN Expert Hypotheses (Phase 10 âœ… Complete)

| # | Testable Hypothesis | Parent | Criterion | Result | Source |
|---|---------------------|--------|-----------|--------|--------|
| **H-NN1** | NN experts outperform Ridge experts | H1 | MoE(NN) - MoE(Ridge) â‰¥ 0.02 RÂ² | âŒ **NN RÂ²=0.38 << Ridge RÂ²=0.87** | MVP-NN1 |
| **H-NN2** | Gains primarily from difficult sub-domains (Bin4/Bin7 low [M/H]) | H1 | Difficult sub-domain Î”RÂ² > average Î”RÂ² | âœ… **All three improved; high [M/H] most** | MVP-NN1 |
| **H-NN3** | Fixed gate + NN expert retains soft routing advantage | H2 | Ï_NN â‰¥ Ï_Ridge â‰ˆ 1.0 | âœ… **Soft RÂ²â‰ˆOracle RÂ², but baseline too weak** | MVP-NN1 |

### Regression-Optimal Gate & Calibration Hypotheses (Phase 11)

| # | Testable Hypothesis | Parent | Criterion | Result | Source |
|---|---------------------|--------|-----------|--------|--------|
| **H-A** | Classification-optimal gate weights â‰  regression-optimal; MSE-trained gate can further improve RÂ² | H2 | RÂ²_regress-gate > RÂ²_classify-gate (0.9213) + 0.003 | â³ | MVP-Next-A |
| **H-B** | Including out-of-range samples maintains overall high RÂ² | H1 | Full-1000 RÂ² > global RÂ² + 0.05 | â³ | MVP-Next-B |
| **H-C** | Weakest bins (Bin3/Bin6) exhibit systematic bias; affine calibration improves performance | H1 | Bin3/Bin6 RÂ² improvement â‰¥ 0.02 | â³ | MVP-Next-C |

> **Core Validation Metric Ï:**
> $$\rho = \frac{R^2_{\text{phys-gate}} - R^2_{\text{global}}}{R^2_{\text{oracle}} - R^2_{\text{global}}}$$
> - **Minimum viable**: $\rho \ge 0.5$ (retain 50% oracle gain)
> - **Promising**: $\rho \ge 0.7$
> - ğŸŸ¢ **Achieved**: **$\rho = 1.00$** (Soft routing retains 100% gain)

## 2.4 Key Hypothesis Validation Status (Updated 2025-12-04)

> **Phase 8 Breakthrough: Physics-Window Gating Resolved**

| # | Key Hypothesis | Testable Sub-hypothesis | MVP | Status |
|---|---------------|------------------------|-----|--------|
| **H-A** | ~~Is gating error the bottleneck?~~ | Continuous conditioning tolerates gate noise better | ~~MVP-7.1~~ | âŒ **No longer needed** (H-PG resolved) |
| **H-B** | ~~MoE "physics boundaries" are learnable~~ | Learnable soft gating exists | ~~MVP-7.4~~ | âœ… **Proven by H-PG** |
| **H-C** | ğŸŸ¡ Noise should be continuously conditioned | Continuous SNR conditioning eliminates noise=0.5 anomaly | MVP-7.3 | â³ Optional |
| **H-D** | ğŸŸ¢ Difficult sub-domains require different features/nonlinearity | Bin4/Bin7 need stronger feature extraction | MVP-7.4 | â³ Optional |
| **H-PG** | ğŸŸ¢ **Physics-window features enable accurate gating** | Sparse physics features retain â‰¥50% oracle gain | MVP-PG1 | âœ… **Validated! Ï=1.00** |

**Hypothesis Relationship Diagram** (Updated 2025-12-04):
```
Established: Oracle Î”RÂ²=0.05 âœ…, but Pseudo only 7.3% âŒ
  â”‚
  â”œâ”€ Diagnosis: Gate deployability is the bottleneck
  â”‚
  â””â”€ âœ… H-PG: Physics-window features enable accurate gating (Phase 8 Complete)
       â”‚
       â”œâ”€ âœ… Step A: Fixed experts ([M/H] 3-expert), gate-only testing
       â”‚   â””â”€ âœ… H-PG1: Gate accuracy 82.10%, Ï=1.00
       â”‚
       â”œâ”€ âœ… Step B: Physics-window feature design
       â”‚   â””â”€ Ca II triplet (EW_8542 most important) + Na + PCA1/2
       â”‚
       â”œâ”€ âœ… Step C: Gate model
       â”‚   â””â”€ LogReg (L2, C=10) sufficient; NN gate unnecessary
       â”‚
       â””â”€ âœ… Step D: Three routing strategies compared
           â”œâ”€ Hard: Ï=0.722 (28% loss)
           â”œâ”€ Soft: Ï=0.997 (âœ… Recommended)
           â””â”€ Soft + fallback: Ï=1.006 (best but marginal)

ğŸŸ¢ Key Finding: Soft routing is critical to success
   â†’ Explains pseudo-gating 7.3% failure (used hard routing)
   â†’ Even at 82% accuracy, soft routing retains 100% gain
```

---

# 3. Insight Synthesis

## 3.1 Synthesis Points

| # | Theme | Sources | Synthesized Conclusion | Confidence |
|---|-------|---------|----------------------|------------|
| C1 | MoE robustness | MVP-1.0, MVP-1.1 | Î”RÂ²=0.050 robust, CI entirely > 0.03 | ğŸŸ¢ High |
| C2 | [M/H] dominance | MVP-1.1 ablation, MVP-5.0 | 68.7% contribution; determines gating priority | ğŸŸ¢ High |
| C3 | Discrete gating deployment | MVP-3.0, MVP-3.1 | Quantile failure + Pseudo 7.3% | ğŸŸ¢ High |
| C4 | Continuous conditioning | MVP-3.2 | Achieves 80% MoE effect; no boundary issues | ğŸŸ¡ Medium |
| C5 | Noise conditioning value | MVP-2.0 | Average +0.080, but noise=0.5 degrades | ğŸŸ¡ Medium |
| **C6** | **ğŸŸ¢ Physics-window gate success** | MVP-PG1 | **Soft routing + 11-dim features Ï=1.00** | ğŸŸ¢ High |
| **C7** | **âš ï¸ Full-spectrum MLP unsuitable** | MVP-NN1 | **NN RÂ²=0.38 << Ridge RÂ²=0.87** | ğŸŸ¢ High |
| **C8** | **ğŸŸ¢ Regression gate > classification gate** | MVP-Next-A | **MLP regression gate RÂ²=0.9310 (+0.0097)** | ğŸŸ¢ High |

## 3.2 Detailed Synthesis

### C1: MoE Robustness

**Individual Findings:**

| Source | Finding | Key Data |
|--------|---------|----------|
| [MVP-1.0](../logg/moe/exp_moe_piecewise_ridge_20251203.md) | Partitioned Ridge significantly outperforms global | âš ï¸ Original Î”RÂ²=0.078 was overestimated |
| [MVP-1.1](../logg/moe/exp_moe_rigorous_validation_20251203.md) | Mask-aligned fair comparison | **Î”RÂ²=0.050, CI=[0.033,0.067]** |
| Large dataset (100k/10k) | Scale-up consistency | Î”RÂ²=0.0501, CI=[0.045,0.055] |

**Synthesized Conclusion:**
> **MoE partitioning by (Teff, [M/H]) yields genuine and stable gains.** Î”RÂ²=+0.050 reproduces across small and large datasets; 95% CI entirely exceeds 0.03 threshold. The mapping is indeed "piecewise simpler" in parameter space, warranting continued MoE investment.

**Design Implications:**
- MoE architecture has intrinsic value; challenge lies in deployable gating
- Robust gains justify further gating and expert optimization

---

### C2: [M/H] as the Dominant Factor

**Individual Findings:**

| Source | Finding | Key Data |
|--------|---------|----------|
| [MVP-1.1 ablation](../logg/moe/exp_moe_rigorous_validation_20251203.md) | [M/H] contribution >> Teff | [M/H] 68.7% vs Teff 42.9% |
| [MVP-5.0](../logg/moe/exp_moe_coefficient_analysis_20251203.md) | High [M/H] information more distributed | High [M/H]: 7-12% energy dispersion; Low [M/H]: 22-31% concentrated |
| [MVP-5.0](../logg/moe/exp_moe_coefficient_analysis_20251203.md) | Ca II triplet importance differential | High [M/H] Ca II importance 1.65Ã— |

**Synthesized Conclusion:**
> **Gains primarily arise from metallicity-related structural differences.** [M/H] determines line strength and feature distribution, making it the primary dimension for expert partitioning. Three [M/H] experts capture 69% of the gain.

**Design Implications:**
- Gating/conditioning should **prioritize [M/H] alignment**
- Teff is secondary; can be simplified
- High [M/H] requires broader windows/multi-region aggregation; Low [M/H] requires narrow windows/high-resolution features

---

### C3: Discrete Gating Deployment Challenges

**Individual Findings:**

| Source | Finding | Key Data |
|--------|---------|----------|
| [MVP-3.0](../logg/moe/exp_moe_quantile_bins_sweep_20251203.md) | Quantile binning fails | K=2 only positive (+0.004); Kâ‰¥3 negative |
| [MVP-3.1](../logg/moe/exp_moe_quantile_bins_sweep_20251203.md) | Pseudo-gating nearly ineffective | Only 7.3% oracle gain retained |

**Synthesized Conclusion:**
> **"Deployable gating" for hard MoE is the critical risk.** Quantile bins indicate effective boundaries are "physics thresholds/structural inflection points," not equal-frequency cuts. Pseudo-gating at 7.3% suggests gating errors can eliminate most gains.

**Design Implications:**
- Abandon simple quantile binning
- Hard MoE requires more precise gating, or transition to continuous conditioning
- MVP-7.1 needed to validate gating noise sensitivity

---

### C4: Continuous Conditioning as a Viable Path

**Individual Findings:**

| Source | Finding | Key Data |
|--------|---------|----------|
| [MVP-3.2](../logg/moe/exp_moe_conditional_ridge_20251203.md) | 1st-order conditional linear approaches MoE | RÂ²=0.9018, 80% of MoE |

**Synthesized Conclusion:**
> **Conditional Ridge demonstrates that MoE gains largely stem from "coefficients varying continuously with [M/H]."** No binning boundaries required; 100% coverage; single training pass; no gate needed.

**Design Implications:**
- **Continuous conditioning may be the more engineering-friendly approach**
- Avoids gating error problem
- Next: MVP-7.2 to extract remaining 20%

---

### C6: ğŸŸ¢ Physics-Window Gate Success (2025-12-04 Breakthrough)

**Individual Findings:**

| Source | Finding | Key Data |
|--------|---------|----------|
| [MVP-PG1](../logg/moe/exp_moe_phys_gate_baseline_20251204.md) | Soft routing retains 100% gain | **Ï=1.00** (vs 0.5 minimum) |
| [MVP-PG1](../logg/moe/exp_moe_phys_gate_baseline_20251204.md) | 82% gate accuracy sufficient | 82.10% (confusion mainly at boundaries) |
| [MVP-PG1](../logg/moe/exp_moe_phys_gate_baseline_20251204.md) | Ca II triplet is core feature | EW_8542 contributes most |
| [MVP-PG1 ablation](../logg/moe/exp_moe_phys_gate_baseline_20251204.md) | Teff proxy helpful but not essential | Without: Ï=0.887 still high |

**Synthesized Conclusion:**
> ğŸŸ¢ **MoE gating deployment problem resolved.** 11-dimensional physics-window features (Ca II depth/EW + Na + PCA1/2) + LogReg gate + Soft routing achieves near-oracle performance. **Soft routing is the critical success factor**â€”even at 82% gate accuracy, soft weighting smooths boundary errors.

**Key Insights:**
1. **Soft routing explains pseudo-gating failure**: 7.3% resulted from hard routing
2. **Gate accuracy is not the bottleneck**: 82% accuracy + soft routing â‰ˆ 100% gain
3. **Ca II 8542 is the most important single feature** (consistent with MVP-5.0 coefficient analysis)

**Design Implications:**
- âœ… **MoE path viable; no need to pivot to Conditional approach**
- âœ… Use Soft routing, not Hard routing
- âœ… LogReg gate sufficient; NN gate unnecessary
- âœ… Ready for Phase 6 NN-MoE integration

---

### C7: âš ï¸ Full-Spectrum MLP Unsuitable (2025-12-04)

**Individual Findings:**

| Source | Finding | Key Data |
|--------|---------|----------|
| [MVP-NN1](../logg/moe/exp_moe_nn_experts_20251204.md) | NN expert far inferior to Ridge | RÂ²_NN=0.38 << RÂ²_Ridge=0.87 |
| [MVP-NN1](../logg/moe/exp_moe_nn_experts_20251204.md) | MoE structure retains value | Î”RÂ² (MoE vs Global) = +0.257 |
| [MVP-NN1](../logg/moe/exp_moe_nn_experts_20251204.md) | Soft routing remains effective | RÂ²_soft â‰ˆ RÂ²_oracle |
| [MVP-NN1](../logg/moe/exp_moe_nn_experts_20251204.md) | Imbalanced expert training | Low [M/H] expert trained only 2 epochs |

**Synthesized Conclusion:**
> âš ï¸ **Full-spectrum MLP (7,200 â†’ 256 â†’ 256 â†’ 1) underperforms Ridge on this task.** For high-dimensional sparse data, Ridge's L2 regularization is more effective. MoE structure has value (Î”RÂ²=+0.26), but the NN architecture is the bottleneck.

**Key Insights:**
1. **Ridge is a strong baseline**: At current feature dimensionality, simple regularization outperforms complex NN
2. **Full-spectrum MLP architecture issue**: ~7,200 dimensions compressed to 256 too aggressively; loses spatial structure
3. **MoE mechanism effective**: Soft routing continues to retain gains; issue is the expert itself

**Design Implications:**
- âŒ Avoid direct full-spectrum MLP
- âœ… Consider 1D-CNN (exploits spectral local correlations) or feature selection + MLP
- âœ… Continue Ridge expert + physics-window gate approach

---

## 3.3 Conflicting Findings

| Theme | Experiment A | Experiment B | Possible Cause | Resolution |
|-------|-------------|-------------|----------------|------------|
| Noise partitioning | MVP-2.0: Average +0.080 valuable | noise=0.5 expert worse than mixed | Discrete binning boundaries incorrect | MVP-7.3: Continuous SNR conditioning |

---

# 4. Strategic Directions

## 4.1 Direction Status Overview (ğŸŸ¢ Updated 2025-12-04)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Research Direction Status (Post-Phase 8)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   ğŸŸ¢ High-Confidence (Validated)          ğŸŸ¡ Pending Validation     â”‚
â”‚   â”œâ”€â”€ Physics-Window Soft Gate â† Ï=1.0    â”œâ”€â”€ Continuous SNR MVP-7.3â”‚
â”‚   â”œâ”€â”€ [M/H]-Priority Gating â† MVP-1.1     â””â”€â”€ NN-MoE Integration    â”‚
â”‚   â””â”€â”€ Continuous Conditioning â† MVP-3.2                             â”‚
â”‚                                                                     â”‚
â”‚   ğŸ”´ Risk (Resolved/Demoted)              âš« Closed                 â”‚
â”‚   â””â”€â”€ ~~Hard MoE~~ â†’ Soft routing resolvesâ”œâ”€â”€ ~~Quantile bins~~     â”‚
â”‚                                           â””â”€â”€ ~~Phase 7 Diagnostics~â”‚
â”‚                                                                     â”‚
â”‚   Recommended: Phase 6 NN-MoE Integration                           â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 4.2 High-Confidence Directions (ğŸŸ¢ Multi-experiment Support)

| Direction | Evidence | Next Action | Priority |
|-----------|----------|-------------|----------|
| **âœ… Physics-Window Soft Gate** | MVP-PG1 Ï=1.00, MVP-9E1 Ï=1.13 | Complete â€” continue optimizing | ğŸŸ¢ Confirmed |
| **âœ… 9-Expert Scaling** | MVP-9E1 RÂ²=0.9213, Ï=1.13 | **Complete â€” exceeds Oracle** | ğŸŸ¢ Validated |
| **ğŸ”´ Regression-Optimal Gate** | Classification vs regression loss weight differences | **MVP-Next-A** | ğŸ”´ **P0 Highest ROI** |
| **ğŸ”´ 100% Coverage** | Currently 816/1000 covered | **MVP-Next-B** | ğŸ”´ **P0 Deliverability** |
| **ğŸ”´ Expert Calibration** | Bin3/Bin6 systematic bias | **MVP-Next-C** | ğŸ”´ P0 |
| **[M/H]-Priority Gating** | MVP-1.1 ablation: 68.7% contribution | Gate features prioritize Ca II | ğŸŸ¢ Confirmed |

## 4.3 Pending Validation (ğŸŸ¡ Hypothesis Unvalidated)

| Direction | Dependent Hypothesis | Required Experiment | Expected Gain |
|-----------|---------------------|---------------------|---------------|
| âœ… ~~Physics-Window Gate~~ | ~~H-PG~~ | âœ… MVP-PG1, MVP-9E1 | âœ… **Ï=1.13 exceeds expectations** |
| **ğŸ”´ Regression-optimal soft mixing** | H-A: Classification weights â‰  regression weights | **MVP-Next-A** | **+0.003~0.01 RÂ²** |
| **ğŸ”´ Full coverage** | H-B: Including out-of-range maintains performance | **MVP-Next-B** | **Deliverable version** |
| **ğŸ”´ Expert calibration** | H-C: Systematic bias correctable | **MVP-Next-C** | **Bin3/Bin6 Î”RÂ²â‰¥0.02** |
| ~~NN-MoE Integration~~ | ~~Physics-window gate transfer~~ | ~~MVP-NN1~~ | âš ï¸ **On hold (NN<<Ridge)** |

## 4.4 Risk Directions (ğŸ”´ Counter-evidence)

| Direction | Counter-evidence | Possible Cause | Continue? |
|-----------|-----------------|----------------|-----------|
| ~~**Hard MoE**~~ | ~~Pseudo only 7.3%~~ | ~~Gating error too sensitive~~ | âœ… **Resolved** via Soft routing |

## 4.5 Closed Directions (âš« Rejected/Resolved)

| Direction | Counter-evidence | Closure Reason | Lesson |
|-----------|-----------------|----------------|--------|
| ~~Quantile binning~~ | MVP-3.0 Kâ‰¥3 negative | Effective boundaries are physics inflection points, not equal-frequency | Do not assume uniform data distribution enables simplification |
| ~~Phase 7 Diagnostics~~ | MVP-PG1 Ï=1.00 | Phase 8 directly resolved gating problem | Soft routing is key |
| ~~Hard routing~~ | MVP-PG1 Hard Ï=0.72 | Soft routing retains full gain | Boundary errors require soft handling |

## 4.6 Strategic Summary (ğŸ”´ Updated 2025-12-04)

> **Gating problem resolved. 9-expert MoE achieves RÂ²=0.9213. Bottleneck shifts to (a) gate weight optimization, (b) coverage, (c) systematic bias.**

**Retrospective (Phases 8-10 Complete):**
- âœ… Confirmed "piecewise structure exists" (Î”RÂ²â‰ˆ0.05 robust)
- âœ… ~~"Discrete gating deployment difficult"~~ â†’ **Resolved via Soft routing Ï=1.00**
- âœ… **9-expert scaling successful**: RÂ²=0.9213, Ï=1.13 exceeds Oracle
- âœ… **Soft routing is the critical mechanism** (Hard Ï=0.72 vs Soft Ï=1.00)
- âš ï¸ **NN expert path on hold**: Full-spectrum MLP underperforms Ridge

**New Bottleneck Identification (Phase 11):**
- ğŸ”´ **Bottleneck A: Gate weight optimization** â€” Classification-optimal â‰  regression-optimal
- ğŸ”´ **Bottleneck B: Coverage** â€” 816/1000 covered; 100% coverage needed
- ğŸ”´ **Bottleneck C: Systematic bias** â€” Bin3/Bin6 (metal-poor) underperforming

**Recommended Next Steps (Phase 11 Milestone M2):**
> 1. **ğŸ”´ MVP-Next-A (Highest ROI)**: Regression-optimal soft mixing â€” Train gate weights with MSE loss
> 2. **ğŸ”´ MVP-Next-B (Deliverability)**: 100% coverage â€” Handle out-of-range samples
> 3. **ğŸ”´ MVP-Next-C (Push RÂ²)**: Expert calibration â€” Affine calibration for weakest bins

**Phase 11 Milestone M2 Objective:**
> Upgrade 9-expert physics MoE to **regression-optimal soft mixing + 100% coverage**, targeting stable improvement over classification gate RÂ² on full test set with bootstrap CI.

**Key Insight:**
> **Next RÂ² improvement comes from optimizing soft mixing weights and addressing boundary/bias issues, not adding more experts.**
> - Gate is near-oracle (Ïâ‰ˆ1.13)
> - Always use Soft routing, never Hard routing

---

# 5. Design Principles

## 5.1 Validated Principles

| # | Principle | Recommendation | Evidence | Scope |
|---|-----------|----------------|----------|-------|
| **P1** | **Prioritize [M/H]-based expert partitioning** | [M/H] contributes 68.7%; 3 [M/H] experts capture 69% gain | MVP-1.1 ablation | MoE gating design |
| **P2** | **Continuous conditioning > discrete gating** | Conditional Ridge more robust to gating error; 100% coverage | MVP-3.2 | Model selection |
| **P3** | **Noise should be continuously conditioned** | Discrete binning fails at noise=0.5; continuous SNR more stable | MVP-2.0 | Noise handling |
| **P4** | **Noise-matched training is necessary** | Deployment requires SNR knowledge to select corresponding expert | MVP-2.0 | Training strategy |
| **P5** | **Default to high-noise expert** | If SNR unknown, high-noise expert is safer | MVP-2.0 cross-noise | Deployment strategy |
| **P6** | **Use mask-aligned comparison** | Ensure Global and MoE evaluated on identical subset | MVP-1.1 | Experimental methodology |

## 5.2 Pending Principles

| # | Principle | Preliminary Recommendation | Validation Required |
|---|-----------|---------------------------|---------------------|
| P7 | Broader windows for high [M/H] | Energy dispersion requires multi-region aggregation | MVP-7.4 |
| P8 | Narrow high-resolution windows for low [M/H] | Concentrated information requires precise extraction | MVP-7.4 |

## 5.3 Key Metrics Reference

| Metric | Value | Condition | Source |
|--------|-------|-----------|--------|
| Global Ridge $R^2$ (baseline) | **0.8616** | noise=0.2, mask-aligned | MVP-1.1 |
| Partitioned Ridge $R^2$ (MoE-1) | **0.9116** | noise=0.2, mask-aligned | MVP-1.1 |
| $\Delta R^2$ (MoE-1) | **+0.050** | CI=[0.033, 0.067] | MVP-1.1 |
| [M/H] contribution ratio | **68.7%** | - | MVP-1.1 ablation |
| Teff contribution ratio | 42.9% | - | MVP-1.1 ablation |
| Conditional Ridge 1st-order $R^2$ | **0.9018** | 80% of MoE | MVP-3.2 |
| Noise Expert average $\Delta R^2$ | **+0.0797** | - | MVP-2.0 |
| Pseudo Gating retention | **7.3%** | ~~Risk~~ â†’ Resolved | MVP-3.1 |
| Ca II triplet importance ratio | **1.65Ã—** | High [M/H] vs Low [M/H] | MVP-5.0 |
| **ğŸŸ¢ Physics-window Gate Ï (Soft)** | **1.00** | Retains 100% gain | MVP-PG1 |
| **Physics-window Gate Ï (Hard)** | 0.722 | 28% loss | MVP-PG1 |
| **Gate classification accuracy** | **82.10%** | LogReg (C=10) | MVP-PG1 |
| **Bootstrap 95% CI** | [0.728, 1.438] | 1000 samples | MVP-PG1 |
| **RÂ²_moe_nn (Soft)** | 0.385 | 3 experts + Soft | MVP-NN1 |
| **RÂ²_global_nn** | 0.128 | Full training | MVP-NN1 |
| **Î”RÂ² (MoE_NN - Global_NN)** | **+0.257** | âœ… Passes threshold | MVP-NN1 |

---

# 6. Appendix

## 6.1 Physical/Domain Background

### 6.1.1 Why [M/H] Has Large Impact

**Metallicity [M/H] determines:**
- Line strength: Higher [M/H] yields stronger, more detectable metallic lines
- Feature distribution: High [M/H] information distributed across multiple bands; Low [M/H] concentrated in few strong lines
- $\log g$ feature extractability: Higher [M/H] provides more pressure-sensitive lines

### 6.1.2 Physical Scenarios Where MoE Is Effective

1. **Piecewise functional relationships:**
   - Low/high $T_{\text{eff}}$ exhibit different line shapeâ€“$\log g$ relationships
   - Extreme metallicities place $\log g$ features in completely different wavelength bands

2. **Mixed noise distributions:**
   - Samples span wide SNR range
   - Certain wavelength bands have distinct noise characteristics

3. **Non-uniform data distributions:**
   - Certain parameter regions are sparsely sampled, requiring specialized experts

### 6.1.3 Information-Theoretic Perspective

$$
R^2 \approx 1 - \frac{\mathbb{E}[(Y - \mathbb{E}[Y|F])^2]}{\operatorname{Var}(Y)}
$$

**Higher $R^2$ indicates "how much $\log g$ uncertainty is eliminated by observing $F$ alone."**

MoE fundamentally performs **conditional distribution modeling**: $P(y|x, z)$ where $z$ is the gating signal. MoE yields gains when $P(y|x)$ varies substantially across $z$.

---

## 6.2 Decision Tree: Interpreting Different Outcomes

### Scenario A: Partitioned Ridge $\Delta R^2 \geq 0.03$ âœ… Occurred

**Diagnosis:** Function is indeed "piecewise simple" in $(T_{\text{eff}}, [\text{M/H}])$ space

**Design Implications:**
- MoE architecture warrants investment
- Must address gating deployment challenge

### Scenario B: Pseudo gating < 50% Oracle âœ… Occurred

**Diagnosis:** Hard gating too sensitive to errors

**Response Strategies:**
- Transition to continuous conditioning
- Or improve gating precision

---

## 6.3 Glossary

| Term | Definition | Notes |
|------|------------|-------|
| MoE | Mixture of Experts | Multi-expert mixture model |
| Oracle gate | Gating using true [M/H]/log g values | Theoretical upper bound |
| Pseudo gate | Gating using predicted values | Deployable version |
| Conditional Ridge | Ridge with coefficients varying continuously with condition | $\phi(x, m) = [x, m\cdot x, m^2\cdot x]$ |
| Mask-aligned | Evaluating Global only on MoE-covered samples | Fair comparison method |

---

## 6.4 Changelog

| Date | Change | Affected Sections |
|------|--------|-------------------|
| 2025-12-03 | Created Hub from moe_main.md split | All |
| 2025-12-04 | Added C1-C5 synthesis details | Â§3 |
| 2025-12-04 | Updated strategic directions | Â§4 |
| **2025-12-04** | **ğŸŸ¢ MVP-PG1 Complete: Physics-window Gate Ï=1.00** | Â§1.2, Â§2.3, Â§2.4, Â§3, Â§4, Â§5.3 |
| 2025-12-04 | Added C6 synthesis: Physics-window Gate success | Â§3.1, Â§3.2 |
| 2025-12-04 | Updated hypothesis validation status H-PG1~H-PG4 | Â§2.3 |
| 2025-12-04 | Updated strategic directions and summary | Â§4 |
| 2025-12-04 | Phase 7 diagnostics closed; Phase 6 NN-MoE recommended | Â§4.5, Â§4.6 |
| **2025-12-04** | **ğŸ”´ Initiated MVP-9E1, MVP-NN1** | Â§1.2, Â§2.3, Â§4.2, Â§4.6 |
| 2025-12-04 | Added Q6, Q7 to question hierarchy: 9-expert scaling + NN experts | Â§1.2 |
| 2025-12-04 | Added H-9E1~3, H-NN1~3 hypotheses | Â§2.3 |
| 2025-12-04 | Updated strategic directions: bottleneck shift from gate to expert | Â§4.6 |
| **2025-12-04** | **âš ï¸ MVP-NN1 Complete: Added C7 insight** | Â§2.3, Â§3.1, Â§3.2, Â§5.3 |
| **2025-12-04** | **ğŸ”´ Initiated Phase 11: MVP-Next-A/B/C** | Â§1.2, Â§2.3, Â§4.2, Â§4.3, Â§4.6 |
| 2025-12-04 | Added Q8 to question hierarchy: 9-expert MoE optimization | Â§1.2 |
| 2025-12-04 | Added H-A/H-B/H-C hypotheses | Â§2.3 |
| 2025-12-04 | Updated strategic directions: bottleneck shift to weight optimization/coverage/bias | Â§4.6 |
| 2025-12-04 | Set M2 milestone objectives | Â§4.6 |

